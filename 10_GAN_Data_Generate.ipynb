{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import keras\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, multiply, Embedding, merge, Concatenate, Conv1D, BatchNormalization\n",
    "from keras.layers import Dense, Flatten, Multiply\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Add\n",
    "import tensorflow as tf\n",
    "from evaluation_metrics import *\n",
    "from helper import *\n",
    "metric_to_calculate = ['FID', 'MMD', 'DTW', 'PC', 'RMSE', 'TWED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "northern-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim=186, input_classes=3, out_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    x = Embedding(input_classes, 30)(in_label)\n",
    "    x = Dense(noise_dim)(x)\n",
    "    x = Reshape((noise_dim,1))(x)\n",
    "    \n",
    "    G_in = Input(shape=[noise_dim,])\n",
    "    gen = Dense(noise_dim)(G_in)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((noise_dim,1))(gen)\n",
    "\n",
    "    x = Concatenate()([gen, x])\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*16, kernel_size=15, strides=1, padding='valid', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=1, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    out = Activation('tanh')(x)\n",
    "    model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "# g_model = generator(noise_dim=100, input_classes=3, out_dim=186)\n",
    "# plot_model(g_model, to_file='gen.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "important-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        return X\n",
    "    else:\n",
    "        if X.shape[-1] == 1:\n",
    "            return X\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polish-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "#     X = np.load('Data/ForGAN/X.npy')\n",
    "#     y = np.load('Data/ForGAN/y.npy')\n",
    "\n",
    "    X = reshape(np.load('Data/TrainVal/X.npy'))\n",
    "    y = np.load('Data/TrainVal/y.npy')\n",
    "\n",
    "    X_N = X[y==0]\n",
    "    X_S = X[y==1]\n",
    "    X_V = X[y==2]\n",
    "\n",
    "    y_N = y[y==0]\n",
    "    y_S = y[y==1]\n",
    "    y_V = y[y==2]\n",
    "\n",
    "    return reshape(X_N), y_N, reshape(X_S), y_S, reshape(X_V), y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "separated-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "# normal noise\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=3):\n",
    "    # generate points in the latent space\n",
    "#     X_fake = np.random.uniform(0, 1.0, size=[n_samples, latent_dim])\n",
    "    X_fake = np.random.normal(0,1.0,(n_samples,latent_dim))\n",
    "    # generate labels\n",
    "    labels_fake = np.hstack((np.zeros(int(n_samples/3)), np.ones(int(n_samples/3)), 2*np.ones(int(n_samples/3))))\n",
    "    # np.random.shuffle(labels_fake)\n",
    "    return [reshape(X_fake), labels_fake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "joined-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], 1)\n",
    "    i_S = randint(0, y_S.shape[0], 1)\n",
    "    i_V = randint(0, y_V.shape[0], 1)\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "diagnostic-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(z_input, n_batch):\n",
    "    X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "    n = 3\n",
    "    Win = (n_batch//3)\n",
    "    XX = np.vstack((X_R, z_input[0:n,:,:], z_input[Win:Win+n,:,:], z_input[2*Win:2*Win+n,:,:]))\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(n):\n",
    "        # subplot(R, C, Plot_No)\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.plot(XX[i,:,:])\n",
    "    for i in range(n, ((n+1)*(n+1))-(n+1)):\n",
    "        # define subplot\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(XX[i,:,:])\n",
    "    plt.show()\n",
    "    # plt.savefig(name, dpi=75)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prepared-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_using_GAN(g_model, Actual_Data, latent_dim, Samples, Batch_Size, label):\n",
    "    X_Aug = []\n",
    "    for i in range(0, Samples+Batch_Size, Batch_Size):\n",
    "        \n",
    "        print (i, end='\\r')\n",
    "        \n",
    "        [z_input, _] = generate_latent_points(latent_dim, Batch_Size)\n",
    "        \n",
    "        if label==0:\n",
    "            labels_input = np.zeros(Batch_Size)\n",
    "        if label==1:\n",
    "            labels_input = np.ones(Batch_Size)\n",
    "        if label==2:\n",
    "            labels_input = 2*np.ones(Batch_Size)\n",
    "        \n",
    "        z_input  = g_model.predict([z_input, labels_input], verbose=0)\n",
    "        X_Aug.append(z_input)\n",
    "    \n",
    "    X_Aug = np.array(X_Aug)\n",
    "    X_Aug = X_Aug.reshape(X_Aug.shape[0]*X_Aug.shape[1], X_Aug.shape[2], X_Aug.shape[3])\n",
    "    X_Aug = np.vstack((Actual_Data, X_Aug))\n",
    "    \n",
    "    if label==0:\n",
    "        y_Aug = np.zeros(X_Aug.shape[0])\n",
    "    if label==1:\n",
    "        y_Aug = np.ones(X_Aug.shape[0])\n",
    "    if label==2:\n",
    "        y_Aug = 2*np.ones(X_Aug.shape[0])\n",
    "    \n",
    "    return X_Aug, y_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suspected-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen):\n",
    "    g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "    g_model.load_weights(model_name + str(batch_no) + '_cgan_generator.h5')\n",
    "\n",
    "    X_NN, y_NN = augment_using_GAN(g_model, X_N, latent_dim, N_Gen, n_batch, label=0)\n",
    "    X_SS, y_SS = augment_using_GAN(g_model, X_S, latent_dim, S_Gen, n_batch, label=1)\n",
    "    X_VV, y_VV = augment_using_GAN(g_model, X_V, latent_dim, V_Gen, n_batch, label=2)\n",
    "    \n",
    "    X = np.vstack((X_NN, X_SS, X_VV))\n",
    "    y = np.hstack((y_NN, y_SS, y_VV))\n",
    "    print (X.shape, y.shape)\n",
    "    \n",
    "    X_name = 'Data/GAN_GEN/' + batch_no + '_X'   \n",
    "    y_name = 'Data/GAN_GEN/' + batch_no + '_y'   \n",
    "    # print (X_name, y_name)\n",
    "    \n",
    "    np.save(X_name, X)\n",
    "    np.save(y_name, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prescription-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125561, 186, 1) (9305, 186, 1) (28954, 186, 1)\n",
      "4439 120695 101046\n"
     ]
    }
   ],
   "source": [
    "# X_N, y_N, X_S, y_S, X_V, y_V = load_real_samples()\n",
    "# print (X_N.shape, y_N.shape, X_S.shape, y_S.shape, X_V.shape, y_V.shape)\n",
    "\n",
    "X_N, _, X_S, _, X_V, _ = load_real_samples()\n",
    "print (X_N.shape, X_S.shape, X_V.shape)\n",
    "\n",
    "Total = 130000\n",
    "N_Gen = Total - X_N.shape[0]\n",
    "S_Gen = Total - X_S.shape[0]\n",
    "V_Gen = Total - X_V.shape[0]\n",
    "print (N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "n_batch = 512\n",
    "latent_dim = 100\n",
    "classes = 3\n",
    "data = 186\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "binding-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Final/BLI/'\n",
    "\n",
    "batch_no = '5023'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '6039'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '6049'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '6063'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "environmental-peoples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392172, 186, 1) (392172,)\n",
      "(392172, 186, 1) (392172,)\n",
      "(392172, 186, 1) (392172,)\n",
      "(392172, 186, 1) (392172,)\n",
      "(392172, 186, 1) (392172,)\n",
      "(392172, 186, 1) (392172,)\n",
      "(392172, 186, 1) (392172,)\n",
      "(392172, 186, 1) (392172,)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Final/BLIN/'\n",
    "\n",
    "batch_no = '2053'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '2055'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '2057'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '3011'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '4069'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '5025'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '7057'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)\n",
    "\n",
    "batch_no = '8069'\n",
    "combine_GAN_augment_data(model_name, batch_no, latent_dim, classes, data, X_N, X_S, X_V, N_Gen, S_Gen, V_Gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "liberal-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_no = '5023'\n",
    "# g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "# g_model.load_weights(model_name + str(batch_no) + '_cgan_generator.h5')\n",
    "# [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "# z_input  = g_model.predict([z_input, labels_input], verbose=1)\n",
    "# print (z_input.shape)\n",
    "\n",
    "# show_plot(z_input, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "junior-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "# g_model.load_weights(model_name + str(batch_no) + '_cgan_generator.h5')\n",
    "\n",
    "# X_NN, y_NN = augment_using_GAN(g_model, X_N, latent_dim, N_Gen, n_batch, label=0)\n",
    "# X_SS, y_SS = augment_using_GAN(g_model, X_S, latent_dim, S_Gen, n_batch, label=1)\n",
    "# X_VV, y_VV = augment_using_GAN(g_model, X_V, latent_dim, V_Gen, n_batch, label=2)\n",
    "\n",
    "# print (X_NN.shape, y_NN.shape, X_SS.shape, y_SS.shape, X_VV.shape, y_VV.shape)\n",
    "\n",
    "# X = np.vstack((X_NN, X_SS, X_VV))\n",
    "# y = np.hstack((y_NN, y_SS, y_VV))\n",
    "# print (X.shape, y.shape)\n",
    "\n",
    "# X_name = 'Data/GAN_GEN/' + batch_no + '_X'   \n",
    "# y_name = 'Data/GAN_GEN/' + batch_no + '_y'   \n",
    "# # print (X_name, y_name)\n",
    "# np.save(X_name, X)\n",
    "# np.save(y_name, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-publication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
