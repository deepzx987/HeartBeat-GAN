{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic conditional gan\n",
    "# generate data\n",
    "# add and train a classifier use k fold also\n",
    "# condition me one hot encoding\n",
    "# generator k lie combined data and disc k lie train data.. coz testing me sara deke bias ho jaega\n",
    "# different loss functions for generator and discriminator\n",
    "# discriminator output shud be one hot encode with labels as n s or v and not 0 or 1 that is fake or real:\n",
    "# confusion here\n",
    "# disc property: should recognise fake and also if gen data is not of that class (so 2 things)\n",
    "# training k time jab random samples uthaenge tab sari classes k\n",
    "# equal no. of samples uthana\n",
    "\n",
    "# refer manning book\n",
    "# For example, the CGAN Discriminator should learn to reject the pair (, 4), regardless of whether the \n",
    "# example (handwritten numeral 3) is real or fake, because it does not match the label, 4. \n",
    "# The CGAN Discriminator should also learn to reject all image-label pairs in which the image is fake, \n",
    "# even if the label matches the image.\n",
    "\n",
    "# Accordingly, in order to fool the Discriminator, it is not enough for the CGAN Generator to produce \n",
    "# realistic-looking data. The examples it generates also need to match their labels. \n",
    "# After the Generator is fully trained, this then allows us to specify what example we want the CGAN to \n",
    "# synthesize by passing it the desired label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Param Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from helper import *\n",
    "import keras as keras\n",
    "from pycm import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176212, 186) (176212,)\n"
     ]
    }
   ],
   "source": [
    "# X_test = np.load('Data/test_data.npy')\n",
    "# X_train = np.load('Data/train_data.npy')\n",
    "\n",
    "# y_train = X_train[:,-1]\n",
    "# X_train = X_train[:,:-1]\n",
    "\n",
    "# y_test = X_test[:,-1]\n",
    "# X_test = X_test[:,:-1]\n",
    "\n",
    "# X_Gen = np.vstack((X_train, X_test))\n",
    "# y_Gen = np.hstack((y_train, y_test))\n",
    "\n",
    "# np.save('X_Gen', X_Gen)\n",
    "# np.save('y_Gen', y_Gen)\n",
    "\n",
    "# X_Gen = np.load('Data/X_Gen.npy')\n",
    "# y_Gen = np.load('Data/y_Gen.npy')\n",
    "\n",
    "# print (X_Gen.shape, y_Gen.shape)\n",
    "\n",
    "# X_N = X_Gen[y_Gen==0][:80000]\n",
    "# X_S = X_Gen[y_Gen==1]\n",
    "# X_V = X_Gen[y_Gen==2]\n",
    "\n",
    "# y_N = y_Gen[y_Gen==0][:80000]\n",
    "# y_S = y_Gen[y_Gen==1]\n",
    "# y_V = y_Gen[y_Gen==2]\n",
    "\n",
    "# X = np.vstack((X_N, X_S, X_V))\n",
    "# y = np.hstack((y_N, y_S, y_V))\n",
    "\n",
    "# print (X.shape, y.shape)\n",
    "\n",
    "# np.save('Data/X', X)\n",
    "# np.save('Data/y', y)\n",
    "\n",
    "# print (y_test.shape, X_test.shape, y_train.shape, X_train.shape, X_Gen.shape, y_Gen.shape)\n",
    "\n",
    "X = np.load('Data/X.npy')\n",
    "y = np.load('Data/y.npy')\n",
    "\n",
    "print (X.shape, y.shape)\n",
    "# X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "# X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "# y_train = keras.utils.to_categorical(y_train)\n",
    "# y_test = keras.utils.to_categorical(y_test)\n",
    "# X_Gen=X_Gen.reshape(X_Gen.shape[0],X_Gen.shape[1],1)\n",
    "# y_Gen = keras.utils.to_categorical(y_Gen)\n",
    "\n",
    "# print (X_Gen.shape, y_Gen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176212, 186)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176212,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 186\n",
    "INPUT_FEAT = 1\n",
    "OUTPUT_CLASS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for LAYER in range(1,8):\n",
    "    filename = 'ResNet_' + str(LAYER)\n",
    "    print (filename)\n",
    "    if not os.path.exists(str(filename)):\n",
    "        os.makedirs(str(filename))\n",
    "    \n",
    "    model = ResNet_model(WINDOW_SIZE,INPUT_FEAT,OUTPUT_CLASS,LAYER)\n",
    "#     model.summary()\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size=32, epochs=1, callbacks=cb, validation_split=0.2, verbose=1)\n",
    "    prediction(model, X_test, y_test, filename)\n",
    "    save_the_model(filename, model)\n",
    "    write_history(filename, history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " 487/2425 [=====>........................] - ETA: 5:08 - loss: 0.1510 - accuracy: 0.9536 - Recall: 0.0951 - Precision: 0.2961 - AUC: 0.5546"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-68b15a80ebed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                             multi_label=True,label_weights=None)])\n\u001b[1;32m     39\u001b[0m history = model.fit(train_generator, steps_per_epoch=train_samples, epochs=EP, verbose=1,\n\u001b[0;32m---> 40\u001b[0;31m                 validation_data=val_generator, validation_steps=val_samples, callbacks=callback)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/p3tf2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# output_directory = 'Parallel_NN'\n",
    "# if not os.path.isdir(output_directory):\n",
    "#     os.mkdir(output_directory)\n",
    "# twelve_lead_model_filename = model_directory + '/' + twelve_lead_filename\n",
    "# train_generator = generator(X_train, y_train, Window, leads, batch_size=BS)\n",
    "# train_samples=np.ceil(y_train.shape[0] / BS)\n",
    "# val_generator = generator(X_val, y_val, Window, leads, batch_size=BS)\n",
    "# val_samples=np.ceil(y_val.shape[0] / BS)\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_AUC', mode='max', verbose=1, patience=Pat),\n",
    "         ModelCheckpoint(filepath=str(twelve_lead_model_filename)+'_check_model.h5', \n",
    "                         monitor='val_AUC', verbose=1, save_best_only=True, mode='max'),\n",
    "         ReduceLROnPlateau(monitor='val_AUC', factor=0.5, patience=Pat//2, verbose=1, \n",
    "                           mode='max', min_delta=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "# model = parallel_NN(WINDOW_SIZE,INPUT_FEAT,OUTPUT_CLASS):\n",
    "model = parallel_NN(Window, len(leads), snomed_classes.shape[0])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy', dtype=None, threshold=0.5),\n",
    "                       tf.keras.metrics.Recall(name='Recall'),\n",
    "                       tf.keras.metrics.Precision(name='Precision'),\n",
    "                       tf.keras.metrics.AUC(num_thresholds=200,summation_method=\"interpolation\",\n",
    "                                            name=\"AUC\",dtype=None,curve=\"ROC\",thresholds=None,\n",
    "                                            multi_label=True,label_weights=None)])\n",
    "history = model.fit(train_generator, steps_per_epoch=train_samples, epochs=EP, verbose=1,\n",
    "                validation_data=val_generator, validation_steps=val_samples, callbacks=callback)\n",
    "\n",
    "\n",
    "history_name = output_directory + '/' + twelve_lead_filename\n",
    "print (twelve_lead_model_filename, history_name)\n",
    "\n",
    "save_model(twelve_lead_model_filename, model)\n",
    "write_history(history_name, history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
