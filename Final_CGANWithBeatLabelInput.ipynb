{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, multiply, Embedding, merge, Concatenate, Conv1D, BatchNormalization\n",
    "from keras.layers import Dense, Flatten, Multiply\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers.core import Activation\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from evaluation_metrics import *\n",
    "metric_to_calculate = ['FID', 'MMD', 'DTW', 'PC', 'RMSE', 'TWED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bronze-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(data_dim, input_classes=3):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    x = Embedding(input_classes, 30)(in_label)\n",
    "    x = Dense(data_dim)(x)\n",
    "    x = Reshape((data_dim,1))(x)\n",
    "    \n",
    "    D_in = Input(shape=[data_dim,1])\n",
    "    x = Concatenate()([D_in, x])\n",
    "    \n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*16, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[D_in, in_label], outputs=out)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# d_model = discriminator(data_dim=186, input_classes=3)\n",
    "# plot_model(d_model, to_file='disc.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "northern-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim=186, input_classes=3, out_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    x = Embedding(input_classes, 30)(in_label)\n",
    "    x = Dense(noise_dim)(x)\n",
    "    x = Reshape((noise_dim,1))(x)\n",
    "    \n",
    "    G_in = Input(shape=[noise_dim,1])\n",
    "#     gen = Dense(noise_dim)(G_in)\n",
    "#     gen = LeakyReLU(alpha=0.2)(gen)\n",
    "#     gen = Reshape((noise_dim,1))(gen)\n",
    "\n",
    "    x = Concatenate()([G_in, x])\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*16, kernel_size=2, strides=2, padding='valid', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=1, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    out = Activation('sigmoid')(x)\n",
    "    model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(out_dim)(x)\n",
    "#     x = Reshape((out_dim,1))(x)\n",
    "#     out = Activation('sigmoid')(x)\n",
    "#     model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# g_model = generator(noise_dim=186, input_classes=3, out_dim=186)\n",
    "# plot_model(g_model, to_file='gen.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "written-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(d_model, g_model):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# gan_model = create_gan(d_model, g_model)\n",
    "# plot_model(gan_model, to_file='gan.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thrown-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        return X\n",
    "    else:\n",
    "        if X.shape[-1] == 1:\n",
    "            return X\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    X = np.load('Data/X.npy')\n",
    "    y = np.load('Data/y.npy')\n",
    "\n",
    "    # print (X.shape, y.shape)\n",
    "\n",
    "    X_N = X[y==0]\n",
    "    X_S = X[y==1]\n",
    "    X_V = X[y==2]\n",
    "\n",
    "    y_N = y[y==0]\n",
    "    y_S = y[y==1]\n",
    "    y_V = y[y==2]\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "\n",
    "#     X_N=X_N.reshape(X_N.shape[0],X_N.shape[1],1)\n",
    "#     X_S=X_S.reshape(X_S.shape[0],X_S.shape[1],1)\n",
    "#     X_V=X_V.reshape(X_V.shape[0],X_V.shape[1],1)\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "    return reshape(X_N), y_N, reshape(X_S), y_S, reshape(X_V), y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_samples):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], int(n_samples/3))\n",
    "    i_S = randint(0, y_S.shape[0], int(n_samples/3))\n",
    "    i_V = randint(0, y_V.shape[0], int(n_samples/3))\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    labels = np.hstack((y_N[i_N], y_S[i_S], y_V[i_V]))\n",
    "    \n",
    "    # generate class labels\n",
    "    y = reshape(np.random.uniform(0.8, 1, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bound-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "# normal noise\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=3):\n",
    "    # generate points in the latent space\n",
    "#     X_fake = np.random.uniform(0, 1.0, size=[n_samples, latent_dim])\n",
    "    X_fake = np.random.normal(0,1.0,(n_samples,latent_dim))\n",
    "    # generate labels\n",
    "    labels_fake = np.hstack((np.zeros(int(n_samples/3)), np.ones(int(n_samples/3)), 2*np.ones(int(n_samples/3))))\n",
    "    np.random.shuffle(labels_fake)\n",
    "    return [reshape(X_fake), reshape(labels_fake)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    ecgs = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = reshape(np.random.uniform(0, 0.2, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.zeros((n_samples, 1))\n",
    "    return [ecgs, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "general-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images\n",
    "def save_plot(X, n, name):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(X[i, :, 0])\n",
    "    plt.savefig(name, dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "oriental-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], 1)\n",
    "    i_S = randint(0, y_S.shape[0], 1)\n",
    "    i_V = randint(0, y_V.shape[0], 1)\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rocky-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_plot(X_R, z_input, n_batch, name):\n",
    "    n = 3\n",
    "    Win = (n_batch//3)\n",
    "    # XX = np.vstack((X_R, z_input))\n",
    "    XX = np.vstack((X_R, z_input[0:n,:,:], z_input[Win:Win+n,:,:], z_input[2*Win:2*Win+n,:,:]))\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(n):\n",
    "        # subplot(R, C, Plot_No)\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.plot(XX[i,:,:])\n",
    "    for i in range(n, ((n+1)*(n+1))-(n+1)):\n",
    "        # define subplot\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(XX[i,:,:])\n",
    "    # plt.show()\n",
    "    plt.savefig(name, dpi=75)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cubic-shirt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0, 1/80, d1=0.36862, d2=0.69752 g=0.75239\n",
      ">0, 3/80, d1=0.36956, d2=0.45253 g=0.73932\n",
      ">0, 5/80, d1=0.36555, d2=0.38284 g=0.80587\n",
      ">0, 7/80, d1=0.34115, d2=0.36173 g=0.76966\n",
      ">0, 9/80, d1=0.35308, d2=0.37614 g=0.72965\n",
      ">0, 11/80, d1=0.35226, d2=0.36072 g=0.70216\n",
      ">0, 13/80, d1=0.33964, d2=0.35588 g=0.65455\n",
      ">0, 15/80, d1=0.32742, d2=0.36307 g=0.58004\n",
      ">0, 17/80, d1=0.34007, d2=0.34378 g=0.55585\n",
      ">0, 19/80, d1=0.32977, d2=0.34627 g=0.49626\n",
      ">0, 21/80, d1=0.36353, d2=0.34891 g=0.46837\n",
      ">0, 23/80, d1=0.35036, d2=0.37476 g=0.44798\n",
      ">0, 25/80, d1=0.32489, d2=0.34316 g=0.41608\n",
      ">0, 27/80, d1=0.34139, d2=0.35226 g=0.44176\n",
      ">0, 29/80, d1=0.32630, d2=0.35190 g=0.37773\n",
      ">0, 31/80, d1=0.33390, d2=0.35731 g=0.36594\n",
      ">0, 33/80, d1=0.36384, d2=0.34522 g=0.34120\n",
      ">0, 35/80, d1=0.34164, d2=0.33599 g=0.34846\n",
      ">0, 37/80, d1=0.32856, d2=0.34640 g=0.34656\n",
      ">0, 39/80, d1=0.32783, d2=0.33636 g=0.34188\n",
      ">0, 41/80, d1=0.33465, d2=0.34104 g=0.33752\n",
      ">0, 43/80, d1=0.32403, d2=0.34476 g=0.34060\n",
      ">0, 45/80, d1=0.33111, d2=0.34116 g=0.33592\n",
      ">0, 47/80, d1=0.35492, d2=0.34303 g=0.33013\n",
      ">0, 49/80, d1=0.35858, d2=0.34480 g=0.33073\n",
      ">0, 51/80, d1=0.34757, d2=0.34990 g=0.34374\n",
      ">0, 53/80, d1=0.33242, d2=0.31731 g=0.32151\n",
      ">0, 55/80, d1=0.32066, d2=0.34278 g=0.33601\n",
      ">0, 57/80, d1=0.32629, d2=0.33853 g=0.50391\n",
      ">0, 59/80, d1=0.33824, d2=0.34960 g=0.40026\n",
      ">0, 61/80, d1=0.33986, d2=0.33219 g=0.33521\n",
      ">0, 63/80, d1=0.33831, d2=0.34679 g=0.34210\n",
      ">0, 65/80, d1=0.34805, d2=0.32781 g=0.32993\n",
      ">0, 67/80, d1=0.33361, d2=0.33973 g=0.32197\n",
      ">0, 69/80, d1=0.34512, d2=0.34374 g=0.31979\n",
      ">0, 71/80, d1=0.33589, d2=0.32853 g=0.32768\n",
      ">0, 73/80, d1=0.34461, d2=0.34059 g=0.32985\n",
      ">0, 75/80, d1=0.32254, d2=0.35156 g=0.31457\n",
      ">0, 77/80, d1=0.30767, d2=0.32108 g=0.33188\n",
      ">0, 79/80, d1=0.33351, d2=0.33460 g=0.32945\n",
      ">1, 1/80, d1=0.34063, d2=0.33315 g=0.32038\n",
      ">1, 3/80, d1=0.31870, d2=0.33333 g=0.32916\n",
      ">1, 5/80, d1=0.32586, d2=0.32229 g=0.36186\n",
      ">1, 7/80, d1=0.33599, d2=0.34852 g=0.52192\n",
      ">1, 9/80, d1=0.34184, d2=0.35278 g=0.31522\n",
      ">1, 11/80, d1=0.33953, d2=0.33460 g=0.32439\n",
      ">1, 13/80, d1=0.33231, d2=0.34730 g=0.32348\n",
      ">1, 15/80, d1=0.34461, d2=0.32842 g=0.32473\n",
      ">1, 17/80, d1=0.29767, d2=0.33035 g=0.32842\n",
      ">1, 19/80, d1=0.34262, d2=0.33290 g=0.32352\n",
      ">1, 21/80, d1=0.31016, d2=0.33619 g=0.31531\n",
      ">1, 23/80, d1=0.33937, d2=0.33818 g=0.31753\n",
      ">1, 25/80, d1=0.33365, d2=0.33011 g=0.33038\n",
      ">1, 27/80, d1=0.35226, d2=0.35340 g=0.32338\n",
      ">1, 29/80, d1=0.33988, d2=0.34931 g=0.33605\n",
      ">1, 31/80, d1=0.33787, d2=0.32514 g=0.31669\n",
      ">1, 33/80, d1=0.33359, d2=0.34315 g=0.31604\n",
      ">1, 35/80, d1=0.33015, d2=0.33907 g=0.33740\n",
      ">1, 37/80, d1=0.34497, d2=0.30857 g=0.33328\n",
      ">1, 39/80, d1=0.31364, d2=0.33941 g=0.31869\n",
      ">1, 41/80, d1=0.33265, d2=0.32558 g=0.33317\n",
      ">1, 43/80, d1=0.33717, d2=0.33720 g=0.33030\n",
      ">1, 45/80, d1=0.39162, d2=0.32683 g=0.34395\n",
      ">1, 47/80, d1=0.35165, d2=0.33959 g=0.32384\n",
      ">1, 49/80, d1=0.32924, d2=0.31977 g=0.32721\n",
      ">1, 51/80, d1=0.31204, d2=0.34610 g=0.32534\n",
      ">1, 53/80, d1=0.32345, d2=0.35583 g=0.33908\n",
      ">1, 55/80, d1=0.32264, d2=0.32436 g=0.34299\n",
      ">1, 57/80, d1=0.32753, d2=0.33119 g=0.32818\n",
      ">1, 59/80, d1=0.33053, d2=0.34689 g=0.31947\n",
      ">1, 61/80, d1=0.32871, d2=0.35504 g=0.32156\n",
      ">1, 63/80, d1=0.34179, d2=0.33334 g=0.33236\n",
      ">1, 65/80, d1=0.33641, d2=0.32120 g=0.33635\n",
      ">1, 67/80, d1=0.35107, d2=0.32961 g=0.34017\n",
      ">1, 69/80, d1=0.31523, d2=0.31602 g=0.33223\n",
      ">1, 71/80, d1=0.34018, d2=0.33886 g=0.32618\n",
      ">1, 73/80, d1=0.35360, d2=0.31405 g=0.33966\n",
      ">1, 75/80, d1=0.33044, d2=0.32662 g=0.33350\n",
      ">1, 77/80, d1=0.33230, d2=0.31013 g=0.33061\n",
      ">1, 79/80, d1=0.34661, d2=0.33748 g=0.31460\n",
      ">2, 1/80, d1=0.33200, d2=0.32999 g=0.35323\n",
      ">2, 3/80, d1=0.32098, d2=0.33160 g=0.43406\n",
      ">2, 5/80, d1=0.36783, d2=0.32382 g=0.61995\n",
      ">2, 7/80, d1=0.32432, d2=0.33608 g=0.33997\n",
      ">2, 9/80, d1=0.33086, d2=0.32473 g=0.39655\n",
      ">2, 11/80, d1=0.33259, d2=0.35306 g=0.34659\n",
      ">2, 13/80, d1=0.31297, d2=0.35003 g=0.34421\n",
      ">2, 15/80, d1=0.33286, d2=0.32857 g=0.35870\n",
      ">2, 17/80, d1=0.32116, d2=0.34162 g=0.33375\n",
      ">2, 19/80, d1=0.33349, d2=0.34065 g=0.32792\n",
      ">2, 21/80, d1=0.31346, d2=0.31534 g=0.33923\n",
      ">2, 23/80, d1=0.31542, d2=0.35751 g=0.32804\n",
      ">2, 25/80, d1=0.36129, d2=0.33213 g=0.33151\n",
      ">2, 27/80, d1=0.33213, d2=0.33040 g=0.33244\n",
      ">2, 29/80, d1=0.34157, d2=0.33990 g=0.34729\n",
      ">2, 31/80, d1=0.33134, d2=0.34248 g=0.34543\n",
      ">2, 33/80, d1=0.33195, d2=0.34500 g=0.32976\n",
      ">2, 35/80, d1=0.36090, d2=0.32422 g=0.32730\n",
      ">2, 37/80, d1=0.32732, d2=0.32111 g=0.32876\n",
      ">2, 39/80, d1=0.33299, d2=0.33144 g=0.32241\n",
      ">2, 41/80, d1=0.30839, d2=0.34722 g=0.38721\n",
      ">2, 43/80, d1=0.32052, d2=0.36107 g=0.43425\n",
      ">2, 45/80, d1=0.35564, d2=0.33651 g=0.38752\n",
      ">2, 47/80, d1=0.33075, d2=0.34945 g=0.33907\n",
      ">2, 49/80, d1=0.33072, d2=0.35984 g=0.35192\n",
      ">2, 51/80, d1=0.35179, d2=0.33931 g=0.33869\n",
      ">2, 53/80, d1=0.32325, d2=0.32563 g=0.33904\n",
      ">2, 55/80, d1=0.32919, d2=0.33356 g=0.31772\n",
      ">2, 57/80, d1=0.34202, d2=0.34504 g=0.33313\n",
      ">2, 59/80, d1=0.32972, d2=0.33631 g=0.33408\n",
      ">2, 61/80, d1=0.32909, d2=0.34193 g=0.33566\n",
      ">2, 63/80, d1=0.34889, d2=0.35011 g=0.35297\n",
      ">2, 65/80, d1=0.32642, d2=0.34944 g=0.32772\n",
      ">2, 67/80, d1=0.32465, d2=0.34596 g=0.36082\n",
      ">2, 69/80, d1=0.31890, d2=0.34648 g=0.32086\n",
      ">2, 71/80, d1=0.36040, d2=0.36023 g=0.35965\n",
      ">2, 73/80, d1=0.34454, d2=0.32462 g=0.33250\n",
      ">2, 75/80, d1=0.38735, d2=0.33962 g=0.32775\n",
      ">2, 77/80, d1=0.34450, d2=0.34262 g=0.41836\n",
      ">2, 79/80, d1=0.34655, d2=0.34990 g=0.37116\n",
      ">3, 1/80, d1=0.34424, d2=0.36722 g=0.33361\n",
      ">3, 3/80, d1=0.31258, d2=0.33189 g=0.32917\n",
      ">3, 5/80, d1=0.34451, d2=0.31561 g=0.37990\n",
      ">3, 7/80, d1=0.35332, d2=0.31785 g=0.39972\n",
      ">3, 9/80, d1=0.30938, d2=0.33051 g=0.34600\n",
      ">3, 11/80, d1=0.33766, d2=0.32453 g=0.34940\n",
      ">3, 13/80, d1=0.32637, d2=0.33481 g=0.33876\n",
      ">3, 15/80, d1=0.33404, d2=0.35431 g=0.38978\n",
      ">3, 17/80, d1=0.35406, d2=0.34741 g=0.34747\n",
      ">3, 19/80, d1=0.32377, d2=0.32407 g=0.32247\n",
      ">3, 21/80, d1=0.31619, d2=0.31690 g=0.33094\n",
      ">3, 23/80, d1=0.34175, d2=0.33134 g=0.51251\n",
      ">3, 25/80, d1=0.33911, d2=0.35241 g=0.43979\n",
      ">3, 27/80, d1=0.32501, d2=0.34105 g=0.33276\n",
      ">3, 29/80, d1=0.30982, d2=0.32252 g=0.33625\n",
      ">3, 31/80, d1=0.32152, d2=0.35100 g=0.33629\n",
      ">3, 33/80, d1=0.33996, d2=0.31910 g=0.34433\n",
      ">3, 35/80, d1=0.32442, d2=0.38567 g=1.18414\n",
      ">3, 37/80, d1=0.34109, d2=0.34664 g=1.09900\n",
      ">3, 39/80, d1=0.30349, d2=0.34692 g=0.34717\n",
      ">3, 41/80, d1=0.34246, d2=0.37453 g=0.36299\n",
      ">3, 43/80, d1=0.31817, d2=0.33422 g=0.34296\n",
      ">3, 45/80, d1=0.33612, d2=0.32609 g=0.34130\n",
      ">3, 47/80, d1=0.32505, d2=0.32502 g=0.33191\n",
      ">3, 49/80, d1=0.33009, d2=0.36233 g=0.39323\n",
      ">3, 51/80, d1=0.33830, d2=0.46236 g=4.55786\n",
      ">3, 53/80, d1=0.36894, d2=0.33774 g=3.13422\n",
      ">3, 55/80, d1=0.31986, d2=0.36590 g=0.98350\n",
      ">3, 57/80, d1=0.34654, d2=0.33624 g=0.41249\n",
      ">3, 59/80, d1=0.32540, d2=0.33897 g=0.33765\n",
      ">3, 61/80, d1=0.33048, d2=0.35297 g=0.32836\n",
      ">3, 63/80, d1=0.33368, d2=0.32099 g=0.34000\n",
      ">3, 65/80, d1=0.33433, d2=0.31496 g=0.37209\n",
      ">3, 67/80, d1=0.33748, d2=0.34002 g=0.36232\n",
      ">3, 69/80, d1=0.32978, d2=0.32547 g=0.39573\n",
      ">3, 71/80, d1=0.34277, d2=0.32202 g=0.34246\n",
      ">3, 73/80, d1=0.32883, d2=0.33343 g=0.33895\n",
      ">3, 75/80, d1=0.33933, d2=0.34518 g=0.34472\n",
      ">3, 77/80, d1=0.33100, d2=0.34784 g=0.32865\n",
      ">3, 79/80, d1=0.33288, d2=0.35108 g=0.33938\n",
      ">4, 1/80, d1=0.31275, d2=0.32731 g=0.37516\n",
      ">4, 3/80, d1=0.32633, d2=0.32673 g=0.37687\n",
      ">4, 5/80, d1=0.32788, d2=0.32249 g=0.32348\n",
      ">4, 7/80, d1=0.31184, d2=0.34981 g=0.34085\n",
      ">4, 9/80, d1=0.32303, d2=0.33045 g=0.34263\n",
      ">4, 11/80, d1=0.33874, d2=0.34026 g=0.32529\n",
      ">4, 13/80, d1=0.32389, d2=0.31637 g=0.36291\n",
      ">4, 15/80, d1=0.33985, d2=0.34166 g=0.40496\n",
      ">4, 17/80, d1=0.33005, d2=0.33756 g=0.35023\n",
      ">4, 19/80, d1=0.33821, d2=0.34258 g=0.33443\n",
      ">4, 21/80, d1=0.33057, d2=0.32700 g=0.37318\n",
      ">4, 23/80, d1=0.32158, d2=0.35553 g=1.81780\n",
      ">4, 25/80, d1=0.33183, d2=0.34853 g=2.51575\n",
      ">4, 27/80, d1=0.33723, d2=0.34499 g=1.54824\n",
      ">4, 29/80, d1=0.31102, d2=0.32583 g=1.43831\n",
      ">4, 31/80, d1=0.31424, d2=0.31626 g=1.39633\n",
      ">4, 33/80, d1=0.32370, d2=0.32624 g=1.25925\n",
      ">4, 35/80, d1=0.31050, d2=0.33183 g=1.27949\n",
      ">4, 37/80, d1=0.35081, d2=0.33196 g=1.34983\n",
      ">4, 39/80, d1=0.32609, d2=0.33349 g=1.16567\n",
      ">4, 41/80, d1=0.32716, d2=0.35529 g=0.93723\n",
      ">4, 43/80, d1=0.32668, d2=0.34745 g=0.86166\n",
      ">4, 45/80, d1=0.32610, d2=0.32764 g=0.71810\n",
      ">4, 47/80, d1=0.31314, d2=0.34868 g=0.43653\n",
      ">4, 49/80, d1=0.33044, d2=0.34297 g=0.37549\n",
      ">4, 51/80, d1=0.32899, d2=0.33754 g=0.33859\n",
      ">4, 53/80, d1=0.33830, d2=0.31883 g=0.35434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4, 55/80, d1=0.31643, d2=0.33592 g=0.34939\n",
      ">4, 57/80, d1=0.32202, d2=0.35380 g=0.33405\n",
      ">4, 59/80, d1=0.32888, d2=0.31729 g=0.35299\n",
      ">4, 61/80, d1=0.33893, d2=0.33316 g=0.33905\n",
      ">4, 63/80, d1=0.31263, d2=0.34497 g=0.33035\n",
      ">4, 65/80, d1=0.33668, d2=0.33330 g=0.32106\n",
      ">4, 67/80, d1=0.33562, d2=0.35959 g=0.68625\n",
      ">4, 69/80, d1=0.31899, d2=0.31844 g=0.35359\n",
      ">4, 71/80, d1=0.33515, d2=0.35086 g=0.33540\n",
      ">4, 73/80, d1=0.34633, d2=0.34368 g=0.34519\n",
      ">4, 75/80, d1=0.35403, d2=0.37116 g=3.10318\n",
      ">4, 77/80, d1=0.35044, d2=0.32316 g=2.13748\n",
      ">4, 79/80, d1=0.34040, d2=0.34723 g=1.64416\n",
      ">5, 1/80, d1=0.33749, d2=0.34307 g=1.66255\n",
      ">5, 3/80, d1=0.32036, d2=0.33414 g=1.38169\n",
      ">5, 5/80, d1=0.34176, d2=0.36106 g=1.34881\n",
      ">5, 7/80, d1=0.33544, d2=0.34854 g=1.56775\n",
      ">5, 9/80, d1=0.33711, d2=0.33747 g=1.27036\n",
      ">5, 11/80, d1=0.33557, d2=0.33485 g=1.31801\n",
      ">5, 13/80, d1=0.32503, d2=0.34597 g=1.47014\n",
      ">5, 15/80, d1=0.33697, d2=0.33540 g=1.28561\n",
      ">5, 17/80, d1=0.31539, d2=0.32220 g=1.22854\n",
      ">5, 19/80, d1=0.34338, d2=0.33504 g=1.21402\n",
      ">5, 21/80, d1=0.32598, d2=0.32834 g=1.24544\n",
      ">5, 23/80, d1=0.31988, d2=0.34545 g=1.13245\n",
      ">5, 25/80, d1=0.32930, d2=0.32317 g=1.05817\n",
      ">5, 27/80, d1=0.33254, d2=0.31665 g=1.14572\n",
      ">5, 29/80, d1=0.33031, d2=0.32624 g=1.14973\n",
      ">5, 31/80, d1=0.31535, d2=0.33960 g=1.06214\n",
      ">5, 33/80, d1=0.33088, d2=0.33462 g=0.97588\n",
      ">5, 35/80, d1=0.33426, d2=0.32233 g=0.95047\n",
      ">5, 37/80, d1=0.32411, d2=0.32795 g=0.96542\n",
      ">5, 39/80, d1=0.31609, d2=0.33668 g=0.87159\n",
      ">5, 41/80, d1=0.32471, d2=0.33856 g=0.79735\n",
      ">5, 43/80, d1=0.31768, d2=0.33803 g=0.80267\n",
      ">5, 45/80, d1=0.32553, d2=0.32345 g=0.79067\n",
      ">5, 47/80, d1=0.31823, d2=0.33560 g=0.70350\n",
      ">5, 49/80, d1=0.33002, d2=0.32490 g=0.64891\n",
      ">5, 51/80, d1=0.32625, d2=0.34005 g=0.64748\n",
      ">5, 53/80, d1=0.33247, d2=0.33726 g=0.51762\n",
      ">5, 55/80, d1=0.33581, d2=0.31765 g=0.61280\n",
      ">5, 57/80, d1=0.32477, d2=0.32405 g=0.71711\n",
      ">5, 59/80, d1=0.33356, d2=0.33455 g=0.47442\n",
      ">5, 61/80, d1=0.34814, d2=0.32598 g=0.78243\n",
      ">5, 63/80, d1=0.32949, d2=0.34198 g=0.42549\n",
      ">5, 65/80, d1=0.33477, d2=0.33459 g=0.32714\n",
      ">5, 67/80, d1=0.40898, d2=0.47968 g=1.58371\n",
      ">5, 69/80, d1=0.39908, d2=0.33557 g=0.55348\n",
      ">5, 71/80, d1=0.32854, d2=0.35428 g=0.36694\n",
      ">5, 73/80, d1=0.33208, d2=0.32494 g=0.38064\n",
      ">5, 75/80, d1=0.32559, d2=0.32682 g=0.34115\n",
      ">5, 77/80, d1=0.31709, d2=0.34969 g=0.34222\n",
      ">5, 79/80, d1=0.30549, d2=0.34346 g=0.33005\n",
      ">6, 1/80, d1=0.31900, d2=0.33627 g=0.38181\n",
      ">6, 3/80, d1=0.33415, d2=0.34586 g=0.32146\n",
      ">6, 5/80, d1=0.32663, d2=0.32464 g=0.33992\n",
      ">6, 7/80, d1=0.32311, d2=0.34630 g=0.32381\n",
      ">6, 9/80, d1=0.34896, d2=0.36784 g=0.34164\n",
      ">6, 11/80, d1=0.32538, d2=0.36227 g=0.36388\n",
      ">6, 13/80, d1=0.31503, d2=0.31514 g=0.32504\n",
      ">6, 15/80, d1=0.33946, d2=0.32764 g=0.34239\n",
      ">6, 17/80, d1=0.33085, d2=0.34493 g=0.39733\n",
      ">6, 19/80, d1=0.33865, d2=0.34148 g=0.32973\n",
      ">6, 21/80, d1=0.30327, d2=0.34546 g=0.38152\n",
      ">6, 23/80, d1=0.35012, d2=0.33758 g=0.37871\n",
      ">6, 25/80, d1=0.32953, d2=0.36264 g=0.31102\n",
      ">6, 27/80, d1=0.34676, d2=0.35104 g=0.34805\n",
      ">6, 29/80, d1=0.33426, d2=0.34213 g=0.32762\n",
      ">6, 31/80, d1=0.32803, d2=0.31821 g=0.33466\n",
      ">6, 33/80, d1=0.32112, d2=0.34147 g=0.32612\n",
      ">6, 35/80, d1=0.34843, d2=0.34158 g=0.34422\n",
      ">6, 37/80, d1=0.33526, d2=0.32934 g=0.32116\n",
      ">6, 39/80, d1=0.32606, d2=0.33262 g=0.31854\n",
      ">6, 41/80, d1=0.33073, d2=0.31606 g=0.33017\n",
      ">6, 43/80, d1=0.31906, d2=0.32045 g=0.32835\n",
      ">6, 45/80, d1=0.34189, d2=0.33346 g=0.33715\n",
      ">6, 47/80, d1=0.33107, d2=0.33769 g=0.34735\n",
      ">6, 49/80, d1=0.35028, d2=0.34167 g=0.34292\n",
      ">6, 51/80, d1=0.33723, d2=0.33914 g=0.33778\n",
      ">6, 53/80, d1=0.33187, d2=0.34502 g=0.37718\n",
      ">6, 55/80, d1=0.31636, d2=0.33850 g=0.54889\n",
      ">6, 57/80, d1=0.32890, d2=0.37897 g=0.39433\n",
      ">6, 59/80, d1=0.35584, d2=0.38182 g=0.35869\n",
      ">6, 61/80, d1=0.34409, d2=0.37191 g=0.34661\n",
      ">6, 63/80, d1=0.32425, d2=0.34357 g=0.33957\n",
      ">6, 65/80, d1=0.31931, d2=0.30344 g=0.35837\n",
      ">6, 67/80, d1=0.32802, d2=0.35031 g=0.37975\n",
      ">6, 69/80, d1=0.34298, d2=0.35334 g=0.36476\n",
      ">6, 71/80, d1=0.32056, d2=0.32605 g=0.49326\n",
      ">6, 73/80, d1=0.32902, d2=0.33629 g=0.33728\n",
      ">6, 75/80, d1=0.33096, d2=0.32925 g=0.33584\n",
      ">6, 77/80, d1=0.31138, d2=0.34042 g=0.33916\n",
      ">6, 79/80, d1=0.33309, d2=0.33211 g=0.32712\n",
      ">7, 1/80, d1=0.32243, d2=0.32687 g=0.33058\n",
      ">7, 3/80, d1=0.33038, d2=0.32360 g=0.32130\n",
      ">7, 5/80, d1=0.32891, d2=0.32508 g=0.36817\n",
      ">7, 7/80, d1=0.32803, d2=0.34184 g=0.46761\n",
      ">7, 9/80, d1=0.34496, d2=0.33770 g=0.34375\n",
      ">7, 11/80, d1=0.34745, d2=0.34204 g=0.36538\n",
      ">7, 13/80, d1=0.34057, d2=0.34941 g=0.35500\n",
      ">7, 15/80, d1=0.31680, d2=0.33559 g=0.42484\n",
      ">7, 17/80, d1=0.30821, d2=0.33738 g=0.34460\n",
      ">7, 19/80, d1=0.31915, d2=0.39705 g=0.34636\n",
      ">7, 21/80, d1=0.33028, d2=0.33657 g=0.33369\n",
      ">7, 23/80, d1=0.32307, d2=0.33898 g=0.33864\n",
      ">7, 25/80, d1=0.32750, d2=0.36855 g=0.33543\n",
      ">7, 27/80, d1=0.34018, d2=0.40142 g=0.32336\n",
      ">7, 29/80, d1=0.32819, d2=0.35690 g=0.32758\n",
      ">7, 31/80, d1=0.32744, d2=0.31378 g=0.32867\n",
      ">7, 33/80, d1=0.32297, d2=0.32783 g=0.32293\n",
      ">7, 35/80, d1=0.32407, d2=0.33559 g=0.32284\n",
      ">7, 37/80, d1=0.33056, d2=0.34977 g=0.32818\n",
      ">7, 39/80, d1=0.32857, d2=0.38586 g=0.32725\n",
      ">7, 41/80, d1=0.32774, d2=0.38463 g=0.33974\n",
      ">7, 43/80, d1=0.32556, d2=0.36481 g=0.34398\n",
      ">7, 45/80, d1=0.33923, d2=0.32633 g=0.34755\n",
      ">7, 47/80, d1=0.31874, d2=0.32640 g=0.33484\n",
      ">7, 49/80, d1=0.33862, d2=0.33827 g=0.32670\n",
      ">7, 51/80, d1=0.32669, d2=0.35561 g=0.32513\n",
      ">7, 53/80, d1=0.33163, d2=0.34696 g=0.37414\n",
      ">7, 55/80, d1=0.31723, d2=0.36494 g=0.45420\n",
      ">7, 57/80, d1=0.31366, d2=0.35786 g=0.35590\n",
      ">7, 59/80, d1=0.32350, d2=0.34327 g=0.51830\n",
      ">7, 61/80, d1=0.30986, d2=0.38216 g=0.57327\n",
      ">7, 63/80, d1=0.32229, d2=0.35881 g=0.33494\n",
      ">7, 65/80, d1=0.30982, d2=0.32414 g=0.34921\n",
      ">7, 67/80, d1=0.32605, d2=0.34482 g=0.30689\n",
      ">7, 69/80, d1=0.34357, d2=0.34544 g=0.34565\n",
      ">7, 71/80, d1=0.31660, d2=0.34823 g=0.33381\n",
      ">7, 73/80, d1=0.32168, d2=0.33729 g=0.32907\n",
      ">7, 75/80, d1=0.32301, d2=0.34929 g=0.35585\n",
      ">7, 77/80, d1=0.33188, d2=0.32721 g=0.34368\n",
      ">7, 79/80, d1=0.32055, d2=0.32951 g=0.35735\n",
      ">8, 1/80, d1=0.32791, d2=0.34528 g=0.32099\n",
      ">8, 3/80, d1=0.32474, d2=0.34613 g=0.35122\n",
      ">8, 5/80, d1=0.31743, d2=0.32829 g=0.34401\n",
      ">8, 7/80, d1=0.34686, d2=0.34792 g=0.36300\n",
      ">8, 9/80, d1=0.33051, d2=0.33592 g=0.33966\n",
      ">8, 11/80, d1=0.32780, d2=0.32284 g=0.33152\n",
      ">8, 13/80, d1=0.32958, d2=0.33815 g=0.32963\n",
      ">8, 15/80, d1=0.34858, d2=0.36260 g=0.35317\n",
      ">8, 17/80, d1=0.31127, d2=0.34039 g=0.32849\n",
      ">8, 19/80, d1=0.34311, d2=0.34248 g=0.34422\n",
      ">8, 21/80, d1=0.30674, d2=0.35078 g=0.34319\n",
      ">8, 23/80, d1=0.30743, d2=0.32904 g=0.33868\n",
      ">8, 25/80, d1=0.33184, d2=0.31280 g=0.36349\n",
      ">8, 27/80, d1=0.33091, d2=0.35610 g=0.43825\n",
      ">8, 29/80, d1=0.33965, d2=0.32155 g=0.36664\n",
      ">8, 31/80, d1=0.32553, d2=0.37562 g=0.33223\n",
      ">8, 33/80, d1=0.32218, d2=0.38055 g=0.56069\n",
      ">8, 35/80, d1=0.32086, d2=0.33965 g=0.56571\n",
      ">8, 37/80, d1=0.31518, d2=0.32900 g=0.33712\n",
      ">8, 39/80, d1=0.34003, d2=0.31895 g=0.34149\n",
      ">8, 41/80, d1=0.30665, d2=0.33545 g=0.32730\n",
      ">8, 43/80, d1=0.33067, d2=0.35011 g=0.34134\n",
      ">8, 45/80, d1=0.32013, d2=0.33738 g=0.33535\n",
      ">8, 47/80, d1=0.33572, d2=0.31279 g=0.33239\n",
      ">8, 49/80, d1=0.32707, d2=0.34074 g=0.31614\n",
      ">8, 51/80, d1=0.30401, d2=0.36516 g=0.33237\n",
      ">8, 53/80, d1=0.33530, d2=0.36632 g=0.32416\n",
      ">8, 55/80, d1=0.33185, d2=0.32368 g=0.35702\n",
      ">8, 57/80, d1=0.32278, d2=0.33879 g=0.32950\n",
      ">8, 59/80, d1=0.33867, d2=0.32420 g=0.33596\n",
      ">8, 61/80, d1=0.31363, d2=0.33423 g=0.32608\n",
      ">8, 63/80, d1=0.34500, d2=0.34393 g=0.32306\n",
      ">8, 65/80, d1=0.31372, d2=0.34664 g=0.33857\n",
      ">8, 67/80, d1=0.33040, d2=0.33320 g=0.33557\n",
      ">8, 69/80, d1=0.31233, d2=0.34873 g=0.36171\n",
      ">8, 71/80, d1=0.33680, d2=0.32757 g=0.37450\n",
      ">8, 73/80, d1=0.33085, d2=0.33569 g=0.39591\n",
      ">8, 75/80, d1=0.31174, d2=0.34299 g=0.34237\n",
      ">8, 77/80, d1=0.31979, d2=0.32665 g=0.33235\n",
      ">8, 79/80, d1=0.33301, d2=0.32703 g=0.32936\n",
      ">9, 1/80, d1=0.32056, d2=0.31121 g=0.38906\n",
      ">9, 3/80, d1=0.31435, d2=0.35044 g=0.64440\n",
      ">9, 5/80, d1=0.31975, d2=0.32719 g=0.41931\n",
      ">9, 7/80, d1=0.32445, d2=0.33476 g=0.46364\n",
      ">9, 9/80, d1=0.33272, d2=0.31709 g=0.36320\n",
      ">9, 11/80, d1=0.31924, d2=0.33206 g=0.45409\n",
      ">9, 13/80, d1=0.32204, d2=0.33412 g=0.34954\n",
      ">9, 15/80, d1=0.32348, d2=0.37556 g=0.43890\n",
      ">9, 17/80, d1=0.33271, d2=0.30916 g=0.38839\n",
      ">9, 19/80, d1=0.32597, d2=0.35119 g=0.37267\n",
      ">9, 21/80, d1=0.33774, d2=0.34448 g=0.37729\n",
      ">9, 23/80, d1=0.32831, d2=0.33339 g=0.39730\n",
      ">9, 25/80, d1=0.34285, d2=0.31707 g=0.39952\n",
      ">9, 27/80, d1=0.33193, d2=0.32612 g=0.38969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">9, 29/80, d1=0.32400, d2=0.34766 g=0.40017\n",
      ">9, 31/80, d1=0.32998, d2=0.32939 g=0.39578\n",
      ">9, 33/80, d1=0.33579, d2=0.34743 g=0.48161\n",
      ">9, 35/80, d1=0.33419, d2=0.35506 g=0.34734\n",
      ">9, 37/80, d1=0.34312, d2=0.38467 g=0.70286\n",
      ">9, 39/80, d1=0.32628, d2=0.37032 g=0.55401\n",
      ">9, 41/80, d1=0.31994, d2=0.34839 g=0.41835\n",
      ">9, 43/80, d1=0.32501, d2=0.35023 g=0.43845\n",
      ">9, 45/80, d1=0.32179, d2=0.33309 g=0.39581\n",
      ">9, 47/80, d1=0.32009, d2=0.33211 g=0.41011\n",
      ">9, 49/80, d1=0.32344, d2=0.32705 g=0.46200\n",
      ">9, 51/80, d1=0.30822, d2=0.36697 g=0.59852\n",
      ">9, 53/80, d1=0.31394, d2=0.34031 g=0.38340\n",
      ">9, 55/80, d1=0.32191, d2=0.34408 g=0.35241\n",
      ">9, 57/80, d1=0.33180, d2=0.34953 g=0.36024\n",
      ">9, 59/80, d1=0.34447, d2=0.34803 g=0.35136\n",
      ">9, 61/80, d1=0.31139, d2=0.32852 g=0.37071\n",
      ">9, 63/80, d1=0.32635, d2=0.31325 g=0.40362\n",
      ">9, 65/80, d1=0.32093, d2=0.32424 g=0.43088\n",
      ">9, 67/80, d1=0.31900, d2=0.32857 g=0.36516\n",
      ">9, 69/80, d1=0.32748, d2=0.34482 g=0.39843\n",
      ">9, 71/80, d1=0.32144, d2=0.32553 g=0.38794\n",
      ">9, 73/80, d1=0.33545, d2=0.33389 g=0.39907\n",
      ">9, 75/80, d1=0.32871, d2=0.33246 g=0.39704\n",
      ">9, 77/80, d1=0.32078, d2=0.31210 g=0.43861\n",
      ">9, 79/80, d1=0.32340, d2=0.33476 g=0.39347\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 186\n",
    "# size of the data\n",
    "data = 186\n",
    "# classes\n",
    "classes = 3\n",
    "n=3\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "# multiples of three (three classes) (less thyan 24000)\n",
    "n_batch=300\n",
    "\n",
    "# create the discriminator\n",
    "d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "# create the generator\n",
    "g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "# create the gan\n",
    "gan_model = create_gan(d_model, g_model)\n",
    "\n",
    "folder_name = 'CGAN_BN_Sigmoid/'\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "plot_model(d_model, to_file=folder_name+'disc.pdf', show_shapes=True)\n",
    "plot_model(g_model, to_file=folder_name+'gen.pdf', show_shapes=True)\n",
    "plot_model(gan_model, to_file=folder_name+'gan.pdf', show_shapes=True)\n",
    "\n",
    "# load image data\n",
    "X_N, y_N, X_S, y_S, X_V, y_V = load_real_samples()\n",
    "# # train model\n",
    "# train(g_model, d_model, gan_model, dataset, latent_dim)\n",
    "\n",
    "bat_per_epo = int(y_S.shape[0] / n_batch)\n",
    "half_batch = int(n_batch / 2)\n",
    "\n",
    "# Loss Values\n",
    "G_L = np.infty\n",
    "plt.ioff()\n",
    "\n",
    "filename = folder_name + 'Plots'\n",
    "if not os.path.isdir(filename):\n",
    "    os.mkdir(filename)\n",
    "\n",
    "model_name = folder_name + 'Model/'\n",
    "if not os.path.isdir(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "f = open(folder_name + 'Loss.csv', 'w')\n",
    "f.write('d_loss1, d_loss2, g_loss \\n')\n",
    "f.close()\n",
    "\n",
    "f = open(folder_name + 'Stats.csv', 'w')\n",
    "for i in range(3):\n",
    "    for mtc in metric_to_calculate:\n",
    "        f.write(str(mtc)+'_'+str(i)+',')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# manually enumerate epochs\n",
    "for i in range(n_epochs):\n",
    "    # enumerate batches over the training set\n",
    "    for j in range(bat_per_epo):\n",
    "        \n",
    "        # get randomly selected 'real' samples\n",
    "        [X_real, labels_real], y_real = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, half_batch)\n",
    "        # update discriminator model weights\n",
    "        d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "        \n",
    "        # generate 'fake' examples\n",
    "        [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # update discriminator model weights\n",
    "        d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "        \n",
    "        # prepare points in latent space as input for the generator\n",
    "        [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = reshape(np.random.uniform(0.8, 1, n_batch))\n",
    "        # y_gan = ones((n_batch, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "        \n",
    "        if g_loss < G_L:\n",
    "            G_L = g_loss\n",
    "            g_model.save(model_name + str(i*1000 + j) + '_cgan_generator.h5')\n",
    "        \n",
    "        f = open(folder_name + 'Loss.csv', 'a')\n",
    "        f.write(str(d_loss1)+','+str(d_loss2)+','+str(g_loss)+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        # summarize loss on this batch\n",
    "        if (j+1)%2 == 0:\n",
    "            print('>%d, %d/%d, d1=%.5f, d2=%.5f g=%.5f' %(i, j, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "            name = filename+'/'+str(i*1000 + j)+'.jpg'\n",
    "            # generate ECGs\n",
    "            latent_points, _ = generate_latent_points(latent_dim, n_batch)\n",
    "            # specify labels\n",
    "            labels = np.hstack((np.zeros(n_batch//3), np.ones(n_batch//3), 2*np.ones(n_batch//3)))\n",
    "            # generate images\n",
    "            z_input  = g_model.predict([latent_points, labels])\n",
    "            X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "            save_new_plot(X_R, z_input, n_batch, name)\n",
    "            \n",
    "        if (j+1)%10 == 0:\n",
    "            [X, _], _ = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_batch)\n",
    "            evaluate(X, z_input, classes, metric_to_calculate, n_batch, folder_name, samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-algorithm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
