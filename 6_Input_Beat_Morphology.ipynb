{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "important-iraqi",
   "metadata": {},
   "source": [
    "# Working Version From Machinelearning mastery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separate-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SG Sigmoid in Generator \n",
    "# SL Soft Labels\n",
    "# GN Gaussian Noise (not uniform)\n",
    "# OHE One Hot Encoding\n",
    "# Replaced Concatenate with multiply\n",
    "\n",
    "# TODO\n",
    "# basic conditional gan\n",
    "# generate data\n",
    "# add and train a classifier use k fold also\n",
    "# condition me one hot encoding\n",
    "# generator k lie combined data and disc k lie train data.. coz testing me sara deke bias ho jaega\n",
    "# different loss functions for generator and discriminator\n",
    "# discriminator output shud be one hot encode with labels as n s or v and not 0 or 1 that is fake or real:\n",
    "# confusion here\n",
    "# disc property: should recognise fake and also if gen data is not of that class (so 2 things)\n",
    "# training k time jab random samples uthaenge tab sari classes k\n",
    "# equal no. of samples uthana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surprising-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import keras\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, multiply, Embedding, merge, Concatenate, Conv1D, BatchNormalization\n",
    "from keras.layers import Dense, Flatten, Multiply\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bronze-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(data_dim, beat_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(beat_dim,1))\n",
    "    D_in = Input(shape=[data_dim,1])\n",
    "    x = Concatenate()([D_in, in_label])\n",
    "    \n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*16, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[D_in, in_label], outputs=out)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# d_model = discriminator(data_dim=186, beat_dim=186)\n",
    "# plot_model(d_model, to_file='disc.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "northern-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import UpSampling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Add\n",
    "import tensorflow as tf\n",
    "\n",
    "def generator(noise_dim=186, beat_dim=186, out_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(beat_dim,1))\n",
    "    G_in = Input(shape=[noise_dim,1])\n",
    "    x = Concatenate()([G_in, in_label])\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*16, kernel_size=2, strides=2, padding='valid', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=1, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    out = Activation('sigmoid')(x)  # for tanh change here\n",
    "    model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "# g_model = generator(noise_dim=186, beat_dim=186, out_dim=186)\n",
    "# plot_model(g_model, to_file='gen.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "written-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(d_model, g_model):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_beat = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_beat])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_beat], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# gan_model = create_gan(d_model, g_model)\n",
    "# plot_model(gan_model, to_file='gan.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    X = np.load('Data/X.npy')\n",
    "    y = np.load('Data/y.npy')\n",
    "\n",
    "    # print (X.shape, y.shape)\n",
    "\n",
    "    X_N = X[y==0]\n",
    "    X_S = X[y==1]\n",
    "    X_V = X[y==2]\n",
    "\n",
    "    y_N = y[y==0]\n",
    "    y_S = y[y==1]\n",
    "    y_V = y[y==2]\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "\n",
    "    X_N=X_N.reshape(X_N.shape[0],X_N.shape[1],1)\n",
    "    X_S=X_S.reshape(X_S.shape[0],X_S.shape[1],1)\n",
    "    X_V=X_V.reshape(X_V.shape[0],X_V.shape[1],1)\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "    return X_N, y_N, X_S, y_S, X_V, y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_samples):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], int(n_samples/3))\n",
    "    i_S = randint(0, y_S.shape[0], int(n_samples/3))\n",
    "    i_V = randint(0, y_V.shape[0], int(n_samples/3))\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "#     labels = np.hstack((y_N[i_N], y_S[i_S], y_V[i_V]))\n",
    "#     labels = keras.utils.to_categorical(labels)\n",
    "    # print (labels.shape)\n",
    "    \n",
    "    # generate class labels\n",
    "    y = np.random.uniform(0.7, 1, n_samples)\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.ones((n_samples, 1))\n",
    "#     return [X, labels], y\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bound-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        return X\n",
    "    else:\n",
    "        if X.shape[-1] == 1:\n",
    "            return X\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            return X\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "# normal noise\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=3):\n",
    "    # generate points in the latent space\n",
    "#     X_fake = np.random.uniform(0, 1.0, size=[n_samples, latent_dim])\n",
    "    X_fake = np.random.normal(0,1.0,(n_samples,latent_dim))\n",
    "    return reshape(X_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict([z_input, z_input])\n",
    "    # create class labels\n",
    "    y = np.random.uniform(0, 0.3, n_samples)\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.zeros((n_samples, 1))\n",
    "    return images, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "general-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images\n",
    "def save_plot(X, n):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(X[i, :, 0])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "speaking-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], 1)\n",
    "    i_S = randint(0, y_S.shape[0], 1)\n",
    "    i_V = randint(0, y_V.shape[0], 1)\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    return X\n",
    "\n",
    "def save_new_plot(X, n, name):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(n-1):\n",
    "        plt.subplot(n+1, n-1, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.plot(X[i, :, 0])\n",
    "    for i in range(3, (n*n)-n):\n",
    "        # define subplot\n",
    "        plt.subplot(n+1, n-1, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(X[i, :, 0])\n",
    "    plt.savefig(name, dpi=50)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-shirt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 2/80, d1=0.48109, d2=0.66606 g=1.28314\n",
      ">1, 4/80, d1=0.44442, d2=0.52309 g=1.18656\n",
      ">1, 6/80, d1=0.43232, d2=0.46297 g=1.31544\n",
      ">1, 8/80, d1=0.44797, d2=0.46930 g=1.32830\n",
      ">1, 10/80, d1=0.43315, d2=0.46864 g=1.24781\n",
      ">1, 12/80, d1=0.44487, d2=0.44316 g=1.19401\n",
      ">1, 14/80, d1=0.44520, d2=0.45552 g=1.19821\n",
      ">1, 16/80, d1=0.45884, d2=0.44868 g=1.02776\n",
      ">1, 18/80, d1=0.44723, d2=0.45409 g=0.99277\n",
      ">1, 20/80, d1=0.43148, d2=0.46593 g=0.94243\n",
      ">1, 22/80, d1=0.43716, d2=0.46099 g=0.85718\n",
      ">1, 24/80, d1=0.40837, d2=0.45382 g=0.78570\n",
      ">1, 26/80, d1=0.42844, d2=0.46323 g=0.77018\n",
      ">1, 28/80, d1=0.42185, d2=0.44222 g=0.82962\n",
      ">1, 30/80, d1=0.44368, d2=0.43345 g=0.78568\n",
      ">1, 32/80, d1=0.44797, d2=0.44712 g=0.73341\n",
      ">1, 34/80, d1=0.46575, d2=0.46406 g=0.84015\n",
      ">1, 36/80, d1=0.46485, d2=0.42896 g=0.92891\n",
      ">1, 38/80, d1=0.45303, d2=0.43499 g=0.92315\n",
      ">1, 40/80, d1=0.45378, d2=0.43537 g=0.84038\n",
      ">1, 42/80, d1=0.44004, d2=0.42643 g=0.93808\n",
      ">1, 44/80, d1=0.46118, d2=0.42529 g=0.97209\n",
      ">1, 46/80, d1=0.44137, d2=0.42927 g=0.93243\n",
      ">1, 48/80, d1=0.43764, d2=0.44768 g=0.81165\n",
      ">1, 50/80, d1=0.40579, d2=0.44658 g=0.91701\n",
      ">1, 52/80, d1=0.44456, d2=0.44068 g=0.87132\n",
      ">1, 54/80, d1=0.42432, d2=0.45166 g=0.91997\n",
      ">1, 56/80, d1=0.46163, d2=0.42574 g=0.98873\n",
      ">1, 58/80, d1=0.49531, d2=0.43048 g=0.99161\n",
      ">1, 60/80, d1=0.46887, d2=0.45407 g=0.96750\n",
      ">1, 62/80, d1=0.42967, d2=0.45674 g=0.87354\n",
      ">1, 64/80, d1=0.42935, d2=0.46380 g=0.85764\n",
      ">1, 66/80, d1=0.44025, d2=0.43264 g=0.89491\n",
      ">1, 68/80, d1=0.41756, d2=0.44101 g=0.82763\n",
      ">1, 70/80, d1=0.44319, d2=0.43172 g=0.81009\n",
      ">1, 72/80, d1=0.41780, d2=0.43244 g=0.84754\n",
      ">1, 74/80, d1=0.43763, d2=0.43528 g=0.76050\n",
      ">1, 76/80, d1=0.47835, d2=0.47876 g=0.78653\n",
      ">1, 78/80, d1=0.49971, d2=0.45218 g=0.75120\n",
      ">1, 80/80, d1=0.42777, d2=0.42169 g=0.66886\n",
      ">2, 2/80, d1=0.46170, d2=0.43839 g=0.68368\n",
      ">2, 4/80, d1=0.44139, d2=0.44393 g=0.69332\n",
      ">2, 6/80, d1=0.42828, d2=0.41645 g=0.67128\n",
      ">2, 8/80, d1=0.41786, d2=0.44976 g=0.67719\n",
      ">2, 10/80, d1=0.39321, d2=0.41643 g=0.65960\n",
      ">2, 12/80, d1=0.43536, d2=0.45118 g=0.67045\n",
      ">2, 14/80, d1=0.42830, d2=0.44764 g=0.65810\n",
      ">2, 16/80, d1=0.43569, d2=0.44705 g=0.56966\n",
      ">2, 18/80, d1=0.40656, d2=0.44221 g=0.62528\n",
      ">2, 20/80, d1=0.40548, d2=0.43045 g=0.58795\n",
      ">2, 22/80, d1=0.43100, d2=0.44863 g=0.51812\n",
      ">2, 24/80, d1=0.44680, d2=0.43671 g=0.51610\n",
      ">2, 26/80, d1=0.46604, d2=0.44005 g=0.66801\n",
      ">2, 28/80, d1=0.45465, d2=0.42916 g=0.59123\n",
      ">2, 30/80, d1=0.50836, d2=0.42922 g=0.57525\n",
      ">2, 32/80, d1=0.45633, d2=0.42691 g=0.61295\n",
      ">2, 34/80, d1=0.48013, d2=0.43198 g=0.63823\n",
      ">2, 36/80, d1=0.45200, d2=0.41127 g=0.57379\n",
      ">2, 38/80, d1=0.43660, d2=0.42646 g=0.52925\n",
      ">2, 40/80, d1=0.44302, d2=0.43699 g=0.54564\n",
      ">2, 42/80, d1=0.40750, d2=0.42895 g=0.50068\n",
      ">2, 44/80, d1=0.43253, d2=0.43151 g=0.51136\n",
      ">2, 46/80, d1=0.41121, d2=0.43143 g=0.52107\n",
      ">2, 48/80, d1=0.43512, d2=0.42204 g=0.48478\n",
      ">2, 50/80, d1=0.43616, d2=0.43781 g=0.49844\n",
      ">2, 52/80, d1=0.40705, d2=0.40868 g=0.48802\n",
      ">2, 54/80, d1=0.40898, d2=0.43669 g=0.46962\n",
      ">2, 56/80, d1=0.41634, d2=0.44242 g=0.46991\n",
      ">2, 58/80, d1=0.43782, d2=0.43611 g=0.45545\n",
      ">2, 60/80, d1=0.43203, d2=0.43370 g=0.47528\n",
      ">2, 62/80, d1=0.42473, d2=0.42598 g=0.48691\n",
      ">2, 64/80, d1=0.42293, d2=0.42702 g=0.46684\n",
      ">2, 66/80, d1=0.46329, d2=0.40586 g=0.49250\n",
      ">2, 68/80, d1=0.45965, d2=0.43673 g=0.49151\n",
      ">2, 70/80, d1=0.42610, d2=0.43185 g=0.47165\n",
      ">2, 72/80, d1=0.43436, d2=0.43628 g=0.49757\n",
      ">2, 74/80, d1=0.41766, d2=0.42946 g=0.50540\n",
      ">2, 76/80, d1=0.43139, d2=0.44445 g=0.45294\n",
      ">2, 78/80, d1=0.43762, d2=0.43004 g=0.48721\n",
      ">2, 80/80, d1=0.43297, d2=0.42588 g=0.49724\n",
      ">3, 2/80, d1=0.43473, d2=0.45692 g=0.45651\n",
      ">3, 4/80, d1=0.42011, d2=0.42038 g=0.47920\n",
      ">3, 6/80, d1=0.44987, d2=0.44389 g=0.52579\n",
      ">3, 8/80, d1=0.40676, d2=0.42621 g=0.47065\n",
      ">3, 10/80, d1=0.44200, d2=0.42156 g=0.50136\n",
      ">3, 12/80, d1=0.42181, d2=0.40882 g=0.49248\n",
      ">3, 14/80, d1=0.43662, d2=0.43108 g=0.47554\n",
      ">3, 16/80, d1=0.42221, d2=0.45510 g=0.47786\n",
      ">3, 18/80, d1=0.43616, d2=0.42256 g=0.47526\n",
      ">3, 20/80, d1=0.44424, d2=0.44709 g=0.43443\n",
      ">3, 22/80, d1=0.45309, d2=0.43511 g=0.48627\n",
      ">3, 24/80, d1=0.44563, d2=0.44104 g=0.52236\n",
      ">3, 26/80, d1=0.44040, d2=0.43464 g=0.61926\n",
      ">3, 28/80, d1=0.46561, d2=0.42124 g=0.62419\n",
      ">3, 30/80, d1=0.44714, d2=0.45366 g=0.62735\n",
      ">3, 32/80, d1=0.42442, d2=0.43856 g=0.62389\n",
      ">3, 34/80, d1=0.44797, d2=0.44438 g=0.51203\n",
      ">3, 36/80, d1=0.41222, d2=0.45554 g=0.54956\n",
      ">3, 38/80, d1=0.45790, d2=0.43048 g=0.50247\n",
      ">3, 40/80, d1=0.45149, d2=0.43001 g=0.52207\n",
      ">3, 42/80, d1=0.42394, d2=0.45054 g=0.50026\n",
      ">3, 44/80, d1=0.42716, d2=0.43854 g=0.50096\n",
      ">3, 46/80, d1=0.41515, d2=0.43373 g=0.52356\n",
      ">3, 48/80, d1=0.41609, d2=0.43557 g=0.48238\n",
      ">3, 50/80, d1=0.42143, d2=0.41176 g=0.46201\n",
      ">3, 52/80, d1=0.44501, d2=0.42757 g=0.48463\n",
      ">3, 54/80, d1=0.44253, d2=0.42354 g=0.43394\n",
      ">3, 56/80, d1=0.42520, d2=0.42657 g=0.47828\n",
      ">3, 58/80, d1=0.43846, d2=0.43500 g=0.43680\n",
      ">3, 60/80, d1=0.43139, d2=0.43355 g=0.45425\n",
      ">3, 62/80, d1=0.41548, d2=0.41963 g=0.44806\n",
      ">3, 64/80, d1=0.44575, d2=0.42311 g=0.43485\n",
      ">3, 66/80, d1=0.40300, d2=0.41727 g=0.43938\n",
      ">3, 68/80, d1=0.42480, d2=0.44169 g=0.44281\n",
      ">3, 70/80, d1=0.45323, d2=0.43744 g=0.43680\n",
      ">3, 72/80, d1=0.44245, d2=0.40295 g=0.47191\n",
      ">3, 74/80, d1=0.44927, d2=0.42465 g=0.45132\n",
      ">3, 76/80, d1=0.43798, d2=0.45538 g=0.44058\n",
      ">3, 78/80, d1=0.41197, d2=0.45090 g=0.42964\n",
      ">3, 80/80, d1=0.40835, d2=0.41553 g=0.42393\n",
      ">4, 2/80, d1=0.44640, d2=0.43919 g=0.42303\n",
      ">4, 4/80, d1=0.41620, d2=0.43557 g=0.42061\n",
      ">4, 6/80, d1=0.43077, d2=0.45847 g=0.45844\n",
      ">4, 8/80, d1=0.45490, d2=0.43922 g=0.46230\n",
      ">4, 10/80, d1=0.43121, d2=0.41991 g=0.45503\n",
      ">4, 12/80, d1=0.41873, d2=0.41868 g=0.47430\n",
      ">4, 14/80, d1=0.42548, d2=0.44699 g=0.43637\n",
      ">4, 16/80, d1=0.40487, d2=0.42156 g=0.44588\n",
      ">4, 18/80, d1=0.39813, d2=0.44172 g=0.42545\n",
      ">4, 20/80, d1=0.44492, d2=0.44864 g=0.44016\n",
      ">4, 22/80, d1=0.42267, d2=0.45296 g=0.44019\n",
      ">4, 24/80, d1=0.41909, d2=0.42725 g=0.44099\n",
      ">4, 26/80, d1=0.42434, d2=0.41906 g=0.43413\n",
      ">4, 28/80, d1=0.43768, d2=0.42521 g=0.45081\n",
      ">4, 30/80, d1=0.42668, d2=0.41110 g=0.45816\n",
      ">4, 32/80, d1=0.42296, d2=0.42601 g=0.44620\n",
      ">4, 34/80, d1=0.44300, d2=0.45795 g=0.43756\n",
      ">4, 36/80, d1=0.41747, d2=0.42975 g=0.43209\n",
      ">4, 38/80, d1=0.44043, d2=0.42070 g=0.44793\n",
      ">4, 40/80, d1=0.44555, d2=0.41477 g=0.43829\n",
      ">4, 42/80, d1=0.43508, d2=0.42459 g=0.45433\n",
      ">4, 44/80, d1=0.41711, d2=0.42706 g=0.43490\n",
      ">4, 46/80, d1=0.42549, d2=0.40899 g=0.45419\n",
      ">4, 48/80, d1=0.43791, d2=0.41446 g=0.43532\n",
      ">4, 50/80, d1=0.39997, d2=0.43640 g=0.44035\n",
      ">4, 52/80, d1=0.41867, d2=0.42182 g=0.43057\n",
      ">4, 54/80, d1=0.42644, d2=0.43457 g=0.42640\n",
      ">4, 56/80, d1=0.43312, d2=0.42702 g=0.47146\n",
      ">4, 58/80, d1=0.42292, d2=0.42069 g=0.44335\n",
      ">4, 60/80, d1=0.43106, d2=0.44916 g=0.42935\n",
      ">4, 62/80, d1=0.42665, d2=0.42988 g=0.46343\n",
      ">4, 64/80, d1=0.43579, d2=0.40994 g=0.47678\n",
      ">4, 66/80, d1=0.42950, d2=0.44151 g=0.44641\n",
      ">4, 68/80, d1=0.43667, d2=0.42400 g=0.44561\n",
      ">4, 70/80, d1=0.43647, d2=0.41967 g=0.43934\n",
      ">4, 72/80, d1=0.45457, d2=0.42879 g=0.47214\n",
      ">4, 74/80, d1=0.45400, d2=0.43153 g=0.47820\n",
      ">4, 76/80, d1=0.44745, d2=0.45059 g=0.49104\n",
      ">4, 78/80, d1=0.47568, d2=0.44113 g=0.46275\n",
      ">4, 80/80, d1=0.46016, d2=0.43829 g=0.48224\n",
      ">5, 2/80, d1=0.44334, d2=0.44689 g=0.44984\n",
      ">5, 4/80, d1=0.42796, d2=0.42862 g=0.44179\n",
      ">5, 6/80, d1=0.42919, d2=0.41394 g=0.43943\n",
      ">5, 8/80, d1=0.44071, d2=0.43201 g=0.42508\n",
      ">5, 10/80, d1=0.40741, d2=0.42711 g=0.42371\n",
      ">5, 12/80, d1=0.42982, d2=0.44232 g=0.43654\n",
      ">5, 14/80, d1=0.41733, d2=0.40433 g=0.43993\n",
      ">5, 16/80, d1=0.40902, d2=0.43233 g=0.43643\n",
      ">5, 18/80, d1=0.43301, d2=0.45213 g=0.43872\n",
      ">5, 20/80, d1=0.43140, d2=0.42426 g=0.46333\n",
      ">5, 22/80, d1=0.42828, d2=0.43637 g=0.42316\n",
      ">5, 24/80, d1=0.42258, d2=0.42917 g=0.42800\n",
      ">5, 26/80, d1=0.41647, d2=0.41670 g=0.43089\n",
      ">5, 28/80, d1=0.43954, d2=0.42913 g=0.43238\n",
      ">5, 30/80, d1=0.42779, d2=0.44696 g=0.41186\n",
      ">5, 32/80, d1=0.42225, d2=0.43141 g=0.42073\n",
      ">5, 34/80, d1=0.44120, d2=0.41807 g=0.41732\n",
      ">5, 36/80, d1=0.44229, d2=0.42795 g=0.42601\n",
      ">5, 38/80, d1=0.42934, d2=0.44548 g=0.41774\n",
      ">5, 40/80, d1=0.43752, d2=0.42868 g=0.43876\n",
      ">5, 42/80, d1=0.42511, d2=0.43212 g=0.43378\n",
      ">5, 44/80, d1=0.42356, d2=0.42826 g=0.41436\n",
      ">5, 46/80, d1=0.41482, d2=0.40714 g=0.42845\n",
      ">5, 48/80, d1=0.43752, d2=0.42513 g=0.44187\n",
      ">5, 50/80, d1=0.43009, d2=0.42953 g=0.43442\n",
      ">5, 52/80, d1=0.43694, d2=0.41376 g=0.46004\n",
      ">5, 54/80, d1=0.44758, d2=0.42556 g=0.42704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5, 56/80, d1=0.45009, d2=0.43628 g=0.43223\n",
      ">5, 58/80, d1=0.44233, d2=0.43380 g=0.44757\n",
      ">5, 60/80, d1=0.43130, d2=0.43965 g=0.42732\n",
      ">5, 62/80, d1=0.43686, d2=0.43805 g=0.41004\n",
      ">5, 64/80, d1=0.41007, d2=0.43338 g=0.43518\n",
      ">5, 66/80, d1=0.44726, d2=0.42789 g=0.41891\n",
      ">5, 68/80, d1=0.47809, d2=0.43650 g=0.43919\n",
      ">5, 70/80, d1=0.41521, d2=0.44145 g=0.42709\n",
      ">5, 72/80, d1=0.41980, d2=0.39872 g=0.42773\n",
      ">5, 74/80, d1=0.40902, d2=0.43602 g=0.40938\n",
      ">5, 76/80, d1=0.41327, d2=0.46692 g=0.43778\n",
      ">5, 78/80, d1=0.43549, d2=0.42662 g=0.42480\n",
      ">5, 80/80, d1=0.41634, d2=0.43227 g=0.40849\n",
      ">6, 2/80, d1=0.41522, d2=0.43112 g=0.41583\n",
      ">6, 4/80, d1=0.41942, d2=0.43481 g=0.42664\n",
      ">6, 6/80, d1=0.41146, d2=0.43660 g=0.45652\n",
      ">6, 8/80, d1=0.43477, d2=0.43040 g=0.43404\n",
      ">6, 10/80, d1=0.41431, d2=0.40867 g=0.43038\n",
      ">6, 12/80, d1=0.42979, d2=0.44422 g=0.43775\n",
      ">6, 14/80, d1=0.42921, d2=0.41643 g=0.42197\n",
      ">6, 16/80, d1=0.42006, d2=0.42360 g=0.43918\n",
      ">6, 18/80, d1=0.43745, d2=0.45084 g=0.42845\n",
      ">6, 20/80, d1=0.43062, d2=0.43690 g=0.44013\n",
      ">6, 22/80, d1=0.43461, d2=0.45363 g=0.43306\n",
      ">6, 24/80, d1=0.43014, d2=0.43427 g=0.44037\n",
      ">6, 26/80, d1=0.41474, d2=0.42856 g=0.43242\n",
      ">6, 28/80, d1=0.43126, d2=0.44191 g=0.41878\n",
      ">6, 30/80, d1=0.43104, d2=0.42497 g=0.42461\n",
      ">6, 32/80, d1=0.42045, d2=0.43204 g=0.42589\n",
      ">6, 34/80, d1=0.43596, d2=0.43100 g=0.43704\n",
      ">6, 36/80, d1=0.42204, d2=0.43477 g=0.43013\n",
      ">6, 38/80, d1=0.41880, d2=0.44601 g=0.43291\n",
      ">6, 40/80, d1=0.43416, d2=0.44606 g=0.43485\n",
      ">6, 42/80, d1=0.42604, d2=0.43636 g=0.45705\n",
      ">6, 44/80, d1=0.43956, d2=0.43131 g=0.47448\n",
      ">6, 46/80, d1=0.40077, d2=0.42764 g=0.42884\n",
      ">6, 48/80, d1=0.42197, d2=0.42919 g=0.42114\n",
      ">6, 50/80, d1=0.43542, d2=0.41644 g=0.43078\n",
      ">6, 52/80, d1=0.41949, d2=0.42165 g=0.43153\n",
      ">6, 54/80, d1=0.43862, d2=0.44579 g=0.41461\n",
      ">6, 56/80, d1=0.40195, d2=0.41183 g=0.42090\n",
      ">6, 58/80, d1=0.45052, d2=0.44528 g=0.42423\n",
      ">6, 60/80, d1=0.41490, d2=0.43778 g=0.42407\n",
      ">6, 62/80, d1=0.42100, d2=0.39880 g=0.43391\n",
      ">6, 64/80, d1=0.46330, d2=0.41704 g=0.43263\n",
      ">6, 66/80, d1=0.44058, d2=0.43827 g=0.43763\n",
      ">6, 68/80, d1=0.43702, d2=0.42192 g=0.41242\n",
      ">6, 70/80, d1=0.44174, d2=0.41325 g=0.42672\n",
      ">6, 72/80, d1=0.42221, d2=0.44382 g=0.43099\n",
      ">6, 74/80, d1=0.41223, d2=0.41215 g=0.43348\n",
      ">6, 76/80, d1=0.42180, d2=0.44238 g=0.42673\n",
      ">6, 78/80, d1=0.42309, d2=0.44745 g=0.43216\n",
      ">6, 80/80, d1=0.43998, d2=0.43508 g=0.43032\n",
      ">7, 2/80, d1=0.42159, d2=0.43408 g=0.42705\n",
      ">7, 4/80, d1=0.43937, d2=0.41852 g=0.43521\n",
      ">7, 6/80, d1=0.41337, d2=0.39771 g=0.45787\n",
      ">7, 8/80, d1=0.42751, d2=0.44030 g=0.43688\n",
      ">7, 10/80, d1=0.41415, d2=0.42822 g=0.41921\n",
      ">7, 12/80, d1=0.43908, d2=0.42324 g=0.45423\n",
      ">7, 14/80, d1=0.41883, d2=0.41609 g=0.47389\n",
      ">7, 16/80, d1=0.41995, d2=0.43419 g=0.46416\n",
      ">7, 18/80, d1=0.43656, d2=0.44283 g=0.43239\n",
      ">7, 20/80, d1=0.42867, d2=0.42907 g=0.43620\n",
      ">7, 22/80, d1=0.42659, d2=0.41094 g=0.42709\n",
      ">7, 24/80, d1=0.44784, d2=0.40591 g=0.42003\n",
      ">7, 26/80, d1=0.40830, d2=0.43123 g=0.41701\n",
      ">7, 28/80, d1=0.41722, d2=0.43065 g=0.42459\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 186\n",
    "# size of the data\n",
    "data = 186\n",
    "# classes\n",
    "classes = 3\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "# multiples of three (three classes) (less thyan 24000)\n",
    "n_batch=300\n",
    "\n",
    "# samples to watch\n",
    "n=3\n",
    "\n",
    "# Loss Values\n",
    "D_L_1 = np.infty\n",
    "D_L_2 = np.infty\n",
    "G_L = np.infty\n",
    "\n",
    "# create the discriminator\n",
    "d_model = discriminator(data_dim=data)\n",
    "# d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "\n",
    "# create the generator\n",
    "g_model = generator(noise_dim=data, beat_dim=data, out_dim=data)\n",
    "# g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "\n",
    "# create the gan\n",
    "gan_model = create_gan(d_model, g_model)\n",
    "\n",
    "# load ECG data\n",
    "X_N, y_N, X_S, y_S, X_V, y_V = load_real_samples()\n",
    "temp_N = np.mean(X_N, axis=0)\n",
    "temp_S = np.mean(X_S, axis=0)\n",
    "temp_V = np.mean(X_V, axis=0)\n",
    "\n",
    "# # train model\n",
    "# train(g_model, d_model, gan_model, dataset, latent_dim)\n",
    "\n",
    "bat_per_epo = int(y_S.shape[0] / n_batch)\n",
    "half_batch = int(n_batch / 2)\n",
    "flag=0\n",
    "\n",
    "N = np.tile(temp_N,(1,int(half_batch/3)))\n",
    "S = np.tile(temp_S,(1,int(half_batch/3)))\n",
    "V = np.tile(temp_V,(1,int(half_batch/3)))\n",
    "final_labels = reshape(np.hstack((N,S,V)).T)\n",
    "\n",
    "final_labels1 = np.vstack((final_labels, final_labels))\n",
    "# print (final_labels.shape, final_labels1.shape)\n",
    "\n",
    "# losses = []\n",
    "plt.ioff()\n",
    "\n",
    "filename = 'Beat_Morphology_Label'\n",
    "# filename = 'Multiply_Tanh_OHE'\n",
    "\n",
    "if not os.path.isdir(filename):\n",
    "    os.mkdir(filename)\n",
    "\n",
    "f = open(filename + '_Loss.csv', 'w')\n",
    "f.write('d_loss1, d_loss2, g_loss \\n')\n",
    "f.close()\n",
    "\n",
    "# manually enumerate epochs\n",
    "for i in range(n_epochs):\n",
    "    # enumerate batches over the training set\n",
    "    for j in range(bat_per_epo):\n",
    "        \n",
    "        # get randomly selected 'real' samples\n",
    "        X_real, y_real = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, half_batch)\n",
    "        # print (X_real.shape, final_labels.shape, y_real.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss1, _ = d_model.train_on_batch([X_real, final_labels], y_real)\n",
    "        \n",
    "        # generate 'fake' examples\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # print (X_fake.shape, y_fake.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss2, _ = d_model.train_on_batch([X_fake, X_fake], y_fake)\n",
    "        \n",
    "        # prepare points in latent space as input for the generator\n",
    "        z_input = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = reshape(np.random.uniform(0.7, 1, n_batch))\n",
    "        # print (z_input.shape, y_gan.shape)\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch([z_input, final_labels1], y_gan)\n",
    "        \n",
    "        if (d_loss1 < D_L_1 and d_loss2 < D_L_2) or g_loss < G_L:\n",
    "            D_L_1 = d_loss1\n",
    "            D_L_2 = d_loss2\n",
    "            G_L = g_loss\n",
    "            g_model.save(filename + '_cgan_generator.h5')\n",
    "            \n",
    "            \n",
    "#         losses.append((d_loss1, d_loss2, g_loss))\n",
    "        f = open(filename + '_Loss.csv', 'a')\n",
    "        f.write(str(d_loss1)+','+str(d_loss2)+','+str(g_loss)+'\\n')\n",
    "        f.close()\n",
    "        \n",
    "        # summarize loss on this batch\n",
    "        if (j+1)%2 == 0:\n",
    "            print('>%d, %d/%d, d1=%.5f, d2=%.5f g=%.5f' %(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "#         if (j+1)%5 == 0:\n",
    "            name = filename + '/'+str(i*1000 + j)+'.jpg'\n",
    "            # generate images\n",
    "            latent_points = generate_latent_points(latent_dim, n*n)\n",
    "            # specify labels\n",
    "            X, y = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n*n)\n",
    "            # generate images\n",
    "            X  = g_model.predict([latent_points, X])\n",
    "            X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "            X = np.vstack((X_R, X))\n",
    "            save_new_plot(X, n+1, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-attendance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-violation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-mounting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from evaluation_metrics import *\n",
    "# metric_to_calculate = ['FID', 'MMD', 'DTW', 'ED', 'PC', 'KLD', 'RMSE', 'TWED']\n",
    "# f = open(data_dir+'Stats.csv', 'a')\n",
    "# f.write('Epoch, d_loss1, d_loss2, g_loss, ')\n",
    "# for i in range(len(label_dict)):\n",
    "#     for mtc in metric_to_calculate:\n",
    "#         f.write(str(mtc)+str(i)+',')\n",
    "# f.write('Time,\\n')\n",
    "# f.close()\n",
    "\n",
    "# d_loss1 = float(d_loss1.history['loss'][0])\n",
    "# d_loss2 = float(d_loss2.history['loss'][0])\n",
    "# g_loss = float(g_loss.history['loss'][0])\n",
    "\n",
    "# if i%checkpoint == 0:\n",
    "        \n",
    "#         f = open(data_dir+'Stats.csv', 'a')\n",
    "#         f.write(str(i+1)+','+str(d_loss1)+','+str(d_loss2)+','+str(g_loss)+',')\n",
    "#         save_model(model=G, data_dir=data_dir, type='G', epoch=i)\n",
    "#         save_model(model=D, data_dir=data_dir, type='D', epoch=i)\n",
    "#         save_model(model=GAN, data_dir=data_dir, type='GAN', epoch=i)\n",
    "        \n",
    "#         for k,metric in enumerate(label_dict.keys()):    \n",
    "#             temp_x = test_data[200*(k):200*(k+1),:-1]\n",
    "#             [z_input, labels_input] = generate_class_specific_latent_input(200, n_classes=n_classes, noise_dim=noise_dim, category=float(metric))\n",
    "#             z_input = G.predict([z_input, labels_input], verbose=verbose)\n",
    "\n",
    "#             for j in range(2):\n",
    "#                 plt.plot(z_input[j])\n",
    "#             plt.savefig(data_dir+str(i)+'_Label_'+str(metric)+'.png')\n",
    "#             plt.close()\n",
    "#             plt.clf()\n",
    "            \n",
    "#             results = evaluate(temp_x,z_input,metric_to_calculate)\n",
    "#             for r in results:\n",
    "#                 f.write(str(r)+',')\n",
    "            \n",
    "#         f.write(str(end-start)+'\\n')\n",
    "#         f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #     # save the generator model\n",
    "#     g_model.save('cgan_generator.h5')\n",
    "\n",
    "# callback = [EarlyStopping(monitor='val_AUC', mode='max', verbose=1, patience=Pat),\n",
    "#          ModelCheckpoint(filepath=str(twelve_lead_model_filename)+'_check_model.h5', \n",
    "#                          monitor='val_AUC', verbose=1, save_best_only=True, mode='max'),\n",
    "#          ReduceLROnPlateau(monitor='val_AUC', factor=0.5, patience=Pat//2, verbose=1, \n",
    "#                            mode='max', min_delta=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "# # model = parallel_NN(WINDOW_SIZE,INPUT_FEAT,OUTPUT_CLASS):\n",
    "# model = parallel_NN(Window, len(leads), snomed_classes.shape[0])\n",
    "\n",
    "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "#               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy', dtype=None, threshold=0.5),\n",
    "#                        tf.keras.metrics.Recall(name='Recall'),\n",
    "#                        tf.keras.metrics.Precision(name='Precision'),\n",
    "#                        tf.keras.metrics.AUC(num_thresholds=200,summation_method=\"interpolation\",\n",
    "#                                             name=\"AUC\",dtype=None,curve=\"ROC\",thresholds=None,\n",
    "#                                             multi_label=True,label_weights=None)])\n",
    "# history = model.fit(train_generator, steps_per_epoch=train_samples, epochs=EP, verbose=1,\n",
    "#                 validation_data=val_generator, validation_steps=val_samples, callbacks=callback)\n",
    "\n",
    "\n",
    "# history_name = output_directory + '/' + twelve_lead_filename\n",
    "# print (twelve_lead_model_filename, history_name)\n",
    "\n",
    "# save_model(twelve_lead_model_filename, model)\n",
    "# write_history(history_name, history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
