{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worst-potential",
   "metadata": {},
   "source": [
    "#### Sigmoid in Generator, Soft Labels, Gaussian Noise\n",
    "\n",
    "# TODO\n",
    "#### add and train a classifier use k fold also, generator k lie combined data and disc k lie train data.. coz testing me sara deke bias ho jaega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import keras\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, multiply, Embedding, merge, Concatenate, Conv1D, BatchNormalization\n",
    "from keras.layers import Dense, Flatten, Multiply, LSTM\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Add\n",
    "import tensorflow as tf\n",
    "from evaluation_metrics import *\n",
    "metric_to_calculate = ['FID', 'MMD', 'DTW', 'PC', 'RMSE', 'TWED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bronze-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(data_dim, beat_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(beat_dim,1))\n",
    "    D_in = Input(shape=[data_dim,1])\n",
    "    x = Concatenate()([D_in, in_label])\n",
    "    \n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(filters=32*16, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[D_in, in_label], outputs=out)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# d_model = discriminator(data_dim=186, beat_dim=186)\n",
    "# plot_model(d_model, to_file='Final/disc.pdf', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "northern-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim=186, beat_dim=186, out_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(beat_dim,1))\n",
    "    G_in = Input(shape=[noise_dim,1])\n",
    "    x = Concatenate()([G_in, in_label])\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*16, kernel_size=2, strides=2, padding='valid', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=1, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = LSTM(1, return_sequences=True)(x)\n",
    "#     x = LSTM(out_dim, return_sequences=False)(x)\n",
    "#     x = Reshape((out_dim,1))(x)\n",
    "    out = Activation('tanh')(x)  # for tanh change here\n",
    "    model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "# g_model = generator(noise_dim=186, beat_dim=186, out_dim=186)\n",
    "# plot_model(g_model, to_file='Temp/gen.pdf', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "written-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(d_model, g_model):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_beat = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_beat])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_beat], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# gan_model = create_gan(d_model, g_model)\n",
    "# plot_model(gan_model, to_file='Final/gan.pdf', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "important-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        return X\n",
    "    else:\n",
    "        if X.shape[-1] == 1:\n",
    "            return X\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    X = np.load('Data/X.npy')\n",
    "    y = np.load('Data/y.npy')\n",
    "\n",
    "    # print (X.shape, y.shape)\n",
    "\n",
    "    X_N = X[y==0]\n",
    "    X_S = X[y==1]\n",
    "    X_V = X[y==2]\n",
    "\n",
    "    y_N = y[y==0]\n",
    "    y_S = y[y==1]\n",
    "    y_V = y[y==2]\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "\n",
    "#     X_N=X_N.reshape(X_N.shape[0],X_N.shape[1],1)\n",
    "#     X_S=X_S.reshape(X_S.shape[0],X_S.shape[1],1)\n",
    "#     X_V=X_V.reshape(X_V.shape[0],X_V.shape[1],1)\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "    return reshape(X_N), y_N, reshape(X_S), y_S, reshape(X_V), y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_samples):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], int(n_samples/3))\n",
    "    i_S = randint(0, y_S.shape[0], int(n_samples/3))\n",
    "    i_V = randint(0, y_V.shape[0], int(n_samples/3))\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    labels = keras.utils.to_categorical(np.hstack((y_N[i_N], y_S[i_S], y_V[i_V])))\n",
    "    # print (labels.shape)\n",
    "    \n",
    "    # generate class labels\n",
    "    y = reshape(np.random.uniform(0.8, 1, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bound-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "# normal noise\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=3):\n",
    "    # generate points in the latent space\n",
    "#     X_fake = np.random.uniform(0, 1.0, size=[n_samples, latent_dim])\n",
    "    X_fake = np.random.normal(0,1.0,(n_samples,latent_dim))\n",
    "    # generate labels\n",
    "    labels_fake = np.hstack((np.zeros(int(n_samples/3)), np.ones(int(n_samples/3)), 2*np.ones(int(n_samples/3))))\n",
    "    np.random.shuffle(labels_fake)\n",
    "    return [reshape(X_fake), keras.utils.to_categorical(labels_fake)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    ecgs = generator.predict([z_input, z_input])\n",
    "    # create class labels\n",
    "    y = reshape(np.random.uniform(0, 0.2, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.zeros((n_samples, 1))\n",
    "    return [ecgs, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "general-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images\n",
    "def save_plot(X, n):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(X[i, :, 0])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funny-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], 1)\n",
    "    i_S = randint(0, y_S.shape[0], 1)\n",
    "    i_V = randint(0, y_V.shape[0], 1)\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "speaking-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_plot(X_R, z_input, n_batch, name):\n",
    "    n = 3\n",
    "    Win = (n_batch//3)\n",
    "    XX = np.vstack((X_R, z_input[0:n,:,:], z_input[Win:Win+n,:,:], z_input[2*Win:2*Win+n,:,:]))\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(n):\n",
    "        # subplot(R, C, Plot_No)\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.plot(XX[i,:,:])\n",
    "    for i in range(n, ((n+1)*(n+1))-(n+1)):\n",
    "        # define subplot\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(XX[i,:,:])\n",
    "    # plt.show()\n",
    "    plt.savefig(name, dpi=75)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cubic-shirt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0, 1/80, d1=0.34833, d2=0.94259 g=0.80824\n",
      ">0, 3/80, d1=0.38880, d2=0.42068 g=0.92011\n",
      ">0, 5/80, d1=0.35920, d2=0.35296 g=0.94834\n",
      ">0, 7/80, d1=0.34121, d2=0.37866 g=1.02340\n",
      ">0, 9/80, d1=0.32470, d2=0.37652 g=0.88986\n",
      ">0, 11/80, d1=0.35027, d2=0.43521 g=0.90005\n",
      ">0, 13/80, d1=0.34306, d2=0.40668 g=0.88467\n",
      ">0, 15/80, d1=0.33876, d2=0.46067 g=0.93234\n",
      ">0, 17/80, d1=0.35054, d2=0.36342 g=0.85052\n",
      ">0, 19/80, d1=0.34525, d2=0.32800 g=0.86523\n",
      ">0, 21/80, d1=0.34078, d2=0.34106 g=0.80832\n",
      ">0, 23/80, d1=0.32926, d2=0.33135 g=0.83447\n",
      ">0, 25/80, d1=0.33720, d2=0.35014 g=0.86140\n",
      ">0, 27/80, d1=0.35985, d2=0.34843 g=0.87350\n",
      ">0, 29/80, d1=0.36040, d2=0.33011 g=0.85652\n",
      ">0, 31/80, d1=0.33209, d2=0.35260 g=0.83378\n",
      ">0, 33/80, d1=0.33493, d2=0.34566 g=0.81906\n",
      ">0, 35/80, d1=0.33379, d2=0.35367 g=0.73197\n",
      ">0, 37/80, d1=0.35473, d2=0.33585 g=0.78836\n",
      ">0, 39/80, d1=0.34625, d2=0.32604 g=0.73971\n",
      ">0, 41/80, d1=0.32010, d2=0.32520 g=0.83308\n",
      ">0, 43/80, d1=0.32754, d2=0.33760 g=0.83749\n",
      ">0, 45/80, d1=0.33737, d2=0.34624 g=0.86750\n",
      ">0, 47/80, d1=0.34624, d2=0.33481 g=0.83222\n",
      ">0, 49/80, d1=0.32683, d2=0.33465 g=0.83804\n",
      ">0, 51/80, d1=0.32021, d2=0.32249 g=0.81479\n",
      ">0, 53/80, d1=0.33833, d2=0.34185 g=0.80241\n",
      ">0, 55/80, d1=0.31845, d2=0.35638 g=0.83860\n",
      ">0, 57/80, d1=0.33984, d2=0.34289 g=0.81024\n",
      ">0, 59/80, d1=0.32863, d2=0.35886 g=0.78561\n",
      ">0, 61/80, d1=0.33617, d2=0.34962 g=0.73158\n",
      ">0, 63/80, d1=0.34872, d2=0.33474 g=0.77724\n",
      ">0, 65/80, d1=0.33276, d2=0.32565 g=0.74178\n",
      ">0, 67/80, d1=0.35923, d2=0.32582 g=0.69690\n",
      ">0, 69/80, d1=0.33411, d2=0.33885 g=0.78417\n",
      ">0, 71/80, d1=0.34035, d2=0.32633 g=0.82475\n",
      ">0, 73/80, d1=0.33512, d2=0.32698 g=0.86632\n",
      ">0, 75/80, d1=0.32949, d2=0.33969 g=0.93304\n",
      ">0, 77/80, d1=0.33330, d2=0.32498 g=0.91083\n",
      ">0, 79/80, d1=0.34184, d2=0.36086 g=0.90708\n",
      ">1, 1/80, d1=0.35346, d2=0.33773 g=0.86756\n",
      ">1, 3/80, d1=0.32870, d2=0.33115 g=0.85972\n",
      ">1, 5/80, d1=0.34383, d2=0.33685 g=0.98726\n",
      ">1, 7/80, d1=0.35029, d2=0.34347 g=0.89132\n",
      ">1, 9/80, d1=0.34012, d2=0.33190 g=0.71335\n",
      ">1, 11/80, d1=0.34800, d2=0.33092 g=0.79219\n",
      ">1, 13/80, d1=0.34208, d2=0.33739 g=0.79533\n",
      ">1, 15/80, d1=0.33387, d2=0.32225 g=0.83206\n",
      ">1, 17/80, d1=0.34084, d2=0.34875 g=0.86466\n",
      ">1, 19/80, d1=0.33144, d2=0.33571 g=0.80385\n",
      ">1, 21/80, d1=0.32763, d2=0.35283 g=0.83782\n",
      ">1, 23/80, d1=0.34861, d2=0.34818 g=0.79252\n",
      ">1, 25/80, d1=0.34257, d2=0.33552 g=0.78934\n",
      ">1, 27/80, d1=0.33246, d2=0.32506 g=0.72767\n",
      ">1, 29/80, d1=0.33431, d2=0.32764 g=0.81729\n",
      ">1, 31/80, d1=0.34086, d2=0.33456 g=0.89668\n",
      ">1, 33/80, d1=0.31367, d2=0.33230 g=0.88507\n",
      ">1, 35/80, d1=0.33128, d2=0.35180 g=0.88159\n",
      ">1, 37/80, d1=0.36576, d2=0.34397 g=0.56515\n",
      ">1, 39/80, d1=0.31091, d2=0.32569 g=0.68730\n",
      ">1, 41/80, d1=0.32271, d2=0.34118 g=0.65922\n",
      ">1, 43/80, d1=0.34291, d2=0.34620 g=0.84352\n",
      ">1, 45/80, d1=0.34033, d2=0.32938 g=0.79083\n",
      ">1, 47/80, d1=0.33896, d2=0.34134 g=0.78277\n",
      ">1, 49/80, d1=0.33870, d2=0.33071 g=0.75012\n",
      ">1, 51/80, d1=0.33621, d2=0.32525 g=0.78871\n",
      ">1, 53/80, d1=0.33938, d2=0.34571 g=0.79255\n",
      ">1, 55/80, d1=0.31524, d2=0.32964 g=0.79510\n",
      ">1, 57/80, d1=0.32468, d2=0.35201 g=0.82834\n",
      ">1, 59/80, d1=0.34458, d2=0.33996 g=0.71179\n",
      ">1, 61/80, d1=0.33931, d2=0.32231 g=0.77055\n",
      ">1, 63/80, d1=0.32803, d2=0.33895 g=0.83841\n",
      ">1, 65/80, d1=0.33449, d2=0.33111 g=0.82743\n",
      ">1, 67/80, d1=0.33410, d2=0.34621 g=0.87362\n",
      ">1, 69/80, d1=0.32573, d2=0.34874 g=0.94621\n",
      ">1, 71/80, d1=0.34540, d2=0.33250 g=0.84642\n",
      ">1, 73/80, d1=0.32692, d2=0.33636 g=0.80041\n",
      ">1, 75/80, d1=0.33276, d2=0.32967 g=0.85927\n",
      ">1, 77/80, d1=0.32033, d2=0.33087 g=0.90749\n",
      ">1, 79/80, d1=0.32828, d2=0.33642 g=0.84775\n",
      ">2, 1/80, d1=0.33342, d2=0.32816 g=0.77820\n",
      ">2, 3/80, d1=0.32011, d2=0.34293 g=0.76715\n",
      ">2, 5/80, d1=0.32986, d2=0.33360 g=0.79508\n",
      ">2, 7/80, d1=0.33811, d2=0.33862 g=0.79946\n",
      ">2, 9/80, d1=0.35753, d2=0.33006 g=0.69514\n",
      ">2, 11/80, d1=0.35529, d2=0.32200 g=0.73031\n",
      ">2, 13/80, d1=0.33297, d2=0.33220 g=0.70488\n",
      ">2, 15/80, d1=0.31805, d2=0.34605 g=0.75623\n",
      ">2, 17/80, d1=0.34572, d2=0.34168 g=0.75266\n",
      ">2, 19/80, d1=0.34212, d2=0.31461 g=0.70842\n",
      ">2, 21/80, d1=0.32670, d2=0.33102 g=0.89495\n",
      ">2, 23/80, d1=0.32741, d2=0.30608 g=0.78855\n",
      ">2, 25/80, d1=0.32629, d2=0.33287 g=0.87843\n",
      ">2, 27/80, d1=0.34065, d2=0.32700 g=0.85616\n",
      ">2, 29/80, d1=0.35503, d2=0.32596 g=0.91367\n",
      ">2, 31/80, d1=0.40948, d2=0.34948 g=0.84728\n",
      ">2, 33/80, d1=0.33514, d2=0.32798 g=0.80573\n",
      ">2, 35/80, d1=0.33315, d2=0.35977 g=0.77173\n",
      ">2, 37/80, d1=0.32730, d2=0.32835 g=0.82307\n",
      ">2, 39/80, d1=0.33353, d2=0.32689 g=0.64979\n",
      ">2, 41/80, d1=0.33090, d2=0.33837 g=0.63434\n",
      ">2, 43/80, d1=0.34171, d2=0.32853 g=0.68774\n",
      ">2, 45/80, d1=0.36029, d2=0.33403 g=0.78050\n",
      ">2, 47/80, d1=0.34757, d2=0.34353 g=0.66026\n",
      ">2, 49/80, d1=0.32939, d2=0.32543 g=0.69841\n",
      ">2, 51/80, d1=0.32628, d2=0.32155 g=0.65224\n",
      ">2, 53/80, d1=0.33312, d2=0.31970 g=0.70564\n",
      ">2, 55/80, d1=0.33243, d2=0.34323 g=0.57452\n",
      ">2, 57/80, d1=0.32594, d2=0.34219 g=0.56103\n",
      ">2, 59/80, d1=0.31465, d2=0.32281 g=0.75406\n",
      ">2, 61/80, d1=0.32780, d2=0.33533 g=0.68316\n",
      ">2, 63/80, d1=0.31175, d2=0.34091 g=0.66018\n",
      ">2, 65/80, d1=0.34176, d2=0.33032 g=0.62954\n",
      ">2, 67/80, d1=0.32336, d2=0.34602 g=0.57765\n",
      ">2, 69/80, d1=0.34387, d2=0.33937 g=0.49881\n",
      ">2, 71/80, d1=0.34578, d2=0.31654 g=0.55569\n",
      ">2, 73/80, d1=0.32682, d2=0.33135 g=0.63101\n",
      ">2, 75/80, d1=0.34189, d2=0.34358 g=0.66457\n",
      ">2, 77/80, d1=0.33745, d2=0.34739 g=0.59155\n",
      ">2, 79/80, d1=0.33473, d2=0.33038 g=0.72419\n",
      ">3, 1/80, d1=0.33654, d2=0.32890 g=0.72071\n",
      ">3, 3/80, d1=0.31958, d2=0.32951 g=0.69242\n",
      ">3, 5/80, d1=0.33403, d2=0.31971 g=0.82144\n",
      ">3, 7/80, d1=0.35036, d2=0.32183 g=0.87372\n",
      ">3, 9/80, d1=0.33755, d2=0.32557 g=0.80620\n",
      ">3, 11/80, d1=0.33874, d2=0.33883 g=0.84320\n",
      ">3, 13/80, d1=0.35936, d2=0.32289 g=0.76202\n",
      ">3, 15/80, d1=0.34023, d2=0.32905 g=0.79972\n",
      ">3, 17/80, d1=0.33561, d2=0.33505 g=0.72221\n",
      ">3, 19/80, d1=0.32633, d2=0.34285 g=0.74641\n",
      ">3, 21/80, d1=0.34158, d2=0.31678 g=0.60851\n",
      ">3, 23/80, d1=0.34430, d2=0.32226 g=0.73010\n",
      ">3, 25/80, d1=0.32723, d2=0.33514 g=1.20517\n",
      ">3, 27/80, d1=0.31493, d2=0.33678 g=0.75728\n",
      ">3, 29/80, d1=0.34162, d2=0.32238 g=0.67817\n",
      ">3, 31/80, d1=0.33325, d2=0.32153 g=0.70834\n",
      ">3, 33/80, d1=0.34165, d2=0.31980 g=0.83737\n",
      ">3, 35/80, d1=0.33179, d2=0.32069 g=1.11367\n",
      ">3, 37/80, d1=0.32200, d2=0.33661 g=0.97590\n",
      ">3, 39/80, d1=0.33027, d2=0.32523 g=0.93106\n",
      ">3, 41/80, d1=0.34002, d2=0.32612 g=1.02040\n",
      ">3, 43/80, d1=0.32510, d2=0.33466 g=0.88527\n",
      ">3, 45/80, d1=0.35067, d2=0.34394 g=1.05815\n",
      ">3, 47/80, d1=0.35301, d2=0.33327 g=1.16412\n",
      ">3, 49/80, d1=0.34517, d2=0.34657 g=0.80486\n",
      ">3, 51/80, d1=0.32919, d2=0.32439 g=1.08800\n",
      ">3, 53/80, d1=0.31052, d2=0.32958 g=0.65420\n",
      ">3, 55/80, d1=0.32690, d2=0.30956 g=0.77207\n",
      ">3, 57/80, d1=0.33338, d2=0.33137 g=0.45176\n",
      ">3, 59/80, d1=0.32504, d2=0.32017 g=0.50742\n",
      ">3, 61/80, d1=0.32992, d2=0.33944 g=0.46502\n",
      ">3, 63/80, d1=0.34238, d2=0.34216 g=0.50666\n",
      ">3, 65/80, d1=0.33788, d2=0.33568 g=0.81516\n",
      ">3, 67/80, d1=0.32076, d2=0.33765 g=0.59226\n",
      ">3, 69/80, d1=0.34272, d2=0.34189 g=0.41313\n",
      ">3, 71/80, d1=0.32241, d2=0.33115 g=0.41040\n",
      ">3, 73/80, d1=0.32324, d2=0.30989 g=0.53592\n",
      ">3, 75/80, d1=0.30909, d2=0.33935 g=0.39270\n",
      ">3, 77/80, d1=0.31751, d2=0.34685 g=0.58392\n",
      ">3, 79/80, d1=0.33290, d2=0.33293 g=0.39596\n",
      ">4, 1/80, d1=0.33970, d2=0.34136 g=0.78829\n",
      ">4, 3/80, d1=0.33503, d2=0.31735 g=0.56611\n",
      ">4, 5/80, d1=0.33338, d2=0.33498 g=0.58256\n",
      ">4, 7/80, d1=0.32604, d2=0.30841 g=0.74622\n",
      ">4, 9/80, d1=0.31883, d2=0.33306 g=0.67528\n",
      ">4, 11/80, d1=0.33566, d2=0.34723 g=0.37903\n",
      ">4, 13/80, d1=0.32253, d2=0.32094 g=1.42733\n",
      ">4, 15/80, d1=0.34779, d2=0.33589 g=0.77940\n",
      ">4, 17/80, d1=0.33418, d2=0.33092 g=0.79901\n",
      ">4, 19/80, d1=0.34036, d2=0.35695 g=0.56783\n",
      ">4, 21/80, d1=0.32251, d2=0.35121 g=0.55112\n",
      ">4, 23/80, d1=0.33644, d2=0.34037 g=0.72464\n",
      ">4, 25/80, d1=0.33170, d2=0.34432 g=0.64908\n",
      ">4, 27/80, d1=0.31493, d2=0.34596 g=0.42981\n",
      ">4, 29/80, d1=0.33402, d2=0.32426 g=0.39095\n",
      ">4, 31/80, d1=0.34653, d2=0.32611 g=0.45470\n",
      ">4, 33/80, d1=0.36147, d2=0.33651 g=0.45332\n",
      ">4, 35/80, d1=0.32052, d2=0.35577 g=0.35241\n",
      ">4, 37/80, d1=0.32568, d2=0.32796 g=0.38086\n",
      ">4, 39/80, d1=0.32921, d2=0.34679 g=0.47531\n",
      ">4, 41/80, d1=0.33378, d2=0.33638 g=0.39891\n",
      ">4, 43/80, d1=0.36267, d2=0.34562 g=0.57798\n",
      ">4, 45/80, d1=0.34054, d2=0.33360 g=0.61665\n",
      ">4, 47/80, d1=0.33896, d2=0.32225 g=0.59688\n",
      ">4, 49/80, d1=0.33810, d2=0.34417 g=0.38650\n",
      ">4, 51/80, d1=0.33432, d2=0.32109 g=0.86607\n",
      ">4, 53/80, d1=0.33249, d2=0.32678 g=0.65450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4, 55/80, d1=0.30727, d2=0.33658 g=0.43342\n",
      ">4, 57/80, d1=0.33412, d2=0.33325 g=0.60157\n",
      ">4, 59/80, d1=0.31975, d2=0.33349 g=0.60090\n",
      ">4, 61/80, d1=0.32384, d2=0.33672 g=0.61738\n",
      ">4, 63/80, d1=0.32349, d2=0.32459 g=0.78633\n",
      ">4, 65/80, d1=0.32717, d2=0.31616 g=0.82971\n",
      ">4, 67/80, d1=0.32713, d2=0.32387 g=0.76938\n",
      ">4, 69/80, d1=0.33036, d2=0.32090 g=0.54139\n",
      ">4, 71/80, d1=0.32130, d2=0.33567 g=0.81547\n",
      ">4, 73/80, d1=0.32360, d2=0.30914 g=0.56077\n",
      ">4, 75/80, d1=0.32683, d2=0.33605 g=0.53162\n",
      ">4, 77/80, d1=0.32603, d2=0.33628 g=0.60094\n",
      ">4, 79/80, d1=0.33876, d2=0.31267 g=0.64244\n",
      ">5, 1/80, d1=0.32979, d2=0.33344 g=0.51007\n",
      ">5, 3/80, d1=0.30504, d2=0.32615 g=0.32624\n",
      ">5, 5/80, d1=0.32229, d2=0.32767 g=0.47045\n",
      ">5, 7/80, d1=0.32021, d2=0.32509 g=0.50715\n",
      ">5, 9/80, d1=0.33395, d2=0.31735 g=0.58268\n",
      ">5, 11/80, d1=0.33233, d2=0.34371 g=0.88649\n",
      ">5, 13/80, d1=0.32090, d2=0.34236 g=0.44625\n",
      ">5, 15/80, d1=0.34133, d2=0.32781 g=0.74740\n",
      ">5, 17/80, d1=0.31597, d2=0.32241 g=0.60066\n",
      ">5, 19/80, d1=0.31315, d2=0.34395 g=0.59806\n",
      ">5, 21/80, d1=0.33592, d2=0.32751 g=0.83540\n",
      ">5, 23/80, d1=0.32854, d2=0.34631 g=0.49186\n",
      ">5, 25/80, d1=0.32483, d2=0.33620 g=0.80609\n",
      ">5, 27/80, d1=0.33717, d2=0.33351 g=0.66396\n",
      ">5, 29/80, d1=0.33992, d2=0.35248 g=0.63279\n",
      ">5, 31/80, d1=0.32983, d2=0.31459 g=0.88981\n",
      ">5, 33/80, d1=0.32540, d2=0.32692 g=0.47999\n",
      ">5, 35/80, d1=0.33277, d2=0.32299 g=0.47255\n",
      ">5, 37/80, d1=0.31486, d2=0.33320 g=0.42830\n",
      ">5, 39/80, d1=0.33048, d2=0.33937 g=0.37099\n",
      ">5, 41/80, d1=0.32119, d2=0.33286 g=0.45571\n",
      ">5, 43/80, d1=0.32512, d2=0.34586 g=0.68161\n",
      ">5, 45/80, d1=0.33841, d2=0.33891 g=0.46663\n",
      ">5, 47/80, d1=0.31641, d2=0.33989 g=0.37870\n",
      ">5, 49/80, d1=0.32828, d2=0.33440 g=0.33701\n",
      ">5, 51/80, d1=0.32190, d2=0.31298 g=0.77611\n",
      ">5, 53/80, d1=0.32835, d2=0.33931 g=0.61736\n",
      ">5, 55/80, d1=0.32667, d2=0.33268 g=0.81469\n",
      ">5, 57/80, d1=0.32324, d2=0.33000 g=0.58405\n",
      ">5, 59/80, d1=0.32173, d2=0.32956 g=0.76768\n",
      ">5, 61/80, d1=0.33844, d2=0.33005 g=0.87317\n",
      ">5, 63/80, d1=0.34226, d2=0.33893 g=0.91795\n",
      ">5, 65/80, d1=0.31905, d2=0.33225 g=1.04347\n",
      ">5, 67/80, d1=0.32181, d2=0.33888 g=1.27423\n",
      ">5, 69/80, d1=0.34048, d2=0.33517 g=0.50421\n",
      ">5, 71/80, d1=0.35211, d2=0.33822 g=0.47051\n",
      ">5, 73/80, d1=0.33742, d2=0.35064 g=0.79782\n",
      ">5, 75/80, d1=0.32720, d2=0.33964 g=1.45962\n",
      ">5, 77/80, d1=0.33434, d2=0.33541 g=1.17489\n",
      ">5, 79/80, d1=0.32601, d2=0.33404 g=0.93320\n",
      ">6, 1/80, d1=0.31887, d2=0.34345 g=0.70523\n",
      ">6, 3/80, d1=0.33426, d2=0.33930 g=0.98376\n",
      ">6, 5/80, d1=0.32403, d2=0.31368 g=0.92298\n",
      ">6, 7/80, d1=0.32228, d2=0.31671 g=0.58876\n",
      ">6, 9/80, d1=0.32652, d2=0.33772 g=0.55766\n",
      ">6, 11/80, d1=0.32774, d2=0.34282 g=0.62373\n",
      ">6, 13/80, d1=0.32807, d2=0.32316 g=0.74694\n",
      ">6, 15/80, d1=0.32495, d2=0.33715 g=0.50888\n",
      ">6, 17/80, d1=0.32156, d2=0.32163 g=0.60097\n",
      ">6, 19/80, d1=0.32906, d2=0.33490 g=0.62687\n",
      ">6, 21/80, d1=0.32180, d2=0.32872 g=0.79458\n",
      ">6, 23/80, d1=0.31670, d2=0.33458 g=0.69520\n",
      ">6, 25/80, d1=0.35693, d2=0.33758 g=0.96973\n",
      ">6, 27/80, d1=0.34340, d2=0.32457 g=0.80353\n",
      ">6, 29/80, d1=0.32304, d2=0.33207 g=0.57027\n",
      ">6, 31/80, d1=0.33281, d2=0.34931 g=0.68147\n",
      ">6, 33/80, d1=0.31652, d2=0.35427 g=0.69495\n",
      ">6, 35/80, d1=0.33951, d2=0.31141 g=0.62025\n",
      ">6, 37/80, d1=0.34108, d2=0.32756 g=0.58755\n",
      ">6, 39/80, d1=0.32731, d2=0.33221 g=0.61232\n",
      ">6, 41/80, d1=0.32267, d2=0.34413 g=0.65182\n",
      ">6, 43/80, d1=0.31867, d2=0.32065 g=0.68544\n",
      ">6, 45/80, d1=0.32453, d2=0.32019 g=0.54375\n",
      ">6, 47/80, d1=0.33883, d2=0.34087 g=0.60558\n",
      ">6, 49/80, d1=0.33964, d2=0.31238 g=1.06343\n",
      ">6, 51/80, d1=0.34160, d2=0.35144 g=0.48089\n",
      ">6, 53/80, d1=0.34649, d2=0.33738 g=0.59239\n",
      ">6, 55/80, d1=0.31635, d2=0.32827 g=0.46942\n",
      ">6, 57/80, d1=0.32494, d2=0.32839 g=0.36722\n",
      ">6, 59/80, d1=0.33244, d2=0.32279 g=0.52042\n",
      ">6, 61/80, d1=0.34313, d2=0.33224 g=0.56990\n",
      ">6, 63/80, d1=0.34102, d2=0.33200 g=0.39793\n",
      ">6, 65/80, d1=0.29270, d2=0.31735 g=0.54470\n",
      ">6, 67/80, d1=0.33986, d2=0.35601 g=0.49257\n",
      ">6, 69/80, d1=0.31912, d2=0.31679 g=0.73193\n",
      ">6, 71/80, d1=0.33325, d2=0.34689 g=0.39096\n",
      ">6, 73/80, d1=0.31712, d2=0.32321 g=0.58446\n",
      ">6, 75/80, d1=0.32282, d2=0.32417 g=0.37931\n",
      ">6, 77/80, d1=0.33171, d2=0.31833 g=0.86818\n",
      ">6, 79/80, d1=0.31691, d2=0.35949 g=0.45756\n",
      ">7, 1/80, d1=0.34092, d2=0.33549 g=0.73065\n",
      ">7, 3/80, d1=0.33622, d2=0.32369 g=0.63303\n",
      ">7, 5/80, d1=0.32685, d2=0.33749 g=0.46015\n",
      ">7, 7/80, d1=0.34245, d2=0.33374 g=1.05558\n",
      ">7, 9/80, d1=0.35084, d2=0.34187 g=0.42354\n",
      ">7, 11/80, d1=0.33033, d2=0.33561 g=0.44494\n",
      ">7, 13/80, d1=0.34401, d2=0.33373 g=0.66384\n",
      ">7, 15/80, d1=0.34563, d2=0.34287 g=0.69659\n",
      ">7, 17/80, d1=0.33062, d2=0.32839 g=0.39065\n",
      ">7, 19/80, d1=0.33230, d2=0.31070 g=0.43483\n",
      ">7, 21/80, d1=0.34111, d2=0.32941 g=0.43330\n",
      ">7, 23/80, d1=0.31312, d2=0.34647 g=0.46291\n",
      ">7, 25/80, d1=0.33769, d2=0.34615 g=0.36234\n",
      ">7, 27/80, d1=0.33012, d2=0.34003 g=0.48952\n",
      ">7, 29/80, d1=0.31833, d2=0.31112 g=0.46617\n",
      ">7, 31/80, d1=0.34957, d2=0.33289 g=0.66361\n",
      ">7, 33/80, d1=0.32262, d2=0.33296 g=0.36226\n",
      ">7, 35/80, d1=0.33105, d2=0.35329 g=0.35845\n",
      ">7, 37/80, d1=0.33821, d2=0.32178 g=0.60947\n",
      ">7, 39/80, d1=0.31732, d2=0.33283 g=0.36163\n",
      ">7, 41/80, d1=0.32434, d2=0.33234 g=0.42502\n",
      ">7, 43/80, d1=0.32031, d2=0.33395 g=0.38794\n",
      ">7, 45/80, d1=0.34276, d2=0.30573 g=0.49128\n",
      ">7, 47/80, d1=0.32826, d2=0.33631 g=0.56917\n",
      ">7, 49/80, d1=0.34524, d2=0.33386 g=0.44323\n",
      ">7, 51/80, d1=0.34064, d2=0.35025 g=0.47838\n",
      ">7, 53/80, d1=0.33379, d2=0.31519 g=0.60674\n",
      ">7, 55/80, d1=0.33100, d2=0.32782 g=0.58281\n",
      ">7, 57/80, d1=0.31706, d2=0.34566 g=0.35521\n",
      ">7, 59/80, d1=0.32623, d2=0.31916 g=0.33561\n",
      ">7, 61/80, d1=0.33919, d2=0.31074 g=0.33071\n",
      ">7, 63/80, d1=0.34014, d2=0.33686 g=0.76093\n",
      ">7, 65/80, d1=0.32261, d2=0.31752 g=0.54032\n",
      ">7, 67/80, d1=0.34478, d2=0.33482 g=0.56551\n",
      ">7, 69/80, d1=0.31169, d2=0.32963 g=0.38472\n",
      ">7, 71/80, d1=0.30816, d2=0.32466 g=0.38213\n",
      ">7, 73/80, d1=0.33793, d2=0.33387 g=0.32802\n",
      ">7, 75/80, d1=0.33529, d2=0.31656 g=0.49450\n",
      ">7, 77/80, d1=0.33811, d2=0.32356 g=0.40864\n",
      ">7, 79/80, d1=0.33533, d2=0.32646 g=0.42695\n",
      ">8, 1/80, d1=0.34392, d2=0.33717 g=0.41327\n",
      ">8, 3/80, d1=0.34260, d2=0.32269 g=0.38797\n",
      ">8, 5/80, d1=0.31472, d2=0.33643 g=0.36375\n",
      ">8, 7/80, d1=0.32138, d2=0.33865 g=0.41539\n",
      ">8, 9/80, d1=0.32602, d2=0.34955 g=0.36574\n",
      ">8, 11/80, d1=0.32744, d2=0.31789 g=0.52545\n",
      ">8, 13/80, d1=0.33625, d2=0.32868 g=0.51951\n",
      ">8, 15/80, d1=0.32383, d2=0.34794 g=0.38033\n",
      ">8, 17/80, d1=0.34402, d2=0.43628 g=0.73971\n",
      ">8, 19/80, d1=0.43930, d2=0.37597 g=0.35600\n",
      ">8, 21/80, d1=0.31420, d2=0.32900 g=0.37638\n",
      ">8, 23/80, d1=0.32586, d2=0.31158 g=0.33303\n",
      ">8, 25/80, d1=0.30327, d2=0.33094 g=0.35771\n",
      ">8, 27/80, d1=0.31932, d2=0.33420 g=0.42753\n",
      ">8, 29/80, d1=0.33761, d2=0.35251 g=0.42015\n",
      ">8, 31/80, d1=0.34359, d2=0.33156 g=0.45284\n",
      ">8, 33/80, d1=0.33697, d2=0.34023 g=0.51303\n",
      ">8, 35/80, d1=0.31466, d2=0.31228 g=0.58618\n",
      ">8, 37/80, d1=0.32472, d2=0.33190 g=0.33677\n",
      ">8, 39/80, d1=0.33401, d2=0.34257 g=0.46158\n",
      ">8, 41/80, d1=0.31921, d2=0.31563 g=0.39728\n",
      ">8, 43/80, d1=0.31620, d2=0.30694 g=0.37135\n",
      ">8, 45/80, d1=0.33762, d2=0.32039 g=0.45249\n",
      ">8, 47/80, d1=0.32823, d2=0.31935 g=0.36480\n",
      ">8, 49/80, d1=0.31735, d2=0.32809 g=0.40047\n",
      ">8, 51/80, d1=0.32526, d2=0.33722 g=0.48245\n",
      ">8, 53/80, d1=0.33051, d2=0.34109 g=0.43608\n",
      ">8, 55/80, d1=0.32816, d2=0.34687 g=0.42191\n",
      ">8, 57/80, d1=0.31317, d2=0.32476 g=0.33862\n",
      ">8, 59/80, d1=0.32432, d2=0.31891 g=0.52097\n",
      ">8, 61/80, d1=0.33290, d2=0.32243 g=0.36660\n",
      ">8, 63/80, d1=0.32293, d2=0.33682 g=0.42515\n",
      ">8, 65/80, d1=0.31802, d2=0.32036 g=0.58360\n",
      ">8, 67/80, d1=0.33554, d2=0.31312 g=0.65467\n",
      ">8, 69/80, d1=0.34165, d2=0.34584 g=0.35491\n",
      ">8, 71/80, d1=0.33943, d2=0.33229 g=0.32099\n",
      ">8, 73/80, d1=0.32472, d2=0.35000 g=0.33845\n",
      ">8, 75/80, d1=0.32221, d2=0.33181 g=0.62286\n",
      ">8, 77/80, d1=0.31207, d2=0.34584 g=0.62997\n",
      ">8, 79/80, d1=0.32204, d2=0.34681 g=0.37245\n",
      ">9, 1/80, d1=0.33458, d2=0.32707 g=0.68698\n",
      ">9, 3/80, d1=0.33968, d2=0.33690 g=0.51422\n",
      ">9, 5/80, d1=0.33081, d2=0.33864 g=0.39793\n",
      ">9, 7/80, d1=0.30858, d2=0.33175 g=0.53161\n",
      ">9, 9/80, d1=0.33082, d2=0.33851 g=0.35166\n",
      ">9, 11/80, d1=0.34065, d2=0.32850 g=0.42662\n",
      ">9, 13/80, d1=0.33213, d2=0.32218 g=0.82508\n",
      ">9, 15/80, d1=0.32692, d2=0.33090 g=0.66009\n",
      ">9, 17/80, d1=0.33755, d2=0.31757 g=0.44319\n",
      ">9, 19/80, d1=0.33824, d2=0.33737 g=0.44051\n",
      ">9, 21/80, d1=0.32286, d2=0.33218 g=0.34651\n",
      ">9, 23/80, d1=0.31197, d2=0.32991 g=0.48875\n",
      ">9, 25/80, d1=0.33449, d2=0.34834 g=0.37656\n",
      ">9, 27/80, d1=0.33578, d2=0.32246 g=0.64851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">9, 29/80, d1=0.31363, d2=0.32482 g=0.35856\n",
      ">9, 31/80, d1=0.35407, d2=0.31800 g=0.76636\n",
      ">9, 33/80, d1=0.33855, d2=0.33306 g=0.41492\n",
      ">9, 35/80, d1=0.34765, d2=0.32508 g=0.61004\n",
      ">9, 37/80, d1=0.32796, d2=0.33535 g=0.53626\n",
      ">9, 39/80, d1=0.34840, d2=0.34269 g=0.60302\n",
      ">9, 41/80, d1=0.32591, d2=0.32805 g=0.75723\n",
      ">9, 43/80, d1=0.32587, d2=0.33146 g=0.48818\n",
      ">9, 45/80, d1=0.34293, d2=0.32036 g=0.44948\n",
      ">9, 47/80, d1=0.30963, d2=0.32929 g=0.52801\n",
      ">9, 49/80, d1=0.31895, d2=0.33014 g=0.63533\n",
      ">9, 51/80, d1=0.32004, d2=0.33150 g=0.57442\n",
      ">9, 53/80, d1=0.33917, d2=0.33113 g=0.82896\n",
      ">9, 55/80, d1=0.33953, d2=0.31341 g=0.88807\n",
      ">9, 57/80, d1=0.32905, d2=0.35318 g=0.38999\n",
      ">9, 59/80, d1=0.36236, d2=0.31763 g=0.98043\n",
      ">9, 61/80, d1=0.33191, d2=0.33249 g=0.54085\n",
      ">9, 63/80, d1=0.32733, d2=0.32178 g=0.52972\n",
      ">9, 65/80, d1=0.30911, d2=0.33512 g=0.44695\n",
      ">9, 67/80, d1=0.33176, d2=0.34767 g=0.50474\n",
      ">9, 69/80, d1=0.34171, d2=0.33935 g=0.66417\n",
      ">9, 71/80, d1=0.32087, d2=0.33090 g=0.47900\n",
      ">9, 73/80, d1=0.31374, d2=0.33335 g=0.43603\n",
      ">9, 75/80, d1=0.32334, d2=0.34491 g=0.69478\n",
      ">9, 77/80, d1=0.31601, d2=0.32041 g=0.43003\n",
      ">9, 79/80, d1=0.32222, d2=0.32514 g=0.51409\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 186\n",
    "# size of the data\n",
    "data = 186\n",
    "# classes\n",
    "classes = 3\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "# multiples of three (three classes) (less thyan 24000)\n",
    "n_batch=300\n",
    "\n",
    "# Loss Values\n",
    "D_L_1 = np.infty\n",
    "D_L_2 = np.infty\n",
    "G_L = np.infty\n",
    "\n",
    "# create the discriminator\n",
    "d_model = discriminator(data_dim=data)\n",
    "# d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "\n",
    "# create the generator\n",
    "g_model = generator(noise_dim=data, beat_dim=data, out_dim=data)\n",
    "# g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "\n",
    "# create the gan\n",
    "gan_model = create_gan(d_model, g_model)\n",
    "\n",
    "# folder_name = 'LSTM_RS_True_Tanh/'\n",
    "folder_name = 'LSTM_RS_True_Tanh_WO_BN/'\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "plot_model(d_model, to_file=folder_name+'disc.pdf', show_shapes=True)\n",
    "plot_model(g_model, to_file=folder_name+'gen.pdf', show_shapes=True)\n",
    "plot_model(gan_model, to_file=folder_name+'gan.pdf', show_shapes=True)\n",
    "\n",
    "\n",
    "# load image data\n",
    "X_N, y_N, X_S, y_S, X_V, y_V = load_real_samples()\n",
    "# # train model\n",
    "# train(g_model, d_model, gan_model, dataset, latent_dim)\n",
    "\n",
    "bat_per_epo = int(y_S.shape[0] / n_batch)\n",
    "half_batch = int(n_batch / 2)\n",
    "plt.ioff()\n",
    "\n",
    "filename = folder_name + 'Plots'\n",
    "if not os.path.isdir(filename):\n",
    "    os.mkdir(filename)\n",
    "\n",
    "model_name = folder_name + 'Model/'\n",
    "if not os.path.isdir(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "f = open(folder_name + 'Loss.csv', 'w')\n",
    "f.write('d_loss1, d_loss2, g_loss \\n')\n",
    "f.close()\n",
    "\n",
    "f = open(folder_name + 'Stats.csv', 'w')\n",
    "for i in range(3):\n",
    "    for mtc in metric_to_calculate:\n",
    "        f.write(str(mtc)+'_'+str(i)+',')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# manually enumerate epochs\n",
    "for i in range(n_epochs):\n",
    "    # enumerate batches over the training set\n",
    "    for j in range(bat_per_epo):\n",
    "        \n",
    "        # get randomly selected 'real' samples\n",
    "        [X_real, labels_real], y_real = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, half_batch)\n",
    "        # print (X_real.shape, labels_real.shape, y_real.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss1, _ = d_model.train_on_batch([X_real, X_real], y_real)\n",
    "        \n",
    "        # generate 'fake' examples\n",
    "        [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # print (X_fake.shape, labels.shape, y_fake.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss2, _ = d_model.train_on_batch([X_fake, X_fake], y_fake)\n",
    "        \n",
    "        # prepare points in latent space as input for the generator\n",
    "        [z_input, _] = generate_latent_points(latent_dim, n_batch)\n",
    "        [X, _], _ = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_batch)\n",
    "        # print (z_input.shape)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = reshape(np.random.uniform(0.8, 1, n_batch))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch([z_input, X], y_gan)\n",
    "        \n",
    "        if g_loss < G_L:\n",
    "            D_L_1 = d_loss1\n",
    "            D_L_2 = d_loss2\n",
    "            G_L = g_loss\n",
    "            g_model.save(model_name + str(i*1000 + j) + '_cgan_generator.h5')\n",
    "\n",
    "        f = open(folder_name + 'Loss.csv', 'a')\n",
    "        f.write(str(d_loss1)+','+str(d_loss2)+','+str(g_loss)+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        if (j+1)%2 == 0:\n",
    "            print('>%d, %d/%d, d1=%.5f, d2=%.5f g=%.5f' %(i, j, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "            name = filename+'/'+str(i*1000 + j)+'.jpg'\n",
    "            # generate ECGs\n",
    "            z_input  = g_model.predict([z_input, X])\n",
    "            X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "            save_new_plot(X_R, z_input, n_batch, name)\n",
    "            \n",
    "        if (j+1)%10 == 0:\n",
    "            evaluate(X, z_input, classes, metric_to_calculate, n_batch, folder_name, samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-welsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "innovative-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = filename + '/'+str(i*1000 + j)+'.jpg'\n",
    "# # generate images\n",
    "# latent_points, labels = generate_latent_points(latent_dim, n*n)\n",
    "# # specify labels\n",
    "# [X, labels], y = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n*n)\n",
    "# # generate images\n",
    "# X  = g_model.predict([latent_points, X])\n",
    "# X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "# X = np.vstack((X_R, X))\n",
    "# save_new_plot(X, n+1, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "animated-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(filename+'_Stats.csv', 'a')\n",
    "# for k,metric in enumerate(label_dict.keys()):    \n",
    "#     temp_x = test_data[200*(k):200*(k+1),:-1]\n",
    "#     [z_input, labels_input] = generate_class_specific_latent_input(200, n_classes=n_classes, noise_dim=noise_dim, category=float(metric))\n",
    "#     z_input = G.predict([z_input, labels_input], verbose=verbose)\n",
    "\n",
    "#     for j in range(2):\n",
    "#         plt.plot(z_input[j])\n",
    "#     plt.savefig(data_dir+str(i)+'_Label_'+str(metric)+'.png')\n",
    "#     plt.close()\n",
    "#     plt.clf()\n",
    "\n",
    "#     results = evaluate(temp_x,z_input,metric_to_calculate)\n",
    "#     for r in results:\n",
    "#         f.write(str(r)+',')\n",
    "\n",
    "# f.write('\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sapphire-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_model(model, data_dir, type='G', epoch=1):\n",
    "#     json_name = data_dir+str(epoch)+'_'+type+'.json'\n",
    "#     h5name = data_dir+str(epoch)+'_'+type+'.h5'\n",
    "#     # serialize model to JSON\n",
    "#     model_json = model.to_json()\n",
    "#     with open(json_name, \"w\") as json_file:\n",
    "#         json_file.write(model_json)\n",
    "#     # serialize weights to HDF5\n",
    "#     model.save_weights(h5name)\n",
    "#     # print(\"Saved model to disk\")\n",
    "#     del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-hearing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "painful-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model=G, data_dir=data_dir, type='G', epoch=i)\n",
    "# #     # save the generator model\n",
    "#     g_model.save('cgan_generator.h5')\n",
    "\n",
    "# callback = [EarlyStopping(monitor='val_AUC', mode='max', verbose=1, patience=Pat),\n",
    "#          ModelCheckpoint(filepath=str(twelve_lead_model_filename)+'_check_model.h5', \n",
    "#                          monitor='val_AUC', verbose=1, save_best_only=True, mode='max'),\n",
    "#          ReduceLROnPlateau(monitor='val_AUC', factor=0.5, patience=Pat//2, verbose=1, \n",
    "#                            mode='max', min_delta=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "# # model = parallel_NN(WINDOW_SIZE,INPUT_FEAT,OUTPUT_CLASS):\n",
    "# model = parallel_NN(Window, len(leads), snomed_classes.shape[0])\n",
    "\n",
    "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "#               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy', dtype=None, threshold=0.5),\n",
    "#                        tf.keras.metrics.Recall(name='Recall'),\n",
    "#                        tf.keras.metrics.Precision(name='Precision'),\n",
    "#                        tf.keras.metrics.AUC(num_thresholds=200,summation_method=\"interpolation\",\n",
    "#                                             name=\"AUC\",dtype=None,curve=\"ROC\",thresholds=None,\n",
    "#                                             multi_label=True,label_weights=None)])\n",
    "# history = model.fit(train_generator, steps_per_epoch=train_samples, epochs=EP, verbose=1,\n",
    "#                 validation_data=val_generator, validation_steps=val_samples, callbacks=callback)\n",
    "\n",
    "\n",
    "# history_name = output_directory + '/' + twelve_lead_filename\n",
    "# print (twelve_lead_model_filename, history_name)\n",
    "\n",
    "# save_model(twelve_lead_model_filename, model)\n",
    "# write_history(history_name, history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
