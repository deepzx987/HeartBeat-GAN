{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import keras\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, multiply, Embedding, merge, Concatenate, Conv1D, BatchNormalization\n",
    "from keras.layers import Dense, Flatten, Multiply\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Add\n",
    "import tensorflow as tf\n",
    "from evaluation_metrics import *\n",
    "from helper import *\n",
    "metric_to_calculate = ['FID', 'MMD', 'DTW', 'PC', 'RMSE', 'TWED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rising-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(data_dim=186, beat_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(beat_dim,1))\n",
    "    D_in = Input(shape=[data_dim,1])\n",
    "    inp1 = Concatenate()([D_in, in_label])\n",
    "\n",
    "    x = Conv1D(filters=48, kernel_size=19, padding='same', strides=4, kernel_initializer='he_normal')(inp1)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=15, padding='same', strides=3, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=80, kernel_size=11, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=96, kernel_size=9, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=112, kernel_size=7, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x1 = Conv1D(filters=48, kernel_size=9, padding='same', strides=4, kernel_initializer='he_normal')(inp1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=64, kernel_size=7, padding='same', strides=3, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=80, kernel_size=5, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=96, kernel_size=3, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=112, kernel_size=3, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = GlobalAveragePooling1D()(x1)\n",
    "\n",
    "    xx = concatenate([x,x1])\n",
    "\n",
    "    xx = Dense(100)(xx)\n",
    "    xx = Dense(100)(xx)\n",
    "\n",
    "    out = Dense(1, activation='sigmoid')(xx)\n",
    "\n",
    "    model = Model(inputs=[D_in, in_label], outputs=out)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "    # model.summary()\n",
    "\n",
    "# d_model = discriminator(data_dim=186, beat_dim=186)\n",
    "# plot_model(d_model, to_file='temp.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bronze-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def discriminator(data_dim, beat_dim=186):\n",
    "    \n",
    "#     in_label = Input(shape=(beat_dim,1))\n",
    "#     D_in = Input(shape=[data_dim,1])\n",
    "#     x = Concatenate()([D_in, in_label])\n",
    "    \n",
    "#     x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "#     x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "#     x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "#     x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "#     x = Conv1D(filters=32*16, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "#     x = Flatten()(x)\n",
    "#     out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "#     model = Model(inputs=[D_in, in_label], outputs=out)\n",
    "#     opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "#     loss = 'binary_crossentropy'\n",
    "#     model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# d_model = discriminator(data_dim=186, beat_dim=186)\n",
    "# plot_model(d_model, to_file='temp.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "northern-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim=186, beat_dim=186, out_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(beat_dim,1))\n",
    "    G_in = Input(shape=[noise_dim,1])\n",
    "    x = Concatenate()([G_in, in_label])\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*16, kernel_size=2, strides=2, padding='valid', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=1, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    out = Activation('tanh')(x)\n",
    "    model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "# g_model = generator(noise_dim=186, beat_dim=186, out_dim=186)\n",
    "# plot_model(g_model, to_file='temp.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "written-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(d_model, g_model):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_beat = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_beat])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_beat], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# gan_model = create_gan(d_model, g_model)\n",
    "# plot_model(gan_model, to_file='Final/gan.pdf', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "important-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        return X\n",
    "    else:\n",
    "        if X.shape[-1] == 1:\n",
    "            return X\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vocal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    X = np.load('Data/ForGAN/X.npy')\n",
    "    y = np.load('Data/ForGAN/y.npy')\n",
    "\n",
    "    # print (X.shape, y.shape)\n",
    "\n",
    "    X_N = X[y==0]\n",
    "    X_S = X[y==1]\n",
    "    X_V = X[y==2]\n",
    "\n",
    "    y_N = y[y==0]\n",
    "    y_S = y[y==1]\n",
    "    y_V = y[y==2]\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "\n",
    "#     X_N=X_N.reshape(X_N.shape[0],X_N.shape[1],1)\n",
    "#     X_S=X_S.reshape(X_S.shape[0],X_S.shape[1],1)\n",
    "#     X_V=X_V.reshape(X_V.shape[0],X_V.shape[1],1)\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "    return reshape(X_N), y_N, reshape(X_S), y_S, reshape(X_V), y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "certified-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_samples):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], int(n_samples/3))\n",
    "    i_S = randint(0, y_S.shape[0], int(n_samples/3))\n",
    "    i_V = randint(0, y_V.shape[0], int(n_samples/3))\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    labels = keras.utils.to_categorical(np.hstack((y_N[i_N], y_S[i_S], y_V[i_V])))\n",
    "    # print (labels.shape)\n",
    "    \n",
    "    # generate class labels\n",
    "    y = reshape(np.random.uniform(0.8, 1, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bound-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "# normal noise\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=3):\n",
    "    # generate points in the latent space\n",
    "#     X_fake = np.random.uniform(0, 1.0, size=[n_samples, latent_dim])\n",
    "    X_fake = np.random.normal(0,1.0,(n_samples,latent_dim))\n",
    "    # generate labels\n",
    "    labels_fake = np.hstack((np.zeros(int(n_samples/3)), np.ones(int(n_samples/3)), 2*np.ones(int(n_samples/3))))\n",
    "    np.random.shuffle(labels_fake)\n",
    "    return [reshape(X_fake), keras.utils.to_categorical(labels_fake)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "solar-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    ecgs = generator.predict([z_input, z_input])\n",
    "    # create class labels\n",
    "    y = reshape(np.random.uniform(0, 0.2, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.zeros((n_samples, 1))\n",
    "    return [ecgs, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "general-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images\n",
    "def save_plot(X, n):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(X[i, :, 0])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "communist-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], 1)\n",
    "    i_S = randint(0, y_S.shape[0], 1)\n",
    "    i_V = randint(0, y_V.shape[0], 1)\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "speaking-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_plot(X_R, z_input, n_batch, name):\n",
    "    n = 3\n",
    "    Win = (n_batch//3)\n",
    "    XX = np.vstack((X_R, z_input[0:n,:,:], z_input[Win:Win+n,:,:], z_input[2*Win:2*Win+n,:,:]))\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(n):\n",
    "        # subplot(R, C, Plot_No)\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.plot(XX[i,:,:])\n",
    "    for i in range(n, ((n+1)*(n+1))-(n+1)):\n",
    "        # define subplot\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(XX[i,:,:])\n",
    "    # plt.show()\n",
    "    plt.savefig(name, dpi=75)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cubic-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0, 1/80, d1=0.39617, d2=1.80103 g=0.40359\n",
      ">0, 3/80, d1=0.79925, d2=0.50633 g=1.29651\n",
      ">0, 5/80, d1=0.96453, d2=0.51815 g=1.04163\n",
      ">0, 7/80, d1=0.77493, d2=0.49567 g=0.80952\n",
      ">0, 9/80, d1=0.67120, d2=0.55769 g=0.87007\n",
      ">0, 11/80, d1=0.65577, d2=0.62309 g=0.84715\n",
      ">0, 13/80, d1=0.68882, d2=0.44463 g=0.82978\n",
      ">0, 15/80, d1=0.57219, d2=0.42002 g=0.67001\n",
      ">0, 17/80, d1=0.47481, d2=0.38789 g=0.52266\n",
      ">0, 19/80, d1=0.43770, d2=0.33595 g=0.44285\n",
      ">0, 21/80, d1=0.37830, d2=0.34881 g=0.37832\n",
      ">0, 23/80, d1=0.36960, d2=0.33832 g=0.36659\n",
      ">0, 25/80, d1=0.36433, d2=0.34456 g=0.34669\n",
      ">0, 27/80, d1=0.37553, d2=0.35140 g=0.35580\n",
      ">0, 29/80, d1=0.37154, d2=0.32324 g=0.33796\n",
      ">0, 31/80, d1=0.34247, d2=0.35116 g=0.33996\n",
      ">0, 33/80, d1=0.33684, d2=0.34329 g=0.34379\n",
      ">0, 35/80, d1=0.34480, d2=0.34291 g=0.34032\n",
      ">0, 37/80, d1=0.36926, d2=0.33459 g=0.33832\n",
      ">0, 39/80, d1=0.35686, d2=0.31628 g=0.34023\n",
      ">0, 41/80, d1=0.34208, d2=0.32282 g=0.34540\n",
      ">0, 43/80, d1=0.33676, d2=0.33466 g=0.33529\n",
      ">0, 45/80, d1=0.34283, d2=0.34480 g=0.33941\n",
      ">0, 47/80, d1=0.33631, d2=0.33862 g=0.34927\n",
      ">0, 49/80, d1=0.37717, d2=0.39024 g=0.45518\n",
      ">0, 51/80, d1=1.10083, d2=0.34553 g=1.45704\n",
      ">0, 53/80, d1=0.61841, d2=0.62262 g=0.84373\n",
      ">0, 55/80, d1=0.56047, d2=0.59743 g=1.03331\n",
      ">0, 57/80, d1=0.52152, d2=0.53363 g=0.84923\n",
      ">0, 59/80, d1=0.53298, d2=0.34946 g=0.52263\n",
      ">0, 61/80, d1=0.43615, d2=0.35133 g=0.44274\n",
      ">0, 63/80, d1=0.39635, d2=0.35308 g=0.38635\n",
      ">0, 65/80, d1=0.36336, d2=0.32537 g=0.35468\n",
      ">0, 67/80, d1=0.35927, d2=0.33352 g=0.35160\n",
      ">0, 69/80, d1=0.35370, d2=0.34794 g=0.34136\n",
      ">0, 71/80, d1=0.35470, d2=0.32212 g=0.33988\n",
      ">0, 73/80, d1=0.35453, d2=0.32686 g=0.34460\n",
      ">0, 75/80, d1=0.34002, d2=0.34123 g=0.34085\n",
      ">0, 77/80, d1=0.33820, d2=0.33542 g=0.34292\n",
      ">0, 79/80, d1=0.34130, d2=0.35844 g=0.33411\n",
      ">1, 1/80, d1=0.35969, d2=0.33937 g=0.34632\n",
      ">1, 3/80, d1=0.32585, d2=0.33548 g=0.34146\n",
      ">1, 5/80, d1=0.34863, d2=0.33749 g=0.33422\n",
      ">1, 7/80, d1=0.34848, d2=0.34631 g=0.35077\n",
      ">1, 9/80, d1=0.33823, d2=0.33822 g=0.33260\n",
      ">1, 11/80, d1=0.33783, d2=0.33423 g=0.34271\n",
      ">1, 13/80, d1=0.33949, d2=0.33842 g=0.34091\n",
      ">1, 15/80, d1=0.34503, d2=0.32687 g=0.34740\n",
      ">1, 17/80, d1=0.35004, d2=0.34852 g=0.33197\n",
      ">1, 19/80, d1=0.33867, d2=0.33467 g=0.32880\n",
      ">1, 21/80, d1=0.33399, d2=0.35355 g=0.33394\n",
      ">1, 23/80, d1=0.35403, d2=0.34591 g=0.33797\n",
      ">1, 25/80, d1=0.35134, d2=0.33086 g=0.34744\n",
      ">1, 27/80, d1=0.32919, d2=0.33068 g=0.32999\n",
      ">1, 29/80, d1=0.33442, d2=0.33534 g=0.33331\n",
      ">1, 31/80, d1=0.34791, d2=0.33110 g=0.34061\n",
      ">1, 33/80, d1=0.32050, d2=0.33564 g=0.32110\n",
      ">1, 35/80, d1=0.33011, d2=0.34484 g=0.33076\n",
      ">1, 37/80, d1=0.36581, d2=0.34036 g=0.33352\n",
      ">1, 39/80, d1=0.31359, d2=0.32877 g=0.33624\n",
      ">1, 41/80, d1=0.32339, d2=0.34108 g=0.32748\n",
      ">1, 43/80, d1=0.34037, d2=0.34804 g=0.31840\n",
      ">1, 45/80, d1=0.34563, d2=0.32588 g=0.34536\n",
      ">1, 47/80, d1=0.33554, d2=0.33854 g=0.33832\n",
      ">1, 49/80, d1=0.34136, d2=0.33530 g=0.33005\n",
      ">1, 51/80, d1=0.33466, d2=0.32432 g=0.32982\n",
      ">1, 53/80, d1=0.33434, d2=0.33541 g=0.33182\n",
      ">1, 55/80, d1=0.31877, d2=0.32636 g=0.34051\n",
      ">1, 57/80, d1=0.32366, d2=0.35816 g=0.32753\n",
      ">1, 59/80, d1=0.34445, d2=0.34226 g=0.32916\n",
      ">1, 61/80, d1=0.33434, d2=0.32569 g=0.34048\n",
      ">1, 63/80, d1=0.31671, d2=0.34081 g=0.33705\n",
      ">1, 65/80, d1=0.33808, d2=0.35247 g=0.71880\n",
      ">1, 67/80, d1=0.36105, d2=2.00243 g=0.84726\n",
      ">1, 69/80, d1=0.64497, d2=0.36107 g=5.25002\n",
      ">1, 71/80, d1=0.45549, d2=0.36596 g=1.50529\n",
      ">1, 73/80, d1=0.39524, d2=0.34302 g=0.50723\n",
      ">1, 75/80, d1=0.35463, d2=0.70043 g=1.49111\n",
      ">1, 77/80, d1=0.41637, d2=0.33578 g=0.59433\n",
      ">1, 79/80, d1=0.35198, d2=0.35310 g=0.39541\n",
      ">2, 1/80, d1=0.34792, d2=0.32492 g=0.34774\n",
      ">2, 3/80, d1=0.33039, d2=0.34879 g=0.33636\n",
      ">2, 5/80, d1=0.34215, d2=0.33546 g=0.33503\n",
      ">2, 7/80, d1=0.34938, d2=0.34191 g=0.32511\n",
      ">2, 9/80, d1=0.35678, d2=0.32818 g=0.34545\n",
      ">2, 11/80, d1=0.35421, d2=0.33019 g=0.33041\n",
      ">2, 13/80, d1=0.33384, d2=0.33899 g=0.32905\n",
      ">2, 15/80, d1=0.32820, d2=0.34925 g=0.32639\n",
      ">2, 17/80, d1=0.34379, d2=0.34532 g=0.34452\n",
      ">2, 19/80, d1=0.34517, d2=0.31504 g=0.33996\n",
      ">2, 21/80, d1=0.33204, d2=0.33061 g=0.34300\n",
      ">2, 23/80, d1=0.33082, d2=0.30393 g=0.33129\n",
      ">2, 25/80, d1=0.32966, d2=0.33014 g=0.33236\n",
      ">2, 27/80, d1=0.34552, d2=0.33202 g=0.33353\n",
      ">2, 29/80, d1=0.34414, d2=0.32530 g=0.34077\n",
      ">2, 31/80, d1=0.34403, d2=0.34991 g=0.32843\n",
      ">2, 33/80, d1=0.33422, d2=0.32998 g=0.34171\n",
      ">2, 35/80, d1=0.33456, d2=0.35219 g=0.33001\n",
      ">2, 37/80, d1=0.33423, d2=0.32880 g=0.32820\n",
      ">2, 39/80, d1=0.33697, d2=0.33197 g=0.33066\n",
      ">2, 41/80, d1=0.33228, d2=0.33684 g=0.32463\n",
      ">2, 43/80, d1=0.34402, d2=0.32363 g=0.33223\n",
      ">2, 45/80, d1=0.34824, d2=0.33154 g=0.33498\n",
      ">2, 47/80, d1=0.34142, d2=0.34836 g=0.33264\n",
      ">2, 49/80, d1=0.32590, d2=0.33099 g=0.33215\n",
      ">2, 51/80, d1=0.32710, d2=0.32243 g=0.33303\n",
      ">2, 53/80, d1=0.33845, d2=0.31818 g=0.33505\n",
      ">2, 55/80, d1=0.32847, d2=0.34235 g=0.32783\n",
      ">2, 57/80, d1=0.31562, d2=0.34681 g=0.32449\n",
      ">2, 59/80, d1=0.31682, d2=0.32610 g=0.32951\n",
      ">2, 61/80, d1=0.33384, d2=0.33268 g=0.33151\n",
      ">2, 63/80, d1=0.31741, d2=0.33880 g=0.33622\n",
      ">2, 65/80, d1=0.34587, d2=0.33483 g=0.33470\n",
      ">2, 67/80, d1=0.32513, d2=0.34191 g=0.32170\n",
      ">2, 69/80, d1=0.33927, d2=0.34122 g=0.31701\n",
      ">2, 71/80, d1=0.34503, d2=0.31787 g=0.33648\n",
      ">2, 73/80, d1=0.32324, d2=0.32606 g=0.34032\n",
      ">2, 75/80, d1=0.34264, d2=0.33793 g=0.32810\n",
      ">2, 77/80, d1=0.33386, d2=0.35074 g=0.31900\n",
      ">2, 79/80, d1=0.33514, d2=0.32833 g=0.33507\n",
      ">3, 1/80, d1=0.33200, d2=0.32842 g=0.31981\n",
      ">3, 3/80, d1=0.31815, d2=0.32370 g=0.33499\n",
      ">3, 5/80, d1=0.32968, d2=0.32115 g=0.32352\n",
      ">3, 7/80, d1=0.33926, d2=0.31669 g=0.31649\n",
      ">3, 9/80, d1=0.34167, d2=0.32028 g=0.33129\n",
      ">3, 11/80, d1=0.33178, d2=0.33439 g=0.33178\n",
      ">3, 13/80, d1=0.34775, d2=0.32139 g=0.32711\n",
      ">3, 15/80, d1=0.33348, d2=0.32912 g=0.31292\n",
      ">3, 17/80, d1=0.32726, d2=0.33057 g=0.33478\n",
      ">3, 19/80, d1=0.33025, d2=0.33863 g=0.33337\n",
      ">3, 21/80, d1=0.33676, d2=0.31278 g=0.32982\n",
      ">3, 23/80, d1=0.34492, d2=0.32048 g=0.33638\n",
      ">3, 25/80, d1=0.32860, d2=0.32920 g=0.33183\n",
      ">3, 27/80, d1=0.32150, d2=0.33244 g=0.34213\n",
      ">3, 29/80, d1=0.33749, d2=0.32064 g=0.36497\n",
      ">3, 31/80, d1=0.33383, d2=0.31867 g=0.35027\n",
      ">3, 33/80, d1=0.34339, d2=0.31436 g=0.32173\n",
      ">3, 35/80, d1=0.32508, d2=0.31951 g=0.38067\n",
      ">3, 37/80, d1=0.32479, d2=0.33393 g=0.35204\n",
      ">3, 39/80, d1=0.33139, d2=0.32167 g=0.36453\n",
      ">3, 41/80, d1=0.34111, d2=0.32311 g=0.34874\n",
      ">3, 43/80, d1=0.32424, d2=0.32893 g=0.34737\n",
      ">3, 45/80, d1=0.34464, d2=0.34334 g=0.31626\n",
      ">3, 47/80, d1=0.34622, d2=0.32633 g=0.34120\n",
      ">3, 49/80, d1=0.33387, d2=0.34562 g=0.33004\n",
      ">3, 51/80, d1=0.32506, d2=0.32546 g=0.33856\n",
      ">3, 53/80, d1=0.31341, d2=0.32539 g=0.34314\n",
      ">3, 55/80, d1=0.32744, d2=0.30394 g=0.34126\n",
      ">3, 57/80, d1=0.33238, d2=0.32850 g=0.32245\n",
      ">3, 59/80, d1=0.32704, d2=0.31593 g=0.32448\n",
      ">3, 61/80, d1=0.33161, d2=0.33686 g=0.33060\n",
      ">3, 63/80, d1=0.34370, d2=0.33969 g=0.33150\n",
      ">3, 65/80, d1=0.34229, d2=0.32997 g=0.32111\n",
      ">3, 67/80, d1=0.32493, d2=0.33667 g=0.32208\n",
      ">3, 69/80, d1=0.34077, d2=0.33623 g=0.32456\n",
      ">3, 71/80, d1=0.31987, d2=0.33017 g=0.33783\n",
      ">3, 73/80, d1=0.32032, d2=0.30948 g=0.32886\n",
      ">3, 75/80, d1=0.31277, d2=0.33812 g=0.32148\n",
      ">3, 77/80, d1=0.31646, d2=0.34359 g=0.32596\n",
      ">3, 79/80, d1=0.33037, d2=0.33117 g=0.33134\n",
      ">4, 1/80, d1=0.33870, d2=0.33703 g=0.32955\n",
      ">4, 3/80, d1=0.33418, d2=0.31869 g=0.34029\n",
      ">4, 5/80, d1=0.33448, d2=0.33529 g=0.32308\n",
      ">4, 7/80, d1=0.32601, d2=0.30434 g=0.31808\n",
      ">4, 9/80, d1=0.31391, d2=0.32703 g=0.32495\n",
      ">4, 11/80, d1=0.32972, d2=0.33311 g=0.32672\n",
      ">4, 13/80, d1=0.32155, d2=0.31837 g=0.33453\n",
      ">4, 15/80, d1=0.32367, d2=0.32580 g=0.30959\n",
      ">4, 17/80, d1=0.33592, d2=0.32782 g=0.32153\n",
      ">4, 19/80, d1=0.33385, d2=0.35703 g=0.31762\n",
      ">4, 21/80, d1=0.32518, d2=0.34497 g=0.33711\n",
      ">4, 23/80, d1=0.33460, d2=0.33602 g=0.32334\n",
      ">4, 25/80, d1=0.32851, d2=0.34012 g=0.32646\n",
      ">4, 27/80, d1=0.31645, d2=0.35021 g=0.33834\n",
      ">4, 29/80, d1=0.33140, d2=0.32463 g=0.33317\n",
      ">4, 31/80, d1=0.34380, d2=0.32563 g=0.33086\n",
      ">4, 33/80, d1=0.36014, d2=0.33371 g=0.33149\n",
      ">4, 35/80, d1=0.32294, d2=0.34944 g=0.31857\n",
      ">4, 37/80, d1=0.32799, d2=0.32705 g=0.32391\n",
      ">4, 39/80, d1=0.33069, d2=0.34159 g=0.32741\n",
      ">4, 41/80, d1=0.33230, d2=0.33192 g=0.32572\n",
      ">4, 43/80, d1=0.35152, d2=0.33951 g=0.33301\n",
      ">4, 45/80, d1=0.33706, d2=0.33133 g=0.34708\n",
      ">4, 47/80, d1=0.33558, d2=0.31863 g=0.33008\n",
      ">4, 49/80, d1=0.33520, d2=0.34008 g=0.33697\n",
      ">4, 51/80, d1=0.33523, d2=0.32042 g=0.32544\n",
      ">4, 53/80, d1=0.32554, d2=0.32729 g=0.32580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4, 55/80, d1=0.30711, d2=0.33212 g=0.32105\n",
      ">4, 57/80, d1=0.33468, d2=0.33069 g=0.32299\n",
      ">4, 59/80, d1=0.31869, d2=0.33558 g=0.32559\n",
      ">4, 61/80, d1=0.32586, d2=0.33150 g=0.32777\n",
      ">4, 63/80, d1=0.32289, d2=0.31868 g=0.32588\n",
      ">4, 65/80, d1=0.32205, d2=0.31698 g=0.33497\n",
      ">4, 67/80, d1=0.32840, d2=0.32026 g=0.32305\n",
      ">4, 69/80, d1=0.33016, d2=0.31872 g=0.32794\n",
      ">4, 71/80, d1=0.32014, d2=0.33094 g=0.32786\n",
      ">4, 73/80, d1=0.32489, d2=0.30590 g=0.32930\n",
      ">4, 75/80, d1=0.32495, d2=0.33063 g=0.33700\n",
      ">4, 77/80, d1=0.32848, d2=0.33454 g=0.32572\n",
      ">4, 79/80, d1=0.34018, d2=0.31259 g=0.32373\n",
      ">5, 1/80, d1=0.32814, d2=0.33207 g=0.32661\n",
      ">5, 3/80, d1=0.30575, d2=0.32387 g=0.32156\n",
      ">5, 5/80, d1=0.32182, d2=0.32709 g=0.32960\n",
      ">5, 7/80, d1=0.31861, d2=0.32436 g=0.32391\n",
      ">5, 9/80, d1=0.33460, d2=0.31451 g=0.32362\n",
      ">5, 11/80, d1=0.33368, d2=0.33820 g=0.32579\n",
      ">5, 13/80, d1=0.32362, d2=0.34163 g=0.32747\n",
      ">5, 15/80, d1=0.34101, d2=0.32962 g=0.33727\n",
      ">5, 17/80, d1=0.31443, d2=0.31972 g=0.31785\n",
      ">5, 19/80, d1=0.30921, d2=0.33795 g=0.33098\n",
      ">5, 21/80, d1=0.33415, d2=0.32246 g=0.32959\n",
      ">5, 23/80, d1=0.33367, d2=0.34124 g=0.33662\n",
      ">5, 25/80, d1=0.32591, d2=0.33228 g=0.33274\n",
      ">5, 27/80, d1=0.33241, d2=0.33688 g=0.32243\n",
      ">5, 29/80, d1=0.34150, d2=0.34208 g=0.33082\n",
      ">5, 31/80, d1=0.33166, d2=0.31062 g=0.33914\n",
      ">5, 33/80, d1=0.32671, d2=0.32352 g=0.32969\n",
      ">5, 35/80, d1=0.33173, d2=0.32185 g=0.30709\n",
      ">5, 37/80, d1=0.31137, d2=0.32616 g=0.33969\n",
      ">5, 39/80, d1=0.33011, d2=0.33761 g=0.32336\n",
      ">5, 41/80, d1=0.32134, d2=0.32926 g=0.32546\n",
      ">5, 43/80, d1=0.32792, d2=0.34197 g=0.31771\n",
      ">5, 45/80, d1=0.33871, d2=0.33643 g=0.33150\n",
      ">5, 47/80, d1=0.31825, d2=0.33783 g=0.32309\n",
      ">5, 49/80, d1=0.32431, d2=0.32928 g=0.33864\n",
      ">5, 51/80, d1=0.31426, d2=0.31095 g=0.32870\n",
      ">5, 53/80, d1=0.32938, d2=0.33881 g=0.32067\n",
      ">5, 55/80, d1=0.32969, d2=0.33002 g=0.33006\n",
      ">5, 57/80, d1=0.32386, d2=0.33014 g=0.32265\n",
      ">5, 59/80, d1=0.32234, d2=0.32688 g=0.33231\n",
      ">5, 61/80, d1=0.33192, d2=0.32650 g=0.32586\n",
      ">5, 63/80, d1=0.34102, d2=0.33712 g=0.32368\n",
      ">5, 65/80, d1=0.31514, d2=0.32794 g=0.32937\n",
      ">5, 67/80, d1=0.31924, d2=0.33395 g=0.31248\n",
      ">5, 69/80, d1=0.34397, d2=0.33396 g=0.32221\n",
      ">5, 71/80, d1=0.34444, d2=0.34063 g=0.33420\n",
      ">5, 73/80, d1=0.33503, d2=0.34615 g=0.34057\n",
      ">5, 75/80, d1=0.32442, d2=0.33367 g=0.33923\n",
      ">5, 77/80, d1=0.32353, d2=0.33374 g=0.32982\n",
      ">5, 79/80, d1=0.32768, d2=0.32804 g=0.31645\n",
      ">6, 1/80, d1=0.31686, d2=0.33650 g=0.33951\n",
      ">6, 3/80, d1=0.33455, d2=0.33506 g=0.32433\n",
      ">6, 5/80, d1=0.32485, d2=0.30792 g=0.31592\n",
      ">6, 7/80, d1=0.32431, d2=0.31661 g=0.33621\n",
      ">6, 9/80, d1=0.32573, d2=0.33769 g=0.32229\n",
      ">6, 11/80, d1=0.32870, d2=0.34021 g=0.33479\n",
      ">6, 13/80, d1=0.33053, d2=0.32070 g=0.32199\n",
      ">6, 15/80, d1=0.32151, d2=0.33302 g=0.32789\n",
      ">6, 17/80, d1=0.31904, d2=0.32158 g=0.32989\n",
      ">6, 19/80, d1=0.32650, d2=0.33031 g=0.33564\n",
      ">6, 21/80, d1=0.32152, d2=0.33105 g=0.33561\n",
      ">6, 23/80, d1=0.31948, d2=0.33036 g=0.34029\n",
      ">6, 25/80, d1=0.35639, d2=0.33116 g=0.33515\n",
      ">6, 27/80, d1=0.33766, d2=0.32616 g=0.33595\n",
      ">6, 29/80, d1=0.32163, d2=0.32893 g=0.33598\n",
      ">6, 31/80, d1=0.33300, d2=0.34662 g=0.33273\n",
      ">6, 33/80, d1=0.31407, d2=0.35333 g=0.32140\n",
      ">6, 35/80, d1=0.33598, d2=0.30852 g=0.31967\n",
      ">6, 37/80, d1=0.34497, d2=0.32558 g=0.32206\n",
      ">6, 39/80, d1=0.32874, d2=0.32832 g=0.32829\n",
      ">6, 41/80, d1=0.32105, d2=0.34108 g=0.33936\n",
      ">6, 43/80, d1=0.31927, d2=0.31678 g=0.32945\n",
      ">6, 45/80, d1=0.32487, d2=0.31869 g=0.32414\n",
      ">6, 47/80, d1=0.33698, d2=0.33762 g=0.32711\n",
      ">6, 49/80, d1=0.33824, d2=0.31049 g=0.33060\n",
      ">6, 51/80, d1=0.33657, d2=0.34401 g=0.33649\n",
      ">6, 53/80, d1=0.33917, d2=0.33592 g=0.31673\n",
      ">6, 55/80, d1=0.31198, d2=0.32706 g=0.33332\n",
      ">6, 57/80, d1=0.31954, d2=0.32836 g=0.33870\n",
      ">6, 59/80, d1=0.33128, d2=0.31854 g=0.31697\n",
      ">6, 61/80, d1=0.34110, d2=0.32895 g=0.32855\n",
      ">6, 63/80, d1=0.34329, d2=0.32455 g=0.32770\n",
      ">6, 65/80, d1=0.29354, d2=0.31401 g=0.32601\n",
      ">6, 67/80, d1=0.34149, d2=0.35047 g=0.31395\n",
      ">6, 69/80, d1=0.31705, d2=0.31073 g=0.33846\n",
      ">6, 71/80, d1=0.33619, d2=0.34109 g=0.33321\n",
      ">6, 73/80, d1=0.31772, d2=0.31950 g=0.33413\n",
      ">6, 75/80, d1=0.32322, d2=0.32537 g=0.31653\n",
      ">6, 77/80, d1=0.33104, d2=0.32052 g=0.32566\n",
      ">6, 79/80, d1=0.31367, d2=0.35539 g=0.32001\n",
      ">7, 1/80, d1=0.33874, d2=0.33785 g=0.33555\n",
      ">7, 3/80, d1=0.33687, d2=0.32504 g=0.31862\n",
      ">7, 5/80, d1=0.32728, d2=0.33315 g=0.33053\n",
      ">7, 7/80, d1=0.33976, d2=0.32727 g=0.32574\n",
      ">7, 9/80, d1=0.33543, d2=0.34313 g=0.33356\n",
      ">7, 11/80, d1=0.33037, d2=0.33371 g=0.33007\n",
      ">7, 13/80, d1=0.34328, d2=0.32961 g=0.31832\n",
      ">7, 15/80, d1=0.33366, d2=0.33993 g=0.31875\n",
      ">7, 17/80, d1=0.33192, d2=0.32669 g=0.32164\n",
      ">7, 19/80, d1=0.33145, d2=0.30880 g=0.32569\n",
      ">7, 21/80, d1=0.34405, d2=0.32887 g=0.32860\n",
      ">7, 23/80, d1=0.31702, d2=0.34282 g=0.32682\n",
      ">7, 25/80, d1=0.33823, d2=0.34785 g=0.32840\n",
      ">7, 27/80, d1=0.32838, d2=0.33798 g=0.33359\n",
      ">7, 29/80, d1=0.31612, d2=0.31108 g=0.33309\n",
      ">7, 31/80, d1=0.34987, d2=0.32681 g=0.33316\n",
      ">7, 33/80, d1=0.32143, d2=0.33182 g=0.31456\n",
      ">7, 35/80, d1=0.33248, d2=0.35075 g=0.32661\n",
      ">7, 37/80, d1=0.33686, d2=0.31693 g=0.33425\n",
      ">7, 39/80, d1=0.31856, d2=0.32980 g=0.31819\n",
      ">7, 41/80, d1=0.32466, d2=0.32327 g=0.33714\n",
      ">7, 43/80, d1=0.32049, d2=0.33140 g=0.34252\n",
      ">7, 45/80, d1=0.34391, d2=0.30088 g=0.32620\n",
      ">7, 47/80, d1=0.32821, d2=0.33413 g=0.33537\n",
      ">7, 49/80, d1=0.34564, d2=0.33207 g=0.32123\n",
      ">7, 51/80, d1=0.34094, d2=0.34295 g=0.33354\n",
      ">7, 53/80, d1=0.32398, d2=0.31395 g=0.33765\n",
      ">7, 55/80, d1=0.33117, d2=0.32778 g=0.32492\n",
      ">7, 57/80, d1=0.32135, d2=0.34539 g=0.31701\n",
      ">7, 59/80, d1=0.32506, d2=0.31802 g=0.31482\n",
      ">7, 61/80, d1=0.33349, d2=0.30994 g=0.33047\n",
      ">7, 63/80, d1=0.33543, d2=0.33478 g=0.32443\n",
      ">7, 65/80, d1=0.31768, d2=0.31521 g=0.31443\n",
      ">7, 67/80, d1=0.34628, d2=0.33141 g=0.32094\n",
      ">7, 69/80, d1=0.31417, d2=0.33025 g=0.32106\n",
      ">7, 71/80, d1=0.31025, d2=0.32220 g=0.34447\n",
      ">7, 73/80, d1=0.33789, d2=0.33134 g=0.33297\n",
      ">7, 75/80, d1=0.33447, d2=0.31365 g=0.32521\n",
      ">7, 77/80, d1=0.33655, d2=0.32035 g=0.31432\n",
      ">7, 79/80, d1=0.32399, d2=0.32491 g=0.32824\n",
      ">8, 1/80, d1=0.34565, d2=0.33739 g=0.32925\n",
      ">8, 3/80, d1=0.34362, d2=0.32400 g=0.32744\n",
      ">8, 5/80, d1=0.31451, d2=0.33159 g=0.33028\n",
      ">8, 7/80, d1=0.32392, d2=0.33506 g=0.33423\n",
      ">8, 9/80, d1=0.32591, d2=0.34481 g=0.33438\n",
      ">8, 11/80, d1=0.33148, d2=0.31796 g=0.34121\n",
      ">8, 13/80, d1=0.33392, d2=0.32380 g=0.33900\n",
      ">8, 15/80, d1=0.31746, d2=0.33020 g=0.30980\n",
      ">8, 17/80, d1=0.33369, d2=0.31966 g=0.32763\n",
      ">8, 19/80, d1=0.33373, d2=0.34171 g=0.31752\n",
      ">8, 21/80, d1=0.30058, d2=0.31860 g=0.33433\n",
      ">8, 23/80, d1=0.32523, d2=0.30752 g=0.32667\n",
      ">8, 25/80, d1=0.29965, d2=0.33010 g=0.33635\n",
      ">8, 27/80, d1=0.32027, d2=0.33146 g=0.31782\n",
      ">8, 29/80, d1=0.33417, d2=0.35014 g=0.33574\n",
      ">8, 31/80, d1=0.34166, d2=0.32759 g=0.31912\n",
      ">8, 33/80, d1=0.33904, d2=0.33936 g=0.32406\n",
      ">8, 35/80, d1=0.31355, d2=0.30687 g=0.32174\n",
      ">8, 37/80, d1=0.32618, d2=0.33043 g=0.32856\n",
      ">8, 39/80, d1=0.33115, d2=0.33663 g=0.33171\n",
      ">8, 41/80, d1=0.31930, d2=0.30886 g=0.33968\n",
      ">8, 43/80, d1=0.31717, d2=0.31064 g=0.32214\n",
      ">8, 45/80, d1=0.33710, d2=0.31557 g=0.32416\n",
      ">8, 47/80, d1=0.32499, d2=0.31674 g=0.30688\n",
      ">8, 49/80, d1=0.31611, d2=0.32925 g=0.33492\n",
      ">8, 51/80, d1=0.32658, d2=0.33533 g=0.32691\n",
      ">8, 53/80, d1=0.33135, d2=0.33742 g=0.32668\n",
      ">8, 55/80, d1=0.32827, d2=0.34380 g=0.33720\n",
      ">8, 57/80, d1=0.31293, d2=0.32346 g=0.34145\n",
      ">8, 59/80, d1=0.32680, d2=0.31718 g=0.32390\n",
      ">8, 61/80, d1=0.33328, d2=0.32261 g=0.33329\n",
      ">8, 63/80, d1=0.32355, d2=0.33258 g=0.32058\n",
      ">8, 65/80, d1=0.31844, d2=0.31762 g=0.34099\n",
      ">8, 67/80, d1=0.33258, d2=0.31122 g=0.32556\n",
      ">8, 69/80, d1=0.33923, d2=0.33970 g=0.32108\n",
      ">8, 71/80, d1=0.33942, d2=0.32793 g=0.31961\n",
      ">8, 73/80, d1=0.32371, d2=0.34528 g=0.32143\n",
      ">8, 75/80, d1=0.32244, d2=0.33168 g=0.33452\n",
      ">8, 77/80, d1=0.31226, d2=0.33468 g=0.31879\n",
      ">8, 79/80, d1=0.31950, d2=0.33767 g=0.33448\n",
      ">9, 1/80, d1=0.33142, d2=0.32234 g=0.33225\n",
      ">9, 3/80, d1=0.34552, d2=0.33166 g=0.31852\n",
      ">9, 5/80, d1=0.33196, d2=0.33742 g=0.32588\n",
      ">9, 7/80, d1=0.30991, d2=0.32971 g=0.31860\n",
      ">9, 9/80, d1=0.32819, d2=0.33689 g=0.33271\n",
      ">9, 11/80, d1=0.33834, d2=0.32550 g=0.31411\n",
      ">9, 13/80, d1=0.32755, d2=0.32097 g=0.32819\n",
      ">9, 15/80, d1=0.32379, d2=0.33143 g=0.31566\n",
      ">9, 17/80, d1=0.34061, d2=0.31847 g=0.32789\n",
      ">9, 19/80, d1=0.33910, d2=0.33230 g=0.32699\n",
      ">9, 21/80, d1=0.31968, d2=0.33228 g=0.32914\n",
      ">9, 23/80, d1=0.31358, d2=0.32472 g=0.33833\n",
      ">9, 25/80, d1=0.33150, d2=0.34862 g=0.31377\n",
      ">9, 27/80, d1=0.33539, d2=0.31713 g=0.31834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">9, 29/80, d1=0.31564, d2=0.32098 g=0.31997\n",
      ">9, 31/80, d1=0.35881, d2=0.31467 g=0.35433\n",
      ">9, 33/80, d1=0.36265, d2=0.33288 g=0.33906\n",
      ">9, 35/80, d1=0.34731, d2=0.32576 g=0.32967\n",
      ">9, 37/80, d1=0.31903, d2=0.33283 g=0.33310\n",
      ">9, 39/80, d1=0.34805, d2=0.34111 g=0.32435\n",
      ">9, 41/80, d1=0.32250, d2=0.32501 g=0.31754\n",
      ">9, 43/80, d1=0.32880, d2=0.33174 g=0.32907\n",
      ">9, 45/80, d1=0.34533, d2=0.31895 g=0.33915\n",
      ">9, 47/80, d1=0.30859, d2=0.32712 g=0.32253\n",
      ">9, 49/80, d1=0.32254, d2=0.33025 g=0.32200\n",
      ">9, 51/80, d1=0.32098, d2=0.32731 g=0.34009\n",
      ">9, 53/80, d1=0.33449, d2=0.33133 g=0.33108\n",
      ">9, 55/80, d1=0.33878, d2=0.31099 g=0.33277\n",
      ">9, 57/80, d1=0.33461, d2=0.34959 g=0.31973\n",
      ">9, 59/80, d1=0.36278, d2=0.31840 g=0.34145\n",
      ">9, 61/80, d1=0.32712, d2=0.33331 g=0.33476\n",
      ">9, 63/80, d1=0.33079, d2=0.31813 g=0.31909\n",
      ">9, 65/80, d1=0.30895, d2=0.33204 g=0.31582\n",
      ">9, 67/80, d1=0.33408, d2=0.34509 g=0.31965\n",
      ">9, 69/80, d1=0.33887, d2=0.33683 g=0.33330\n",
      ">9, 71/80, d1=0.31895, d2=0.32739 g=0.32409\n",
      ">9, 73/80, d1=0.31398, d2=0.33500 g=0.31908\n",
      ">9, 75/80, d1=0.32101, d2=0.34268 g=0.33919\n",
      ">9, 77/80, d1=0.32092, d2=0.31435 g=0.33062\n",
      ">9, 79/80, d1=0.32153, d2=0.32376 g=0.32010\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 186\n",
    "# size of the data\n",
    "data = 186\n",
    "# classes\n",
    "classes = 3\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "# multiples of three (three classes) (less thyan 24000)\n",
    "n_batch=300\n",
    "\n",
    "# Loss Values\n",
    "G_L = np.infty\n",
    "\n",
    "# create the discriminator\n",
    "d_model = discriminator(data_dim=data)\n",
    "# d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "\n",
    "# create the generator\n",
    "g_model = generator(noise_dim=data, beat_dim=data, out_dim=data)\n",
    "# g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "\n",
    "# create the gan\n",
    "gan_model = create_gan(d_model, g_model)\n",
    "\n",
    "folder_name = 'Final/Beat_Input'\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "plot_model(d_model, to_file=folder_name+'disc.pdf', show_shapes=True)\n",
    "plot_model(g_model, to_file=folder_name+'gen.pdf', show_shapes=True)\n",
    "plot_model(gan_model, to_file=folder_name+'gan.pdf', show_shapes=True)\n",
    "\n",
    "\n",
    "# load image data\n",
    "X_N, y_N, X_S, y_S, X_V, y_V = load_real_samples()\n",
    "# # train model\n",
    "# train(g_model, d_model, gan_model, dataset, latent_dim)\n",
    "\n",
    "bat_per_epo = int(y_S.shape[0] / n_batch)\n",
    "half_batch = int(n_batch / 2)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "    \n",
    "filename = folder_name + 'Plots'\n",
    "if not os.path.isdir(filename):\n",
    "    os.mkdir(filename)\n",
    "\n",
    "model_name = folder_name + 'Model/'\n",
    "if not os.path.isdir(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "f = open(folder_name + 'Loss.csv', 'w')\n",
    "f.write('d_loss1, d_loss2, g_loss \\n')\n",
    "f.close()\n",
    "\n",
    "f = open(folder_name + 'Stats.csv', 'w')\n",
    "for i in range(3):\n",
    "    for mtc in metric_to_calculate:\n",
    "        f.write(str(mtc)+'_'+str(i)+',')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# manually enumerate epochs\n",
    "for i in range(n_epochs):\n",
    "    # enumerate batches over the training set\n",
    "    for j in range(bat_per_epo):\n",
    "        \n",
    "        # get randomly selected 'real' samples\n",
    "        [X_real, labels_real], y_real = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, half_batch)\n",
    "        # print (X_real.shape, labels_real.shape, y_real.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss1, _ = d_model.train_on_batch([X_real, X_real], y_real)\n",
    "        \n",
    "        # generate 'fake' examples\n",
    "        [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # print (X_fake.shape, labels.shape, y_fake.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss2, _ = d_model.train_on_batch([X_fake, X_fake], y_fake)\n",
    "        \n",
    "        # prepare points in latent space as input for the generator\n",
    "        [z_input, _] = generate_latent_points(latent_dim, n_batch)\n",
    "        [X, _], _ = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_batch)\n",
    "        # print (z_input.shape)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = reshape(np.random.uniform(0.8, 1, n_batch))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch([z_input, X], y_gan)\n",
    "        \n",
    "        if g_loss < G_L:\n",
    "            G_L = g_loss\n",
    "            g_model.save(model_name + str(i*1000 + j) + '_cgan_generator.h5')\n",
    "\n",
    "        f = open(folder_name + 'Loss.csv', 'a')\n",
    "        f.write(str(d_loss1)+','+str(d_loss2)+','+str(g_loss)+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        if (j+1)%2 == 0:\n",
    "            print('>%d, %d/%d, d1=%.5f, d2=%.5f g=%.5f' %(i, j, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "            name = filename+'/'+str(i*1000 + j)+'.jpg'\n",
    "            # generate ECGs\n",
    "            z_input  = g_model.predict([z_input, X])\n",
    "            X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "            save_new_plot(X_R, z_input, n_batch, name)\n",
    "            \n",
    "        if (j+1)%10 == 0:\n",
    "            evaluate(X, z_input, classes, metric_to_calculate, n_batch, folder_name, samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-welsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
