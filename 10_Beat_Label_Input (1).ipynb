{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import keras\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, multiply, Embedding, merge, Concatenate, Conv1D, BatchNormalization\n",
    "from keras.layers import Dense, Flatten, Multiply\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Add\n",
    "import tensorflow as tf\n",
    "from evaluation_metrics import *\n",
    "from helper import *\n",
    "metric_to_calculate = ['FID', 'MMD', 'DTW', 'PC', 'RMSE', 'TWED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(data_dim, input_classes=3):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    x = Embedding(input_classes, 30)(in_label)\n",
    "    x = Dense(data_dim)(x)\n",
    "    x = Reshape((data_dim,1))(x)\n",
    "    \n",
    "    D_in = Input(shape=[data_dim,1])\n",
    "    inp1 = Concatenate()([D_in, x])\n",
    "\n",
    "    x = Conv1D(filters=48, kernel_size=19, padding='same', strides=4, kernel_initializer='he_normal')(inp1)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=15, padding='same', strides=3, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=80, kernel_size=11, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=96, kernel_size=9, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=112, kernel_size=7, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x1 = Conv1D(filters=48, kernel_size=9, padding='same', strides=4, kernel_initializer='he_normal')(inp1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=64, kernel_size=7, padding='same', strides=3, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=80, kernel_size=5, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=96, kernel_size=3, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=112, kernel_size=3, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    # x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = GlobalAveragePooling1D()(x1)\n",
    "\n",
    "    xx = concatenate([x,x1])\n",
    "\n",
    "    xx = Dense(100)(xx)\n",
    "    xx = Dense(100)(xx)\n",
    "\n",
    "    out = Dense(1, activation='sigmoid')(xx)\n",
    "\n",
    "    model = Model(inputs=[D_in, in_label], outputs=out)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "    # model.summary()\n",
    "\n",
    "# d_model = discriminator(data_dim=186, input_classes=3)\n",
    "# plot_model(d_model, to_file='disc.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "northern-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim=186, input_classes=3, out_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    x = Embedding(input_classes, 30)(in_label)\n",
    "    x = Dense(noise_dim)(x)\n",
    "    x = Reshape((noise_dim,1))(x)\n",
    "    \n",
    "    G_in = Input(shape=[noise_dim,])\n",
    "    gen = Dense(noise_dim)(G_in)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((noise_dim,1))(gen)\n",
    "\n",
    "    x = Concatenate()([gen, x])\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*16, kernel_size=15, strides=1, padding='valid', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=1, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    out = Activation('tanh')(x)\n",
    "    model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "# g_model = generator(noise_dim=100, input_classes=3, out_dim=186)\n",
    "# plot_model(g_model, to_file='gen.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "written-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(d_model, g_model):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_beat = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_beat])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_beat], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# gan_model = create_gan(d_model, g_model)\n",
    "# plot_model(gan_model, to_file='gan.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "important-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        return X\n",
    "    else:\n",
    "        if X.shape[-1] == 1:\n",
    "            return X\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    X = np.load('Data/ForGAN/X.npy')\n",
    "    y = np.load('Data/ForGAN/y.npy')\n",
    "\n",
    "    # print (X.shape, y.shape)\n",
    "\n",
    "    X_N = X[y==0]\n",
    "    X_S = X[y==1]\n",
    "    X_V = X[y==2]\n",
    "\n",
    "    y_N = y[y==0]\n",
    "    y_S = y[y==1]\n",
    "    y_V = y[y==2]\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "\n",
    "#     X_N=X_N.reshape(X_N.shape[0],X_N.shape[1],1)\n",
    "#     X_S=X_S.reshape(X_S.shape[0],X_S.shape[1],1)\n",
    "#     X_V=X_V.reshape(X_V.shape[0],X_V.shape[1],1)\n",
    "\n",
    "    # print (X_N.shape, y_N.shape)\n",
    "    # print (X_S.shape, y_S.shape)\n",
    "    # print (X_V.shape, y_V.shape)\n",
    "    return reshape(X_N), y_N, reshape(X_S), y_S, reshape(X_V), y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_samples):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], int(n_samples/3))\n",
    "    i_S = randint(0, y_S.shape[0], int(n_samples/3))\n",
    "    i_V = randint(0, y_V.shape[0], int(n_samples/3))\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    labels = np.hstack((y_N[i_N], y_S[i_S], y_V[i_V]))\n",
    "    # print (labels.shape)\n",
    "    \n",
    "    # generate class labels\n",
    "    y = reshape(np.random.uniform(0.8, 1, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bound-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "# normal noise\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=3):\n",
    "    # generate points in the latent space\n",
    "#     X_fake = np.random.uniform(0, 1.0, size=[n_samples, latent_dim])\n",
    "    X_fake = np.random.normal(0,1.0,(n_samples,latent_dim))\n",
    "    # generate labels\n",
    "    labels_fake = np.hstack((np.zeros(int(n_samples/3)), np.ones(int(n_samples/3)), 2*np.ones(int(n_samples/3))))\n",
    "    np.random.shuffle(labels_fake)\n",
    "    return [reshape(X_fake), labels_fake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    ecgs = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = reshape(np.random.uniform(0, 0.2, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.zeros((n_samples, 1))\n",
    "    return [ecgs, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "general-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images\n",
    "def save_plot(X, n):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(X[i, :, 0])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "communist-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], 1)\n",
    "    i_S = randint(0, y_S.shape[0], 1)\n",
    "    i_V = randint(0, y_V.shape[0], 1)\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "speaking-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_plot(X_R, z_input, n_batch, name):\n",
    "    n = 3\n",
    "    Win = (n_batch//3)\n",
    "    XX = np.vstack((X_R, z_input[0:n,:,:], z_input[Win:Win+n,:,:], z_input[2*Win:2*Win+n,:,:]))\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(n):\n",
    "        # subplot(R, C, Plot_No)\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.plot(XX[i,:,:])\n",
    "    for i in range(n, ((n+1)*(n+1))-(n+1)):\n",
    "        # define subplot\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(XX[i,:,:])\n",
    "    # plt.show()\n",
    "    plt.savefig(name, dpi=75)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cubic-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0, 1/80, d1=0.51439, d2=1.35248 g=0.47764\n",
      ">0, 3/80, d1=0.65761, d2=0.70606 g=0.89714\n",
      ">0, 5/80, d1=0.84415, d2=0.51116 g=1.08220\n",
      ">0, 7/80, d1=0.82986, d2=0.50367 g=1.08233\n",
      ">0, 9/80, d1=0.81716, d2=0.51348 g=1.06272\n",
      ">0, 11/80, d1=0.79735, d2=0.53053 g=1.01836\n",
      ">0, 13/80, d1=0.77870, d2=0.56457 g=0.93675\n",
      ">0, 15/80, d1=0.69041, d2=0.61789 g=0.79646\n",
      ">0, 17/80, d1=0.59800, d2=0.68967 g=0.72065\n",
      ">0, 19/80, d1=0.55423, d2=0.73673 g=0.74602\n",
      ">0, 21/80, d1=0.61772, d2=0.67413 g=0.80779\n",
      ">0, 23/80, d1=0.61229, d2=0.66571 g=0.76398\n",
      ">0, 25/80, d1=0.57763, d2=0.68278 g=0.73847\n",
      ">0, 27/80, d1=0.52905, d2=0.70483 g=0.73430\n",
      ">0, 29/80, d1=0.54395, d2=0.71421 g=0.74965\n",
      ">0, 31/80, d1=0.59143, d2=0.70988 g=0.75751\n",
      ">0, 33/80, d1=0.55747, d2=0.68507 g=0.78209\n",
      ">0, 35/80, d1=0.55022, d2=0.72511 g=0.74933\n",
      ">0, 37/80, d1=0.58279, d2=0.69067 g=0.78552\n",
      ">0, 39/80, d1=0.57315, d2=0.68349 g=0.77362\n",
      ">0, 41/80, d1=0.58071, d2=0.69382 g=0.78377\n",
      ">0, 43/80, d1=0.58036, d2=0.75277 g=0.77408\n",
      ">0, 45/80, d1=0.61348, d2=0.70991 g=0.81158\n",
      ">0, 47/80, d1=0.62244, d2=0.70639 g=0.89993\n",
      ">0, 49/80, d1=0.64125, d2=0.66521 g=0.81635\n",
      ">0, 51/80, d1=0.63268, d2=0.70160 g=0.77645\n",
      ">0, 53/80, d1=0.64118, d2=0.67554 g=0.79612\n",
      ">0, 55/80, d1=0.64488, d2=0.71341 g=0.77997\n",
      ">0, 57/80, d1=0.66242, d2=0.67260 g=0.83334\n",
      ">0, 59/80, d1=0.62582, d2=0.72218 g=0.76708\n",
      ">0, 61/80, d1=0.66316, d2=0.68679 g=0.82751\n",
      ">0, 63/80, d1=0.71252, d2=0.64729 g=0.81277\n",
      ">0, 65/80, d1=0.64654, d2=0.71407 g=0.75889\n",
      ">0, 67/80, d1=0.65901, d2=0.68787 g=0.80804\n",
      ">0, 69/80, d1=0.65750, d2=0.68908 g=0.78173\n",
      ">0, 71/80, d1=0.68205, d2=0.67491 g=0.79895\n",
      ">0, 73/80, d1=0.67778, d2=0.68323 g=0.79547\n",
      ">0, 75/80, d1=0.68446, d2=0.66533 g=0.79022\n",
      ">0, 77/80, d1=0.65725, d2=0.66092 g=0.78408\n",
      ">0, 79/80, d1=0.63923, d2=0.72089 g=0.78814\n",
      ">1, 1/80, d1=0.68738, d2=0.65197 g=0.84637\n",
      ">1, 3/80, d1=0.69002, d2=0.65797 g=0.79937\n",
      ">1, 5/80, d1=0.65869, d2=0.68352 g=0.77709\n",
      ">1, 7/80, d1=0.64206, d2=0.65642 g=0.78558\n",
      ">1, 9/80, d1=0.60799, d2=0.70565 g=0.80822\n",
      ">1, 11/80, d1=0.64644, d2=0.69104 g=0.85730\n",
      ">1, 13/80, d1=0.68813, d2=0.64295 g=0.82565\n",
      ">1, 15/80, d1=0.61884, d2=0.68069 g=0.73419\n",
      ">1, 17/80, d1=0.59050, d2=0.74293 g=0.82042\n",
      ">1, 19/80, d1=0.64697, d2=0.67090 g=0.78754\n",
      ">1, 21/80, d1=0.60934, d2=0.67253 g=0.80129\n",
      ">1, 23/80, d1=0.63013, d2=0.68359 g=0.78507\n",
      ">1, 25/80, d1=0.62741, d2=0.67891 g=0.80102\n",
      ">1, 27/80, d1=0.64711, d2=0.64839 g=0.81874\n",
      ">1, 29/80, d1=0.64496, d2=0.66238 g=0.82003\n",
      ">1, 31/80, d1=0.59943, d2=0.68638 g=0.76696\n",
      ">1, 33/80, d1=0.58110, d2=0.69372 g=0.76118\n",
      ">1, 35/80, d1=0.61891, d2=0.70604 g=0.80126\n",
      ">1, 37/80, d1=0.63118, d2=0.69323 g=0.84454\n",
      ">1, 39/80, d1=0.61960, d2=0.67364 g=0.84866\n",
      ">1, 41/80, d1=0.66492, d2=0.63509 g=0.94148\n",
      ">1, 43/80, d1=0.71059, d2=0.60313 g=0.86275\n",
      ">1, 45/80, d1=0.57280, d2=0.68712 g=0.82214\n",
      ">1, 47/80, d1=0.65251, d2=0.67841 g=0.85823\n",
      ">1, 49/80, d1=0.63928, d2=0.67497 g=0.83437\n",
      ">1, 51/80, d1=0.65047, d2=0.69907 g=0.80062\n",
      ">1, 53/80, d1=0.65090, d2=0.70053 g=0.81038\n",
      ">1, 55/80, d1=0.63622, d2=0.71230 g=0.76854\n",
      ">1, 57/80, d1=0.66976, d2=0.72004 g=0.78641\n",
      ">1, 59/80, d1=0.65850, d2=0.77852 g=0.77915\n",
      ">1, 61/80, d1=0.69453, d2=0.70947 g=0.79870\n",
      ">1, 63/80, d1=0.66873, d2=0.72307 g=0.75292\n",
      ">1, 65/80, d1=0.65563, d2=0.71891 g=0.92389\n",
      ">1, 67/80, d1=0.78024, d2=0.63155 g=1.08915\n",
      ">1, 69/80, d1=0.65976, d2=0.59855 g=1.09867\n",
      ">1, 71/80, d1=0.70152, d2=0.41154 g=1.55124\n",
      ">1, 73/80, d1=0.62413, d2=0.39928 g=1.58505\n",
      ">1, 75/80, d1=0.55005, d2=0.37822 g=1.73150\n",
      ">1, 77/80, d1=0.48355, d2=0.36022 g=1.85802\n",
      ">1, 79/80, d1=0.45045, d2=0.33102 g=1.92784\n",
      ">2, 1/80, d1=0.42723, d2=0.33327 g=2.01692\n",
      ">2, 3/80, d1=0.41242, d2=0.34203 g=2.03993\n",
      ">2, 5/80, d1=0.41799, d2=0.35334 g=2.01822\n",
      ">2, 7/80, d1=0.46200, d2=0.43164 g=2.02066\n",
      ">2, 9/80, d1=0.47729, d2=0.72155 g=1.94767\n",
      ">2, 11/80, d1=0.81722, d2=0.32735 g=0.88168\n",
      ">2, 13/80, d1=0.50498, d2=1.84038 g=11.35382\n",
      ">2, 15/80, d1=0.40834, d2=0.57050 g=1.15941\n",
      ">2, 17/80, d1=0.52903, d2=0.92976 g=0.89513\n",
      ">2, 19/80, d1=0.57931, d2=0.45571 g=1.40927\n",
      ">2, 21/80, d1=0.54751, d2=0.68681 g=1.00301\n",
      ">2, 23/80, d1=0.60570, d2=0.67786 g=1.09492\n",
      ">2, 25/80, d1=0.54772, d2=0.73903 g=0.86808\n",
      ">2, 27/80, d1=0.72374, d2=0.60025 g=1.08463\n",
      ">2, 29/80, d1=0.64343, d2=0.65388 g=0.93053\n",
      ">2, 31/80, d1=0.66064, d2=0.63968 g=0.98645\n",
      ">2, 33/80, d1=0.72614, d2=0.59369 g=1.02930\n",
      ">2, 35/80, d1=0.69842, d2=0.64760 g=0.94862\n",
      ">2, 37/80, d1=0.68503, d2=0.67969 g=0.84430\n",
      ">2, 39/80, d1=0.67096, d2=0.67632 g=0.90144\n",
      ">2, 41/80, d1=0.61429, d2=0.65228 g=0.84028\n",
      ">2, 43/80, d1=0.60975, d2=0.73564 g=0.79087\n",
      ">2, 45/80, d1=0.66100, d2=0.73301 g=0.81382\n",
      ">2, 47/80, d1=0.68898, d2=0.61791 g=0.93535\n",
      ">2, 49/80, d1=0.71156, d2=0.67519 g=0.84381\n",
      ">2, 51/80, d1=0.66812, d2=0.70727 g=0.76645\n",
      ">2, 53/80, d1=0.63620, d2=0.72813 g=0.78976\n",
      ">2, 55/80, d1=0.67081, d2=0.67664 g=0.81624\n",
      ">2, 57/80, d1=0.68333, d2=0.64223 g=0.82424\n",
      ">2, 59/80, d1=0.65710, d2=0.72754 g=0.80182\n",
      ">2, 61/80, d1=0.68709, d2=0.66126 g=0.85225\n",
      ">2, 63/80, d1=0.72689, d2=0.65556 g=0.80246\n",
      ">2, 65/80, d1=0.69908, d2=0.67049 g=0.79573\n",
      ">2, 67/80, d1=0.67110, d2=0.67955 g=0.79157\n",
      ">2, 69/80, d1=0.68554, d2=0.68300 g=0.76956\n",
      ">2, 71/80, d1=0.65802, d2=0.67969 g=0.78788\n",
      ">2, 73/80, d1=0.64583, d2=0.65394 g=0.79944\n",
      ">2, 75/80, d1=0.65888, d2=0.66632 g=0.78933\n",
      ">2, 77/80, d1=0.64280, d2=0.67022 g=0.77811\n",
      ">2, 79/80, d1=0.62865, d2=0.69010 g=0.79053\n",
      ">3, 1/80, d1=0.65968, d2=0.66772 g=0.88760\n",
      ">3, 3/80, d1=0.75545, d2=0.61258 g=0.88349\n",
      ">3, 5/80, d1=0.70663, d2=0.62916 g=0.87837\n",
      ">3, 7/80, d1=0.70265, d2=0.61697 g=0.88067\n",
      ">3, 9/80, d1=0.68117, d2=0.62843 g=0.84662\n",
      ">3, 11/80, d1=0.66718, d2=0.65220 g=0.80931\n",
      ">3, 13/80, d1=0.62663, d2=0.67735 g=0.79523\n",
      ">3, 15/80, d1=0.60746, d2=0.65378 g=0.83417\n",
      ">3, 17/80, d1=0.60756, d2=0.75225 g=0.92261\n",
      ">3, 19/80, d1=0.71983, d2=0.61802 g=0.95637\n",
      ">3, 21/80, d1=0.74787, d2=0.56520 g=0.98146\n",
      ">3, 23/80, d1=0.64065, d2=0.62506 g=0.85199\n",
      ">3, 25/80, d1=0.60755, d2=0.68550 g=0.83033\n",
      ">3, 27/80, d1=0.64643, d2=0.62894 g=0.83032\n",
      ">3, 29/80, d1=0.58386, d2=0.67050 g=0.79949\n",
      ">3, 31/80, d1=0.54808, d2=0.76213 g=0.77753\n",
      ">3, 33/80, d1=0.64513, d2=0.70272 g=0.85450\n",
      ">3, 35/80, d1=0.69279, d2=0.66128 g=0.91496\n",
      ">3, 37/80, d1=0.72326, d2=0.59743 g=0.92913\n",
      ">3, 39/80, d1=0.67989, d2=0.64514 g=0.82615\n",
      ">3, 41/80, d1=0.62287, d2=0.66304 g=0.80488\n",
      ">3, 43/80, d1=0.66283, d2=0.69963 g=0.83856\n",
      ">3, 45/80, d1=0.69563, d2=0.66381 g=0.81073\n",
      ">3, 47/80, d1=0.67990, d2=0.70201 g=0.82104\n",
      ">3, 49/80, d1=0.72112, d2=0.62166 g=0.85087\n",
      ">3, 51/80, d1=0.69427, d2=0.65188 g=0.81741\n",
      ">3, 53/80, d1=0.68824, d2=0.67706 g=0.79236\n",
      ">3, 55/80, d1=0.67235, d2=0.67101 g=0.81177\n",
      ">3, 57/80, d1=0.68568, d2=0.69460 g=0.78714\n",
      ">3, 59/80, d1=0.67376, d2=0.67665 g=0.78219\n",
      ">3, 61/80, d1=0.64250, d2=0.67959 g=0.79255\n",
      ">3, 63/80, d1=0.64800, d2=0.69448 g=0.82206\n",
      ">3, 65/80, d1=0.66201, d2=0.68095 g=0.90114\n",
      ">3, 67/80, d1=0.77385, d2=0.58282 g=0.97328\n",
      ">3, 69/80, d1=0.75658, d2=0.60385 g=0.88605\n",
      ">3, 71/80, d1=0.66672, d2=0.64931 g=0.83075\n",
      ">3, 73/80, d1=0.64582, d2=0.65975 g=0.85923\n",
      ">3, 75/80, d1=0.68966, d2=0.66354 g=0.88195\n",
      ">3, 77/80, d1=0.70028, d2=0.62123 g=0.90176\n",
      ">3, 79/80, d1=0.66554, d2=0.63986 g=0.82772\n",
      ">4, 1/80, d1=0.60237, d2=0.76401 g=0.77714\n",
      ">4, 3/80, d1=0.64509, d2=0.68013 g=0.86446\n",
      ">4, 5/80, d1=0.63260, d2=0.63244 g=0.98625\n",
      ">4, 7/80, d1=0.61747, d2=0.83611 g=0.78787\n",
      ">4, 9/80, d1=0.74417, d2=0.60868 g=0.96779\n",
      ">4, 11/80, d1=0.73483, d2=0.60614 g=0.92709\n",
      ">4, 13/80, d1=0.72086, d2=0.58508 g=1.00616\n",
      ">4, 15/80, d1=0.71848, d2=0.60368 g=0.91414\n",
      ">4, 17/80, d1=0.72122, d2=0.72258 g=0.92937\n",
      ">4, 19/80, d1=0.68220, d2=0.50383 g=1.09301\n",
      ">4, 21/80, d1=0.55979, d2=0.62425 g=0.82575\n",
      ">4, 23/80, d1=0.54820, d2=0.73666 g=0.81316\n",
      ">4, 25/80, d1=0.61584, d2=0.71860 g=0.84214\n",
      ">4, 27/80, d1=0.68018, d2=0.67629 g=0.87106\n",
      ">4, 29/80, d1=0.71771, d2=0.62231 g=0.94766\n",
      ">4, 31/80, d1=0.75516, d2=0.58432 g=0.91972\n",
      ">4, 33/80, d1=0.68687, d2=0.62195 g=0.90771\n",
      ">4, 35/80, d1=0.67220, d2=0.58974 g=0.95550\n",
      ">4, 37/80, d1=0.68745, d2=0.66590 g=0.96755\n",
      ">4, 39/80, d1=0.71411, d2=0.56574 g=0.99322\n",
      ">4, 41/80, d1=0.68775, d2=0.66506 g=0.87423\n",
      ">4, 43/80, d1=0.68650, d2=0.63948 g=0.87537\n",
      ">4, 45/80, d1=0.63289, d2=0.62009 g=0.86279\n",
      ">4, 47/80, d1=0.58324, d2=0.66567 g=0.81986\n",
      ">4, 49/80, d1=0.62462, d2=0.65333 g=0.86721\n",
      ">4, 51/80, d1=0.58823, d2=0.64188 g=0.86854\n",
      ">4, 53/80, d1=0.60851, d2=0.66988 g=0.85420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4, 55/80, d1=0.62328, d2=0.60872 g=0.91688\n",
      ">4, 57/80, d1=0.67425, d2=0.62658 g=0.90718\n",
      ">4, 59/80, d1=0.66442, d2=0.61028 g=0.91985\n",
      ">4, 61/80, d1=0.65226, d2=0.61059 g=0.91691\n",
      ">4, 63/80, d1=0.66999, d2=0.62667 g=0.91130\n",
      ">4, 65/80, d1=0.65530, d2=0.58897 g=0.95111\n",
      ">4, 67/80, d1=0.65425, d2=0.64496 g=0.88102\n",
      ">4, 69/80, d1=0.68013, d2=0.62804 g=0.94976\n",
      ">4, 71/80, d1=0.69563, d2=0.60371 g=0.94928\n",
      ">4, 73/80, d1=0.66861, d2=0.58711 g=0.96341\n",
      ">4, 75/80, d1=0.65983, d2=0.64168 g=0.87078\n",
      ">4, 77/80, d1=0.67726, d2=0.61072 g=0.94313\n",
      ">4, 79/80, d1=0.64097, d2=0.59994 g=0.97015\n",
      ">5, 1/80, d1=0.69671, d2=0.63706 g=0.92671\n",
      ">5, 3/80, d1=0.65675, d2=0.58276 g=0.95473\n",
      ">5, 5/80, d1=0.63395, d2=0.67427 g=0.84043\n",
      ">5, 7/80, d1=0.65027, d2=0.58861 g=0.94091\n",
      ">5, 9/80, d1=0.65863, d2=0.62710 g=0.89134\n",
      ">5, 11/80, d1=0.67281, d2=0.60751 g=0.97456\n",
      ">5, 13/80, d1=0.68018, d2=0.61401 g=0.90137\n",
      ">5, 15/80, d1=0.67717, d2=0.61111 g=0.95788\n",
      ">5, 17/80, d1=0.67091, d2=0.58839 g=0.97293\n",
      ">5, 19/80, d1=0.69976, d2=0.58183 g=0.93926\n",
      ">5, 21/80, d1=0.63076, d2=0.61459 g=0.90943\n",
      ">5, 23/80, d1=0.61769, d2=0.61399 g=0.89020\n",
      ">5, 25/80, d1=0.60542, d2=0.65368 g=0.92314\n",
      ">5, 27/80, d1=0.60904, d2=0.60091 g=1.01016\n",
      ">5, 29/80, d1=0.59929, d2=0.58791 g=1.04660\n",
      ">5, 31/80, d1=0.44908, d2=0.61270 g=1.00876\n",
      ">5, 33/80, d1=0.38754, d2=0.61331 g=1.21208\n",
      ">5, 35/80, d1=0.41877, d2=1.29359 g=2.95278\n",
      ">5, 37/80, d1=0.80168, d2=0.42195 g=1.61221\n",
      ">5, 39/80, d1=0.58308, d2=0.50400 g=1.78442\n",
      ">5, 41/80, d1=0.59027, d2=0.76238 g=1.22859\n",
      ">5, 43/80, d1=0.67558, d2=0.40296 g=1.79559\n",
      ">5, 45/80, d1=0.61216, d2=0.64501 g=1.13319\n",
      ">5, 47/80, d1=0.65033, d2=0.62396 g=1.12045\n",
      ">5, 49/80, d1=0.65866, d2=0.56994 g=1.20108\n",
      ">5, 51/80, d1=0.73449, d2=0.53389 g=1.12553\n",
      ">5, 53/80, d1=0.71389, d2=0.54226 g=1.01076\n",
      ">5, 55/80, d1=0.61611, d2=0.59628 g=1.04984\n",
      ">5, 57/80, d1=0.65636, d2=0.56926 g=0.96981\n",
      ">5, 59/80, d1=0.62844, d2=0.61404 g=0.94656\n",
      ">5, 61/80, d1=0.63619, d2=0.61700 g=0.98811\n",
      ">5, 63/80, d1=0.71482, d2=0.57689 g=1.01506\n",
      ">5, 65/80, d1=0.68442, d2=0.58517 g=1.00271\n",
      ">5, 67/80, d1=0.64356, d2=0.58785 g=0.95013\n",
      ">5, 69/80, d1=0.64324, d2=0.54153 g=0.98623\n",
      ">5, 71/80, d1=0.59667, d2=0.58582 g=0.95539\n",
      ">5, 73/80, d1=0.61651, d2=0.60575 g=0.99326\n",
      ">5, 75/80, d1=0.62907, d2=0.58231 g=0.99208\n",
      ">5, 77/80, d1=0.66516, d2=0.59289 g=0.96087\n",
      ">5, 79/80, d1=0.64793, d2=0.63458 g=0.96009\n",
      ">6, 1/80, d1=0.59678, d2=0.57823 g=0.99466\n",
      ">6, 3/80, d1=0.61517, d2=0.59967 g=0.97225\n",
      ">6, 5/80, d1=0.57594, d2=0.61246 g=0.97043\n",
      ">6, 7/80, d1=0.64894, d2=0.56772 g=0.97606\n",
      ">6, 9/80, d1=0.64100, d2=0.59468 g=0.96186\n",
      ">6, 11/80, d1=0.59697, d2=0.57725 g=0.99461\n",
      ">6, 13/80, d1=0.64996, d2=0.60397 g=0.99683\n",
      ">6, 15/80, d1=0.64015, d2=0.57718 g=0.98481\n",
      ">6, 17/80, d1=0.65609, d2=0.62068 g=0.99454\n",
      ">6, 19/80, d1=0.64898, d2=0.59807 g=0.99845\n",
      ">6, 21/80, d1=0.68694, d2=0.55968 g=1.01576\n",
      ">6, 23/80, d1=0.62720, d2=0.59772 g=0.98859\n",
      ">6, 25/80, d1=0.69336, d2=0.59884 g=0.98149\n",
      ">6, 27/80, d1=0.64444, d2=0.62827 g=0.93578\n",
      ">6, 29/80, d1=0.62990, d2=0.63791 g=1.01857\n",
      ">6, 31/80, d1=0.65315, d2=0.67957 g=0.96274\n",
      ">6, 33/80, d1=0.68104, d2=0.62082 g=0.93475\n",
      ">6, 35/80, d1=0.65029, d2=0.63867 g=0.94249\n",
      ">6, 37/80, d1=0.64616, d2=0.61634 g=0.97648\n",
      ">6, 39/80, d1=0.65949, d2=0.57853 g=0.98069\n",
      ">6, 41/80, d1=0.66111, d2=0.59804 g=0.93809\n",
      ">6, 43/80, d1=0.65711, d2=0.60355 g=0.96271\n",
      ">6, 45/80, d1=0.62074, d2=0.60829 g=1.04895\n",
      ">6, 47/80, d1=0.64627, d2=0.59217 g=1.00489\n",
      ">6, 49/80, d1=0.68784, d2=0.59136 g=0.96917\n",
      ">6, 51/80, d1=0.62507, d2=0.62494 g=0.92591\n",
      ">6, 53/80, d1=0.63007, d2=0.65816 g=1.01592\n",
      ">6, 55/80, d1=0.66644, d2=0.58082 g=0.98889\n",
      ">6, 57/80, d1=0.59004, d2=0.64849 g=1.00203\n",
      ">6, 59/80, d1=0.63203, d2=0.59334 g=0.98919\n",
      ">6, 61/80, d1=0.63566, d2=0.59816 g=0.95815\n",
      ">6, 63/80, d1=0.65846, d2=0.60282 g=1.09389\n",
      ">6, 65/80, d1=0.69999, d2=0.55967 g=1.19792\n",
      ">6, 67/80, d1=0.72390, d2=0.61699 g=1.05054\n",
      ">6, 69/80, d1=0.62635, d2=0.59880 g=1.01692\n",
      ">6, 71/80, d1=0.63999, d2=0.61906 g=1.01494\n",
      ">6, 73/80, d1=0.66991, d2=0.58585 g=1.03700\n",
      ">6, 75/80, d1=0.63058, d2=0.64248 g=1.03813\n",
      ">6, 77/80, d1=0.68715, d2=0.61107 g=1.13758\n",
      ">6, 79/80, d1=0.66921, d2=0.62691 g=1.07195\n",
      ">7, 1/80, d1=0.65538, d2=0.58840 g=1.01076\n",
      ">7, 3/80, d1=0.66073, d2=0.57293 g=1.00132\n",
      ">7, 5/80, d1=0.64707, d2=0.66440 g=0.94004\n",
      ">7, 7/80, d1=0.63176, d2=0.63992 g=1.03105\n",
      ">7, 9/80, d1=0.67220, d2=0.60941 g=0.96499\n",
      ">7, 11/80, d1=0.67477, d2=0.55724 g=1.06614\n",
      ">7, 13/80, d1=0.71654, d2=0.55464 g=1.04548\n",
      ">7, 15/80, d1=0.65132, d2=0.53552 g=1.08695\n",
      ">7, 17/80, d1=0.62993, d2=0.67644 g=0.96474\n",
      ">7, 19/80, d1=0.69734, d2=0.56718 g=1.12458\n",
      ">7, 21/80, d1=0.62365, d2=0.60185 g=1.03736\n",
      ">7, 23/80, d1=0.68189, d2=0.63315 g=0.93441\n",
      ">7, 25/80, d1=0.63082, d2=0.62228 g=0.94868\n",
      ">7, 27/80, d1=0.63493, d2=0.59164 g=0.98285\n",
      ">7, 29/80, d1=0.61520, d2=0.63647 g=0.97669\n",
      ">7, 31/80, d1=0.63938, d2=0.57332 g=1.02765\n",
      ">7, 33/80, d1=0.63563, d2=0.60166 g=0.94816\n",
      ">7, 35/80, d1=0.62599, d2=0.62327 g=0.95955\n",
      ">7, 37/80, d1=0.69257, d2=0.57826 g=0.97262\n",
      ">7, 39/80, d1=0.64279, d2=0.60966 g=0.95258\n",
      ">7, 41/80, d1=0.62763, d2=0.67446 g=0.92941\n",
      ">7, 43/80, d1=0.64827, d2=0.61640 g=1.10879\n",
      ">7, 45/80, d1=0.70380, d2=0.55950 g=1.00615\n",
      ">7, 47/80, d1=0.68452, d2=0.61672 g=0.97823\n",
      ">7, 49/80, d1=0.63599, d2=0.67292 g=0.93908\n",
      ">7, 51/80, d1=0.70073, d2=0.61554 g=1.08372\n",
      ">7, 53/80, d1=0.60885, d2=0.78640 g=0.97258\n",
      ">7, 55/80, d1=0.53308, d2=0.52962 g=1.16459\n",
      ">7, 57/80, d1=0.51520, d2=0.47222 g=1.22666\n",
      ">7, 59/80, d1=0.43203, d2=0.91947 g=1.26991\n",
      ">7, 61/80, d1=0.86851, d2=0.59714 g=1.50115\n",
      ">7, 63/80, d1=0.77349, d2=0.64897 g=1.17900\n",
      ">7, 65/80, d1=0.74707, d2=0.57344 g=1.04616\n",
      ">7, 67/80, d1=0.69318, d2=0.57860 g=1.14055\n",
      ">7, 69/80, d1=0.71636, d2=0.54027 g=1.13743\n",
      ">7, 71/80, d1=0.68922, d2=0.54352 g=1.25437\n",
      ">7, 73/80, d1=0.71564, d2=0.56623 g=1.02698\n",
      ">7, 75/80, d1=0.62874, d2=0.60890 g=0.93759\n",
      ">7, 77/80, d1=0.59942, d2=0.61653 g=0.89101\n",
      ">7, 79/80, d1=0.56931, d2=0.60680 g=0.97563\n",
      ">8, 1/80, d1=0.56416, d2=0.56976 g=1.03447\n",
      ">8, 3/80, d1=0.58060, d2=0.57859 g=1.10785\n",
      ">8, 5/80, d1=0.61605, d2=0.57526 g=1.13861\n",
      ">8, 7/80, d1=0.65634, d2=0.57816 g=1.07183\n",
      ">8, 9/80, d1=0.68328, d2=0.56867 g=1.07267\n",
      ">8, 11/80, d1=0.64031, d2=0.54307 g=1.07781\n",
      ">8, 13/80, d1=0.62150, d2=0.54964 g=1.04315\n",
      ">8, 15/80, d1=0.57782, d2=0.54283 g=1.04623\n",
      ">8, 17/80, d1=0.63059, d2=0.59515 g=0.96528\n",
      ">8, 19/80, d1=0.59685, d2=0.57200 g=1.01035\n",
      ">8, 21/80, d1=0.62116, d2=0.57003 g=1.03092\n",
      ">8, 23/80, d1=0.57594, d2=0.55271 g=1.06941\n",
      ">8, 25/80, d1=0.68188, d2=0.56409 g=1.06631\n",
      ">8, 27/80, d1=0.62494, d2=0.59119 g=1.04836\n",
      ">8, 29/80, d1=0.67722, d2=0.58930 g=1.00882\n",
      ">8, 31/80, d1=0.60638, d2=0.64353 g=0.96512\n",
      ">8, 33/80, d1=0.61344, d2=0.56680 g=1.03576\n",
      ">8, 35/80, d1=0.66755, d2=0.63656 g=1.07468\n",
      ">8, 37/80, d1=0.68320, d2=0.64624 g=1.14049\n",
      ">8, 39/80, d1=0.65006, d2=0.52649 g=1.09708\n",
      ">8, 41/80, d1=0.59576, d2=0.61680 g=1.08720\n",
      ">8, 43/80, d1=0.61461, d2=0.54843 g=1.14205\n",
      ">8, 45/80, d1=0.60469, d2=0.54066 g=1.21784\n",
      ">8, 47/80, d1=0.62872, d2=0.55633 g=1.08140\n",
      ">8, 49/80, d1=0.59667, d2=0.53752 g=1.08566\n",
      ">8, 51/80, d1=0.60563, d2=0.53800 g=1.06782\n",
      ">8, 53/80, d1=0.64417, d2=0.62424 g=1.04123\n",
      ">8, 55/80, d1=0.66334, d2=0.61818 g=0.99210\n",
      ">8, 57/80, d1=0.63715, d2=0.62949 g=0.97626\n",
      ">8, 59/80, d1=0.66658, d2=0.61333 g=1.01810\n",
      ">8, 61/80, d1=0.69224, d2=0.57885 g=0.98221\n",
      ">8, 63/80, d1=0.65895, d2=0.63891 g=1.00853\n",
      ">8, 65/80, d1=0.68041, d2=0.67699 g=1.11715\n",
      ">8, 67/80, d1=0.73258, d2=0.50795 g=1.18506\n",
      ">8, 69/80, d1=0.65181, d2=0.52298 g=1.16107\n",
      ">8, 71/80, d1=0.63826, d2=0.61714 g=1.07503\n",
      ">8, 73/80, d1=0.62285, d2=0.59927 g=0.99465\n",
      ">8, 75/80, d1=0.64046, d2=0.58428 g=1.00970\n",
      ">8, 77/80, d1=0.66815, d2=0.59390 g=1.00272\n",
      ">8, 79/80, d1=0.68396, d2=0.60318 g=1.13846\n",
      ">9, 1/80, d1=0.68541, d2=0.56787 g=1.18815\n",
      ">9, 3/80, d1=0.66500, d2=0.58668 g=1.19010\n",
      ">9, 5/80, d1=0.64351, d2=0.56328 g=1.02577\n",
      ">9, 7/80, d1=0.64803, d2=0.69876 g=1.02397\n",
      ">9, 9/80, d1=0.62995, d2=0.75989 g=1.02749\n",
      ">9, 11/80, d1=0.57685, d2=0.52402 g=1.16135\n",
      ">9, 13/80, d1=0.52066, d2=0.82808 g=1.30140\n",
      ">9, 15/80, d1=0.67952, d2=0.72013 g=1.37344\n",
      ">9, 17/80, d1=0.93124, d2=0.51450 g=1.37611\n",
      ">9, 19/80, d1=0.72018, d2=0.62332 g=1.02307\n",
      ">9, 21/80, d1=0.69150, d2=0.57271 g=1.06311\n",
      ">9, 23/80, d1=0.65321, d2=0.57206 g=1.05083\n",
      ">9, 25/80, d1=0.67404, d2=0.60156 g=0.98623\n",
      ">9, 27/80, d1=0.61051, d2=0.57200 g=1.05307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">9, 29/80, d1=0.57058, d2=0.60082 g=1.03519\n",
      ">9, 31/80, d1=0.59276, d2=0.56773 g=1.09799\n",
      ">9, 33/80, d1=0.72043, d2=0.58298 g=1.03624\n",
      ">9, 35/80, d1=0.61547, d2=0.52907 g=1.10154\n",
      ">9, 37/80, d1=0.64239, d2=0.59162 g=0.96762\n",
      ">9, 39/80, d1=0.58815, d2=0.57756 g=1.04566\n",
      ">9, 41/80, d1=0.61992, d2=0.61494 g=0.99443\n",
      ">9, 43/80, d1=0.62414, d2=0.57804 g=1.10081\n",
      ">9, 45/80, d1=0.64665, d2=0.55888 g=1.02679\n",
      ">9, 47/80, d1=0.56744, d2=0.64976 g=1.06552\n",
      ">9, 49/80, d1=0.64502, d2=0.65229 g=0.98186\n",
      ">9, 51/80, d1=0.65721, d2=0.56441 g=1.04757\n",
      ">9, 53/80, d1=0.66530, d2=0.57453 g=1.00242\n",
      ">9, 55/80, d1=0.64697, d2=0.59176 g=1.02734\n",
      ">9, 57/80, d1=0.71507, d2=0.56908 g=1.00631\n",
      ">9, 59/80, d1=0.66305, d2=0.57565 g=0.96522\n",
      ">9, 61/80, d1=0.60580, d2=0.59551 g=0.97146\n",
      ">9, 63/80, d1=0.68191, d2=0.60929 g=0.96899\n",
      ">9, 65/80, d1=0.67493, d2=0.63666 g=1.00297\n",
      ">9, 67/80, d1=0.67612, d2=0.58428 g=1.00954\n",
      ">9, 69/80, d1=0.68064, d2=0.61637 g=0.91228\n",
      ">9, 71/80, d1=0.67275, d2=0.59966 g=0.94729\n",
      ">9, 73/80, d1=0.65328, d2=0.61741 g=0.92181\n",
      ">9, 75/80, d1=0.64176, d2=0.59252 g=0.94666\n",
      ">9, 77/80, d1=0.68918, d2=0.59142 g=0.93007\n",
      ">9, 79/80, d1=0.63761, d2=0.56769 g=1.00518\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# size of the data\n",
    "data = 186\n",
    "# classes\n",
    "classes = 3\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "# multiples of three (three classes) (less thyan 24000)\n",
    "n_batch=300\n",
    "\n",
    "# Loss Values\n",
    "G_L = np.infty\n",
    "\n",
    "# create the discriminator\n",
    "d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "# d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "\n",
    "# create the generator\n",
    "g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "# g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "\n",
    "# create the gan\n",
    "gan_model = create_gan(d_model, g_model)\n",
    "\n",
    "folder_name = 'Final_CGAN_Beat_Label_Input_Working/'\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "plot_model(d_model, to_file=folder_name+'disc.pdf', show_shapes=True)\n",
    "plot_model(g_model, to_file=folder_name+'gen.pdf', show_shapes=True)\n",
    "plot_model(gan_model, to_file=folder_name+'gan.pdf', show_shapes=True)\n",
    "\n",
    "\n",
    "# load image data\n",
    "X_N, y_N, X_S, y_S, X_V, y_V = load_real_samples()\n",
    "# # train model\n",
    "# train(g_model, d_model, gan_model, dataset, latent_dim)\n",
    "\n",
    "bat_per_epo = int(y_S.shape[0] / n_batch)\n",
    "half_batch = int(n_batch / 2)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "    \n",
    "filename = folder_name + 'Plots'\n",
    "if not os.path.isdir(filename):\n",
    "    os.mkdir(filename)\n",
    "\n",
    "model_name = folder_name + 'Model/'\n",
    "if not os.path.isdir(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "f = open(folder_name + 'Loss.csv', 'w')\n",
    "f.write('d_loss1, d_loss2, g_loss \\n')\n",
    "f.close()\n",
    "\n",
    "f = open(folder_name + 'Stats.csv', 'w')\n",
    "for i in range(3):\n",
    "    for mtc in metric_to_calculate:\n",
    "        f.write(str(mtc)+'_'+str(i)+',')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# manually enumerate epochs\n",
    "for i in range(n_epochs):\n",
    "    # enumerate batches over the training set\n",
    "    for j in range(bat_per_epo):\n",
    "        \n",
    "        # get randomly selected 'real' samples\n",
    "        [X_real, labels_real], y_real = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, half_batch)\n",
    "        # print (X_real.shape, labels_real.shape, y_real.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "        \n",
    "        # generate 'fake' examples\n",
    "        [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # print (X_fake.shape, labels.shape, y_fake.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "        \n",
    "        # prepare points in latent space as input for the generator\n",
    "        [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "        [X, _], _ = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_batch)\n",
    "        # print (z_input.shape)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = reshape(np.random.uniform(0.8, 1, n_batch))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "        \n",
    "        if g_loss < G_L:\n",
    "            G_L = g_loss\n",
    "            g_model.save(model_name + str(i*1000 + j) + '_cgan_generator.h5')\n",
    "\n",
    "        f = open(folder_name + 'Loss.csv', 'a')\n",
    "        f.write(str(d_loss1)+','+str(d_loss2)+','+str(g_loss)+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        if (j+1)%2 == 0:\n",
    "            print('>%d, %d/%d, d1=%.5f, d2=%.5f g=%.5f' %(i, j, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "            name = filename+'/'+str(i*1000 + j)+'.jpg'\n",
    "            # generate ECGs\n",
    "            z_input  = g_model.predict([z_input, labels_input])\n",
    "            X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "            save_new_plot(X_R, z_input, n_batch, name)\n",
    "            \n",
    "#         if (j+1)%10 == 0:\n",
    "#             evaluate(X, z_input, classes, metric_to_calculate, n_batch, folder_name, samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-welsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "innovative-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = filename + '/'+str(i*1000 + j)+'.jpg'\n",
    "# # generate images\n",
    "# latent_points, labels = generate_latent_points(latent_dim, n*n)\n",
    "# # specify labels\n",
    "# [X, labels], y = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n*n)\n",
    "# # generate images\n",
    "# X  = g_model.predict([latent_points, X])\n",
    "# X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "# X = np.vstack((X_R, X))\n",
    "# save_new_plot(X, n+1, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "animated-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(filename+'_Stats.csv', 'a')\n",
    "# for k,metric in enumerate(label_dict.keys()):    \n",
    "#     temp_x = test_data[200*(k):200*(k+1),:-1]\n",
    "#     [z_input, labels_input] = generate_class_specific_latent_input(200, n_classes=n_classes, noise_dim=noise_dim, category=float(metric))\n",
    "#     z_input = G.predict([z_input, labels_input], verbose=verbose)\n",
    "\n",
    "#     for j in range(2):\n",
    "#         plt.plot(z_input[j])\n",
    "#     plt.savefig(data_dir+str(i)+'_Label_'+str(metric)+'.png')\n",
    "#     plt.close()\n",
    "#     plt.clf()\n",
    "\n",
    "#     results = evaluate(temp_x,z_input,metric_to_calculate)\n",
    "#     for r in results:\n",
    "#         f.write(str(r)+',')\n",
    "\n",
    "# f.write('\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sapphire-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_model(model, data_dir, type='G', epoch=1):\n",
    "#     json_name = data_dir+str(epoch)+'_'+type+'.json'\n",
    "#     h5name = data_dir+str(epoch)+'_'+type+'.h5'\n",
    "#     # serialize model to JSON\n",
    "#     model_json = model.to_json()\n",
    "#     with open(json_name, \"w\") as json_file:\n",
    "#         json_file.write(model_json)\n",
    "#     # serialize weights to HDF5\n",
    "#     model.save_weights(h5name)\n",
    "#     # print(\"Saved model to disk\")\n",
    "#     del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-hearing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "painful-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model=G, data_dir=data_dir, type='G', epoch=i)\n",
    "# #     # save the generator model\n",
    "#     g_model.save('cgan_generator.h5')\n",
    "\n",
    "# callback = [EarlyStopping(monitor='val_AUC', mode='max', verbose=1, patience=Pat),\n",
    "#          ModelCheckpoint(filepath=str(twelve_lead_model_filename)+'_check_model.h5', \n",
    "#                          monitor='val_AUC', verbose=1, save_best_only=True, mode='max'),\n",
    "#          ReduceLROnPlateau(monitor='val_AUC', factor=0.5, patience=Pat//2, verbose=1, \n",
    "#                            mode='max', min_delta=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "# # model = parallel_NN(WINDOW_SIZE,INPUT_FEAT,OUTPUT_CLASS):\n",
    "# model = parallel_NN(Window, len(leads), snomed_classes.shape[0])\n",
    "\n",
    "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "#               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy', dtype=None, threshold=0.5),\n",
    "#                        tf.keras.metrics.Recall(name='Recall'),\n",
    "#                        tf.keras.metrics.Precision(name='Precision'),\n",
    "#                        tf.keras.metrics.AUC(num_thresholds=200,summation_method=\"interpolation\",\n",
    "#                                             name=\"AUC\",dtype=None,curve=\"ROC\",thresholds=None,\n",
    "#                                             multi_label=True,label_weights=None)])\n",
    "# history = model.fit(train_generator, steps_per_epoch=train_samples, epochs=EP, verbose=1,\n",
    "#                 validation_data=val_generator, validation_steps=val_samples, callbacks=callback)\n",
    "\n",
    "\n",
    "# history_name = output_directory + '/' + twelve_lead_filename\n",
    "# print (twelve_lead_model_filename, history_name)\n",
    "\n",
    "# save_model(twelve_lead_model_filename, model)\n",
    "# write_history(history_name, history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
