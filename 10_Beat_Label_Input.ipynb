{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# example of training an conditional gan on the fashion mnist dataset\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import keras\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, multiply, Embedding, merge, Concatenate, Conv1D, BatchNormalization\n",
    "from keras.layers import Dense, Flatten, Multiply\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Add\n",
    "import tensorflow as tf\n",
    "from evaluation_metrics import *\n",
    "from helper import *\n",
    "metric_to_calculate = ['DTW', 'FID', 'TWED', 'RMSE', 'MMD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(data_dim, input_classes=3):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    x = Embedding(input_classes, 30)(in_label)\n",
    "    x = Dense(data_dim)(x)\n",
    "    x = Reshape((data_dim,1))(x)\n",
    "    \n",
    "    D_in = Input(shape=[data_dim,1])\n",
    "    inp1 = Concatenate()([D_in, x])\n",
    "\n",
    "    x = Conv1D(filters=48, kernel_size=19, padding='same', strides=4, kernel_initializer='he_normal')(inp1)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=15, padding='same', strides=3, kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=80, kernel_size=11, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=96, kernel_size=9, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv1D(filters=112, kernel_size=7, padding='same', strides=2, kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x1 = Conv1D(filters=48, kernel_size=9, padding='same', strides=4, kernel_initializer='he_normal')(inp1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=64, kernel_size=7, padding='same', strides=3, kernel_initializer='he_normal')(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=80, kernel_size=5, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=96, kernel_size=3, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = Conv1D(filters=112, kernel_size=3, padding='same', strides=2, kernel_initializer='he_normal')(x1)\n",
    "    x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "    x1 = GlobalAveragePooling1D()(x1)\n",
    "\n",
    "    xx = concatenate([x,x1])\n",
    "\n",
    "    xx = Dense(100)(xx)\n",
    "    xx = Dense(100)(xx)\n",
    "\n",
    "    out = Dense(1, activation='sigmoid')(xx)\n",
    "\n",
    "    model = Model(inputs=[D_in, in_label], outputs=out)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "    # model.summary()\n",
    "\n",
    "# d_model = discriminator(data_dim=186, input_classes=3)\n",
    "# plot_model(d_model, to_file='disc.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "northern-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim=186, input_classes=3, out_dim=186):\n",
    "    \n",
    "    in_label = Input(shape=(1,))\n",
    "    x = Embedding(input_classes, 30)(in_label)\n",
    "    x = Dense(noise_dim)(x)\n",
    "    x = Reshape((noise_dim,1))(x)\n",
    "    \n",
    "    G_in = Input(shape=[noise_dim,])\n",
    "    gen = Dense(noise_dim)(G_in)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((noise_dim,1))(gen)\n",
    "\n",
    "    x = Concatenate()([gen, x])\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*16, kernel_size=15, strides=1, padding='valid', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*8, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32*2, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling1D()(x)\n",
    "    x = Conv1D(filters=1, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "    out = Activation('tanh')(x)\n",
    "    model = Model(inputs=[G_in, in_label], outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "# g_model = generator(noise_dim=100, input_classes=3, out_dim=186)\n",
    "# plot_model(g_model, to_file='gen.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "written-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(d_model, g_model):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_beat = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_beat])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_beat], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# gan_model = create_gan(d_model, g_model)\n",
    "# plot_model(gan_model, to_file='gan.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "important-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        return X\n",
    "    else:\n",
    "        if X.shape[-1] == 1:\n",
    "            return X\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocal-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    X = np.load('Data/ForGAN/X.npy')\n",
    "    y = np.load('Data/ForGAN/y.npy')\n",
    "\n",
    "    # print (X.shape, y.shape)\n",
    "\n",
    "    X_N = X[y==0]\n",
    "    X_S = X[y==1]\n",
    "    X_V = X[y==2]\n",
    "\n",
    "    y_N = y[y==0]\n",
    "    y_S = y[y==1]\n",
    "    y_V = y[y==2]\n",
    "\n",
    "    return reshape(X_N), y_N, reshape(X_S), y_S, reshape(X_V), y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_samples):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], int(n_samples/3))\n",
    "    i_S = randint(0, y_S.shape[0], int(n_samples/3))\n",
    "    i_V = randint(0, y_V.shape[0], int(n_samples/3))\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    labels = np.hstack((y_N[i_N], y_S[i_S], y_V[i_V]))\n",
    "    # print (labels.shape)\n",
    "    \n",
    "    # generate class labels\n",
    "    y = reshape(np.random.uniform(0.8, 1, n_samples))\n",
    "\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bound-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "# normal noise\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=3):\n",
    "    # generate points in the latent space\n",
    "#     X_fake = np.random.uniform(0, 1.0, size=[n_samples, latent_dim])\n",
    "    X_fake = np.random.normal(0,1.0,(n_samples,latent_dim))\n",
    "    # generate labels\n",
    "    labels_fake = np.hstack((np.zeros(int(n_samples/3)), np.ones(int(n_samples/3)), 2*np.ones(int(n_samples/3))))\n",
    "    # np.random.shuffle(labels_fake)\n",
    "    return [reshape(X_fake), labels_fake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    ecgs = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = reshape(np.random.uniform(0, 0.2, n_samples))\n",
    "#     y = y.reshape(y.shape[0], 1)\n",
    "#     y = np.zeros((n_samples, 1))\n",
    "    return [ecgs, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "communist-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V):\n",
    "    \n",
    "    # choose random instances\n",
    "    i_N = randint(0, y_N.shape[0], 1)\n",
    "    i_S = randint(0, y_S.shape[0], 1)\n",
    "    i_V = randint(0, y_V.shape[0], 1)\n",
    "    \n",
    "    # select ECG and labels\n",
    "    X = np.vstack((X_N[i_N], X_S[i_S], X_V[i_V]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "speaking-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_plot(X_R, z_input, n_batch, name):\n",
    "    n = 3\n",
    "    Win = (n_batch//3)\n",
    "    XX = np.vstack((X_R, z_input[0:n,:,:], z_input[Win:Win+n,:,:], z_input[2*Win:2*Win+n,:,:]))\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(n):\n",
    "        # subplot(R, C, Plot_No)\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.plot(XX[i,:,:])\n",
    "    for i in range(n, ((n+1)*(n+1))-(n+1)):\n",
    "        # define subplot\n",
    "        plt.subplot(n+1, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.plot(XX[i,:,:])\n",
    "    # plt.show()\n",
    "    plt.savefig(name, dpi=75)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cubic-shirt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0, 1/80, d1=0.97522, d2=0.43001 g=1.63823\n",
      ">0, 3/80, d1=0.48443, d2=1.58549 g=0.54937\n",
      ">0, 5/80, d1=0.84997, d2=0.47714 g=1.29009\n",
      ">0, 7/80, d1=0.90097, d2=0.49759 g=1.13633\n",
      ">0, 9/80, d1=0.83619, d2=0.52573 g=1.09173\n",
      ">0, 11/80, d1=0.81130, d2=0.55323 g=0.96344\n",
      ">0, 13/80, d1=0.70176, d2=0.61745 g=0.81497\n",
      ">0, 15/80, d1=0.60712, d2=0.73726 g=0.80027\n",
      ">0, 17/80, d1=0.68371, d2=0.64074 g=0.82758\n",
      ">0, 19/80, d1=0.65289, d2=0.67242 g=0.75146\n",
      ">0, 21/80, d1=0.59441, d2=0.68014 g=0.76877\n",
      ">0, 23/80, d1=0.61299, d2=0.67304 g=0.82227\n",
      ">0, 25/80, d1=0.58950, d2=0.69590 g=0.77023\n",
      ">0, 27/80, d1=0.58716, d2=0.69152 g=0.75829\n",
      ">0, 29/80, d1=0.54684, d2=0.68724 g=0.78277\n",
      ">0, 31/80, d1=0.54449, d2=0.67366 g=0.82637\n",
      ">0, 33/80, d1=0.53516, d2=0.69575 g=0.77156\n",
      ">0, 35/80, d1=0.53041, d2=0.67395 g=0.77708\n",
      ">0, 37/80, d1=0.53781, d2=0.65614 g=0.83705\n",
      ">0, 39/80, d1=0.51355, d2=0.68894 g=0.81307\n",
      ">0, 41/80, d1=0.51715, d2=0.68891 g=0.79079\n",
      ">0, 43/80, d1=0.51935, d2=0.67032 g=0.83680\n",
      ">0, 45/80, d1=0.46738, d2=0.69818 g=0.84071\n",
      ">0, 47/80, d1=0.57950, d2=0.63202 g=0.83582\n",
      ">0, 49/80, d1=0.48833, d2=0.66502 g=0.85682\n",
      ">0, 51/80, d1=0.54152, d2=0.65814 g=0.86755\n",
      ">0, 53/80, d1=0.52241, d2=0.66420 g=0.89133\n",
      ">0, 55/80, d1=0.50895, d2=0.62887 g=1.17715\n",
      ">0, 57/80, d1=0.57359, d2=0.67967 g=0.92002\n",
      ">0, 59/80, d1=0.63941, d2=0.61673 g=0.90839\n",
      ">0, 61/80, d1=0.56624, d2=0.75834 g=0.89816\n",
      ">0, 63/80, d1=0.61638, d2=0.66399 g=1.00560\n",
      ">0, 65/80, d1=0.53766, d2=0.73248 g=0.80384\n",
      ">0, 67/80, d1=0.68750, d2=0.71244 g=1.05061\n",
      ">0, 69/80, d1=0.65693, d2=0.54119 g=1.12383\n",
      ">0, 71/80, d1=0.65177, d2=0.69345 g=1.13380\n",
      ">0, 73/80, d1=0.76569, d2=0.67160 g=0.90835\n",
      ">0, 75/80, d1=0.66529, d2=0.69183 g=0.85483\n",
      ">0, 77/80, d1=0.63100, d2=0.68107 g=0.85894\n",
      ">0, 79/80, d1=0.64503, d2=0.70427 g=0.90815\n",
      ">1, 1/80, d1=0.72441, d2=0.67282 g=0.86995\n",
      ">1, 3/80, d1=0.67471, d2=0.68550 g=0.87913\n",
      ">1, 5/80, d1=0.69367, d2=0.66742 g=0.88206\n",
      ">1, 7/80, d1=0.70715, d2=0.66001 g=0.85530\n",
      ">1, 9/80, d1=0.62469, d2=0.69396 g=0.81702\n",
      ">1, 11/80, d1=0.67765, d2=0.66502 g=0.92889\n",
      ">1, 13/80, d1=0.67319, d2=0.65733 g=0.82960\n",
      ">1, 15/80, d1=0.63341, d2=0.67523 g=0.83568\n",
      ">1, 17/80, d1=0.66258, d2=0.69458 g=0.84143\n",
      ">1, 19/80, d1=0.64578, d2=0.66726 g=0.83279\n",
      ">1, 21/80, d1=0.62613, d2=0.70687 g=0.81109\n",
      ">1, 23/80, d1=0.63362, d2=0.68392 g=0.84996\n",
      ">1, 25/80, d1=0.63734, d2=0.65854 g=0.86792\n",
      ">1, 27/80, d1=0.60810, d2=0.67472 g=0.82088\n",
      ">1, 29/80, d1=0.57706, d2=0.69404 g=0.83539\n",
      ">1, 31/80, d1=0.62393, d2=0.65873 g=0.86454\n",
      ">1, 33/80, d1=0.58822, d2=0.68887 g=0.90468\n",
      ">1, 35/80, d1=0.71069, d2=0.59284 g=1.00087\n",
      ">1, 37/80, d1=0.69656, d2=0.64442 g=0.89348\n",
      ">1, 39/80, d1=0.63931, d2=0.56193 g=1.05120\n",
      ">1, 41/80, d1=0.70781, d2=0.57706 g=1.13537\n",
      ">1, 43/80, d1=0.74429, d2=0.55144 g=1.06297\n",
      ">1, 45/80, d1=0.65170, d2=0.69674 g=0.94305\n",
      ">1, 47/80, d1=0.54343, d2=0.60842 g=0.85773\n",
      ">1, 49/80, d1=0.47828, d2=0.65412 g=0.91724\n",
      ">1, 51/80, d1=0.58193, d2=0.81638 g=1.18714\n",
      ">1, 53/80, d1=0.74740, d2=0.55605 g=1.38359\n",
      ">1, 55/80, d1=0.69385, d2=0.49498 g=1.56476\n",
      ">1, 57/80, d1=0.60963, d2=0.50426 g=1.45241\n",
      ">1, 59/80, d1=0.64646, d2=0.37074 g=1.69209\n",
      ">1, 61/80, d1=0.50556, d2=0.57407 g=1.90300\n",
      ">1, 63/80, d1=0.81966, d2=0.37391 g=1.66477\n",
      ">1, 65/80, d1=0.46631, d2=0.76138 g=1.45317\n",
      ">1, 67/80, d1=0.59944, d2=0.36636 g=1.76992\n",
      ">1, 69/80, d1=0.53639, d2=0.48318 g=1.74241\n",
      ">1, 71/80, d1=0.67804, d2=0.38912 g=1.86632\n",
      ">1, 73/80, d1=0.53194, d2=0.39271 g=1.77126\n",
      ">1, 75/80, d1=0.44667, d2=0.39286 g=1.88884\n",
      ">1, 77/80, d1=0.46054, d2=0.39875 g=1.94583\n",
      ">1, 79/80, d1=0.44895, d2=0.40095 g=1.90335\n",
      ">2, 1/80, d1=0.45679, d2=0.43310 g=2.02570\n",
      ">2, 3/80, d1=0.49078, d2=0.38873 g=1.86120\n",
      ">2, 5/80, d1=0.48915, d2=0.44475 g=1.94891\n",
      ">2, 7/80, d1=0.50233, d2=0.42264 g=1.85587\n",
      ">2, 9/80, d1=0.50204, d2=0.42021 g=1.89076\n",
      ">2, 11/80, d1=0.52982, d2=0.35381 g=1.86570\n",
      ">2, 13/80, d1=0.47346, d2=0.39284 g=2.00261\n",
      ">2, 15/80, d1=0.49894, d2=0.46339 g=2.06803\n",
      ">2, 17/80, d1=0.58917, d2=0.55479 g=2.00606\n",
      ">2, 19/80, d1=0.55709, d2=1.01194 g=2.37536\n",
      ">2, 21/80, d1=0.66288, d2=0.49068 g=1.18400\n",
      ">2, 23/80, d1=0.59076, d2=0.71609 g=1.11445\n",
      ">2, 25/80, d1=0.57965, d2=0.51477 g=1.17004\n",
      ">2, 27/80, d1=0.55353, d2=0.54896 g=1.21908\n",
      ">2, 29/80, d1=0.54741, d2=0.52976 g=1.18169\n",
      ">2, 31/80, d1=0.56106, d2=0.66733 g=1.18546\n",
      ">2, 33/80, d1=0.60505, d2=0.63401 g=0.99355\n",
      ">2, 35/80, d1=0.62288, d2=0.55851 g=1.12454\n",
      ">2, 37/80, d1=0.57643, d2=0.61945 g=1.17367\n",
      ">2, 39/80, d1=0.60177, d2=0.53147 g=1.05790\n",
      ">2, 41/80, d1=0.51587, d2=0.59300 g=1.25005\n",
      ">2, 43/80, d1=0.49951, d2=0.72198 g=1.21335\n",
      ">2, 45/80, d1=0.61533, d2=0.62915 g=1.13862\n",
      ">2, 47/80, d1=0.61189, d2=0.69123 g=0.87472\n",
      ">2, 49/80, d1=0.58674, d2=0.64483 g=0.93475\n",
      ">2, 51/80, d1=0.53664, d2=0.64736 g=0.99669\n",
      ">2, 53/80, d1=0.53343, d2=0.66398 g=1.02020\n",
      ">2, 55/80, d1=0.64318, d2=0.69842 g=0.99493\n",
      ">2, 57/80, d1=0.62661, d2=0.64733 g=1.07440\n",
      ">2, 59/80, d1=0.63014, d2=0.70292 g=0.95879\n",
      ">2, 61/80, d1=0.63912, d2=0.74743 g=0.87523\n",
      ">2, 63/80, d1=0.59786, d2=0.73205 g=0.92422\n",
      ">2, 65/80, d1=0.60067, d2=0.69688 g=0.95022\n",
      ">2, 67/80, d1=0.62543, d2=0.80542 g=0.94632\n",
      ">2, 69/80, d1=0.72609, d2=0.70987 g=1.02040\n",
      ">2, 71/80, d1=0.75634, d2=0.64425 g=0.96011\n",
      ">2, 73/80, d1=0.72937, d2=0.64612 g=0.97036\n",
      ">2, 75/80, d1=0.68068, d2=0.65516 g=0.91484\n",
      ">2, 77/80, d1=0.66591, d2=0.68367 g=0.84371\n",
      ">2, 79/80, d1=0.62560, d2=0.70197 g=0.81766\n",
      ">3, 1/80, d1=0.63203, d2=0.67690 g=0.83503\n",
      ">3, 3/80, d1=0.61640, d2=0.66477 g=0.86929\n",
      ">3, 5/80, d1=0.58718, d2=0.69253 g=0.83784\n",
      ">3, 7/80, d1=0.65900, d2=0.70127 g=0.90805\n",
      ">3, 9/80, d1=0.71708, d2=0.60770 g=0.96653\n",
      ">3, 11/80, d1=0.67741, d2=0.61284 g=0.99069\n",
      ">3, 13/80, d1=0.67290, d2=0.60395 g=0.97205\n",
      ">3, 15/80, d1=0.67045, d2=0.67277 g=0.86497\n",
      ">3, 17/80, d1=0.68757, d2=0.77976 g=0.80529\n",
      ">3, 19/80, d1=0.60877, d2=0.72957 g=0.83996\n",
      ">3, 21/80, d1=0.58235, d2=0.62630 g=0.91714\n",
      ">3, 23/80, d1=0.58285, d2=0.76992 g=0.92283\n",
      ">3, 25/80, d1=0.72323, d2=0.78814 g=0.99964\n",
      ">3, 27/80, d1=0.86553, d2=0.55832 g=1.10793\n",
      ">3, 29/80, d1=0.76825, d2=0.54516 g=1.06786\n",
      ">3, 31/80, d1=0.69180, d2=0.60126 g=0.98271\n",
      ">3, 33/80, d1=0.74130, d2=0.59917 g=0.97046\n",
      ">3, 35/80, d1=0.66437, d2=0.65198 g=0.83800\n",
      ">3, 37/80, d1=0.63903, d2=0.66201 g=0.84585\n",
      ">3, 39/80, d1=0.65430, d2=0.64399 g=0.85061\n",
      ">3, 41/80, d1=0.68624, d2=0.63359 g=0.86491\n",
      ">3, 43/80, d1=0.62265, d2=0.64770 g=0.85836\n",
      ">3, 45/80, d1=0.65377, d2=0.63162 g=0.88616\n",
      ">3, 47/80, d1=0.66712, d2=0.65837 g=0.87450\n",
      ">3, 49/80, d1=0.64905, d2=0.63161 g=0.83537\n",
      ">3, 51/80, d1=0.70669, d2=0.69101 g=0.86487\n",
      ">3, 53/80, d1=0.63763, d2=0.64425 g=0.92473\n",
      ">3, 55/80, d1=0.61878, d2=0.76771 g=0.83830\n",
      ">3, 57/80, d1=0.78299, d2=0.60265 g=1.04918\n",
      ">3, 59/80, d1=0.76677, d2=0.61357 g=0.94019\n",
      ">3, 61/80, d1=0.68872, d2=0.61173 g=0.93069\n",
      ">3, 63/80, d1=0.65211, d2=0.66053 g=0.87690\n",
      ">3, 65/80, d1=0.66063, d2=0.64595 g=0.90035\n",
      ">3, 67/80, d1=0.64890, d2=0.62815 g=0.89600\n",
      ">3, 69/80, d1=0.64364, d2=0.60921 g=0.92156\n",
      ">3, 71/80, d1=0.61536, d2=0.62399 g=0.91417\n",
      ">3, 73/80, d1=0.62992, d2=0.62851 g=0.89271\n",
      ">3, 75/80, d1=0.65318, d2=0.63952 g=0.95611\n",
      ">3, 77/80, d1=0.65310, d2=0.55245 g=1.04955\n",
      ">3, 79/80, d1=0.66607, d2=0.63458 g=0.91911\n",
      ">4, 1/80, d1=0.57829, d2=0.81153 g=0.94637\n",
      ">4, 3/80, d1=0.61690, d2=0.58342 g=0.98844\n",
      ">4, 5/80, d1=0.58384, d2=0.76144 g=1.00692\n",
      ">4, 7/80, d1=0.77213, d2=0.51465 g=1.20679\n",
      ">4, 9/80, d1=0.69342, d2=0.61130 g=1.03208\n",
      ">4, 11/80, d1=0.68380, d2=0.55967 g=1.06065\n",
      ">4, 13/80, d1=0.60378, d2=0.64455 g=0.93345\n",
      ">4, 15/80, d1=0.60847, d2=0.61522 g=1.00228\n",
      ">4, 17/80, d1=0.62875, d2=0.52406 g=1.07932\n",
      ">4, 19/80, d1=0.61475, d2=0.66536 g=1.00787\n",
      ">4, 21/80, d1=0.63487, d2=0.56576 g=1.11641\n",
      ">4, 23/80, d1=0.55877, d2=0.65606 g=1.01142\n",
      ">4, 25/80, d1=0.77990, d2=0.59958 g=1.18444\n",
      ">4, 27/80, d1=0.69894, d2=0.55411 g=1.19529\n",
      ">4, 29/80, d1=0.71788, d2=0.47134 g=1.39520\n",
      ">4, 31/80, d1=0.66897, d2=0.56324 g=1.20179\n",
      ">4, 33/80, d1=0.63623, d2=0.58159 g=0.94871\n",
      ">4, 35/80, d1=0.60239, d2=0.60351 g=0.99980\n",
      ">4, 37/80, d1=0.54553, d2=0.59232 g=1.00470\n",
      ">4, 39/80, d1=0.60938, d2=0.61571 g=0.96851\n",
      ">4, 41/80, d1=0.58711, d2=0.58061 g=1.07675\n",
      ">4, 43/80, d1=0.63433, d2=0.57450 g=1.05971\n",
      ">4, 45/80, d1=0.60876, d2=0.55822 g=1.10343\n",
      ">4, 47/80, d1=0.59186, d2=0.59377 g=1.01891\n",
      ">4, 49/80, d1=0.60788, d2=0.56543 g=1.03263\n",
      ">4, 51/80, d1=0.62477, d2=0.61421 g=1.00632\n",
      ">4, 53/80, d1=0.58538, d2=0.60169 g=1.04242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4, 55/80, d1=0.63977, d2=0.57898 g=1.09245\n",
      ">4, 57/80, d1=0.58832, d2=0.55895 g=1.13440\n",
      ">4, 59/80, d1=0.60127, d2=0.54034 g=1.06825\n",
      ">4, 61/80, d1=0.62110, d2=0.58272 g=1.07938\n",
      ">4, 63/80, d1=0.54955, d2=0.58568 g=1.10010\n",
      ">4, 65/80, d1=0.59350, d2=0.61725 g=1.11098\n",
      ">4, 67/80, d1=0.64303, d2=0.56220 g=1.04707\n",
      ">4, 69/80, d1=0.66289, d2=0.54832 g=1.14408\n",
      ">4, 71/80, d1=0.62512, d2=0.62736 g=1.05758\n",
      ">4, 73/80, d1=0.63646, d2=0.57785 g=1.05733\n",
      ">4, 75/80, d1=0.65089, d2=0.54741 g=1.06115\n",
      ">4, 77/80, d1=0.64254, d2=0.74115 g=1.11587\n",
      ">4, 79/80, d1=0.73462, d2=0.56038 g=1.06260\n",
      ">5, 1/80, d1=1.01264, d2=0.55629 g=1.14641\n",
      ">5, 3/80, d1=0.67236, d2=0.62022 g=0.98863\n",
      ">5, 5/80, d1=0.66290, d2=0.62633 g=0.98415\n",
      ">5, 7/80, d1=0.74153, d2=0.62376 g=1.04844\n",
      ">5, 9/80, d1=0.59975, d2=0.55760 g=1.02636\n",
      ">5, 11/80, d1=0.64611, d2=0.75926 g=1.31862\n",
      ">5, 13/80, d1=0.82204, d2=0.53660 g=1.19180\n",
      ">5, 15/80, d1=0.68950, d2=0.66401 g=0.94101\n",
      ">5, 17/80, d1=0.68964, d2=0.57958 g=0.95345\n",
      ">5, 19/80, d1=0.62559, d2=0.59665 g=0.92338\n",
      ">5, 21/80, d1=0.65536, d2=0.66086 g=0.90600\n",
      ">5, 23/80, d1=0.68639, d2=0.60944 g=0.98395\n",
      ">5, 25/80, d1=0.66206, d2=0.59715 g=0.94369\n",
      ">5, 27/80, d1=0.66108, d2=0.63837 g=0.95151\n",
      ">5, 29/80, d1=0.64304, d2=0.52804 g=1.06978\n",
      ">5, 31/80, d1=0.64620, d2=0.63712 g=0.94734\n",
      ">5, 33/80, d1=0.62920, d2=0.56806 g=1.02502\n",
      ">5, 35/80, d1=0.63481, d2=0.57633 g=1.05898\n",
      ">5, 37/80, d1=0.63907, d2=0.77304 g=1.00639\n",
      ">5, 39/80, d1=0.68754, d2=0.53713 g=1.11781\n",
      ">5, 41/80, d1=0.64823, d2=0.56404 g=1.05325\n",
      ">5, 43/80, d1=0.68668, d2=0.65206 g=0.99401\n",
      ">5, 45/80, d1=0.64142, d2=0.52974 g=1.08756\n",
      ">5, 47/80, d1=0.65840, d2=0.54951 g=1.02842\n",
      ">5, 49/80, d1=0.60111, d2=0.61154 g=0.95910\n",
      ">5, 51/80, d1=0.64900, d2=0.59289 g=1.02180\n",
      ">5, 53/80, d1=0.68259, d2=0.52642 g=1.05695\n",
      ">5, 55/80, d1=0.61838, d2=0.59178 g=1.00188\n",
      ">5, 57/80, d1=0.64176, d2=0.59693 g=1.00921\n",
      ">5, 59/80, d1=0.61063, d2=0.53393 g=1.05959\n",
      ">5, 61/80, d1=0.60485, d2=0.67556 g=1.11864\n",
      ">5, 63/80, d1=0.62545, d2=0.68934 g=0.99360\n",
      ">5, 65/80, d1=0.70489, d2=0.58430 g=1.18653\n",
      ">5, 67/80, d1=0.68184, d2=0.57272 g=1.02794\n",
      ">5, 69/80, d1=0.65043, d2=0.60861 g=0.97612\n",
      ">5, 71/80, d1=0.64601, d2=0.55320 g=1.01680\n",
      ">5, 73/80, d1=0.59742, d2=0.62960 g=1.00728\n",
      ">5, 75/80, d1=0.65708, d2=0.63681 g=0.98971\n",
      ">5, 77/80, d1=0.67738, d2=0.60162 g=1.04041\n",
      ">5, 79/80, d1=0.79178, d2=0.62760 g=1.01884\n",
      ">6, 1/80, d1=0.74753, d2=0.57884 g=1.03211\n",
      ">6, 3/80, d1=0.70938, d2=0.57288 g=0.97545\n",
      ">6, 5/80, d1=0.68783, d2=0.59380 g=0.98408\n",
      ">6, 7/80, d1=0.63936, d2=0.60042 g=0.95082\n",
      ">6, 9/80, d1=0.66338, d2=0.57274 g=1.03514\n",
      ">6, 11/80, d1=0.63416, d2=0.58038 g=1.01908\n",
      ">6, 13/80, d1=0.63252, d2=0.58578 g=0.97921\n",
      ">6, 15/80, d1=0.63435, d2=0.59111 g=0.95246\n",
      ">6, 17/80, d1=0.63534, d2=0.61737 g=0.94968\n",
      ">6, 19/80, d1=0.62969, d2=0.60710 g=0.98393\n",
      ">6, 21/80, d1=0.63962, d2=0.58890 g=1.00853\n",
      ">6, 23/80, d1=0.58892, d2=0.56135 g=0.99955\n",
      ">6, 25/80, d1=0.63180, d2=0.56576 g=1.03630\n",
      ">6, 27/80, d1=0.58070, d2=0.54519 g=1.02356\n",
      ">6, 29/80, d1=0.65635, d2=0.53469 g=1.02512\n",
      ">6, 31/80, d1=0.64162, d2=0.59816 g=1.02022\n",
      ">6, 33/80, d1=0.63554, d2=0.55666 g=1.13969\n",
      ">6, 35/80, d1=0.71359, d2=0.51442 g=1.07446\n",
      ">6, 37/80, d1=0.72782, d2=0.57276 g=1.05378\n",
      ">6, 39/80, d1=0.62089, d2=0.55989 g=1.10430\n",
      ">6, 41/80, d1=0.61562, d2=0.57104 g=1.05412\n",
      ">6, 43/80, d1=0.72490, d2=0.52572 g=1.07844\n",
      ">6, 45/80, d1=0.60195, d2=0.65276 g=0.98584\n",
      ">6, 47/80, d1=0.61810, d2=0.55330 g=1.01933\n",
      ">6, 49/80, d1=0.59925, d2=0.59428 g=1.03447\n",
      ">6, 51/80, d1=0.59355, d2=0.62635 g=1.01606\n",
      ">6, 53/80, d1=0.62774, d2=0.53978 g=1.01108\n",
      ">6, 55/80, d1=0.63823, d2=0.62234 g=0.97365\n",
      ">6, 57/80, d1=0.68526, d2=0.59347 g=1.20347\n",
      ">6, 59/80, d1=0.69959, d2=0.76439 g=1.19420\n",
      ">6, 61/80, d1=0.73479, d2=0.57570 g=1.03059\n",
      ">6, 63/80, d1=0.69673, d2=0.53666 g=1.09497\n",
      ">6, 65/80, d1=0.61390, d2=0.62637 g=1.05787\n",
      ">6, 67/80, d1=0.68466, d2=0.62586 g=1.07153\n",
      ">6, 69/80, d1=0.65813, d2=0.56368 g=1.07437\n",
      ">6, 71/80, d1=0.63256, d2=0.56629 g=0.98001\n",
      ">6, 73/80, d1=0.60678, d2=0.61832 g=0.97403\n",
      ">6, 75/80, d1=0.61844, d2=0.57755 g=1.01878\n",
      ">6, 77/80, d1=0.61025, d2=0.59507 g=1.02265\n",
      ">6, 79/80, d1=0.66446, d2=0.59425 g=0.95854\n",
      ">7, 1/80, d1=0.64412, d2=0.58266 g=0.93589\n",
      ">7, 3/80, d1=0.62426, d2=0.59444 g=0.98537\n",
      ">7, 5/80, d1=0.66492, d2=0.59516 g=0.97911\n",
      ">7, 7/80, d1=0.61010, d2=0.60971 g=0.98558\n",
      ">7, 9/80, d1=0.63045, d2=0.59663 g=1.01226\n",
      ">7, 11/80, d1=0.69895, d2=0.62059 g=0.97690\n",
      ">7, 13/80, d1=0.65019, d2=0.63050 g=0.99955\n",
      ">7, 15/80, d1=0.65513, d2=0.58829 g=1.01940\n",
      ">7, 17/80, d1=0.64148, d2=0.54237 g=1.04499\n",
      ">7, 19/80, d1=0.62415, d2=0.67787 g=0.97776\n",
      ">7, 21/80, d1=0.73143, d2=0.67410 g=0.96408\n",
      ">7, 23/80, d1=0.63672, d2=0.57027 g=1.00587\n",
      ">7, 25/80, d1=0.61854, d2=0.63747 g=1.03769\n",
      ">7, 27/80, d1=0.72759, d2=0.56360 g=1.07386\n",
      ">7, 29/80, d1=0.70773, d2=0.58318 g=1.01483\n",
      ">7, 31/80, d1=0.63252, d2=0.59424 g=0.96901\n",
      ">7, 33/80, d1=0.65453, d2=0.59405 g=1.02293\n",
      ">7, 35/80, d1=0.66153, d2=0.61885 g=1.03193\n",
      ">7, 37/80, d1=0.67203, d2=0.59023 g=1.05121\n",
      ">7, 39/80, d1=0.67957, d2=0.55957 g=1.03326\n",
      ">7, 41/80, d1=0.63124, d2=0.60972 g=0.96403\n",
      ">7, 43/80, d1=0.66524, d2=0.77636 g=1.41195\n",
      ">7, 45/80, d1=0.65661, d2=0.67107 g=1.00948\n",
      ">7, 47/80, d1=0.69441, d2=0.60754 g=1.14586\n",
      ">7, 49/80, d1=0.70018, d2=0.57930 g=1.02957\n",
      ">7, 51/80, d1=0.68499, d2=0.53448 g=1.11176\n",
      ">7, 53/80, d1=0.64823, d2=0.51893 g=1.08302\n",
      ">7, 55/80, d1=0.59707, d2=0.58878 g=0.97347\n",
      ">7, 57/80, d1=0.61989, d2=0.56087 g=1.08571\n",
      ">7, 59/80, d1=0.63524, d2=0.51352 g=1.04382\n",
      ">7, 61/80, d1=0.60254, d2=0.56097 g=0.99746\n",
      ">7, 63/80, d1=0.57602, d2=0.54357 g=1.07716\n",
      ">7, 65/80, d1=0.61399, d2=0.53702 g=1.07641\n",
      ">7, 67/80, d1=0.62654, d2=0.54842 g=1.05631\n",
      ">7, 69/80, d1=0.63362, d2=0.53106 g=1.05077\n",
      ">7, 71/80, d1=0.63154, d2=0.52832 g=1.07539\n",
      ">7, 73/80, d1=0.60402, d2=0.56445 g=1.02195\n",
      ">7, 75/80, d1=0.61278, d2=0.54534 g=1.07267\n",
      ">7, 77/80, d1=0.61937, d2=0.62486 g=1.05748\n",
      ">7, 79/80, d1=0.64541, d2=0.56083 g=1.08466\n",
      ">8, 1/80, d1=0.60604, d2=0.55360 g=1.13482\n",
      ">8, 3/80, d1=0.62856, d2=0.60432 g=1.05766\n",
      ">8, 5/80, d1=0.65521, d2=0.62320 g=1.25788\n",
      ">8, 7/80, d1=0.71985, d2=0.59109 g=1.18273\n",
      ">8, 9/80, d1=0.61143, d2=0.58073 g=1.17161\n",
      ">8, 11/80, d1=0.68832, d2=0.63521 g=1.18308\n",
      ">8, 13/80, d1=0.55852, d2=1.00419 g=1.43358\n",
      ">8, 15/80, d1=0.97756, d2=0.53215 g=1.23385\n",
      ">8, 17/80, d1=0.68201, d2=0.67914 g=1.00985\n",
      ">8, 19/80, d1=0.77368, d2=0.60540 g=1.02834\n",
      ">8, 21/80, d1=0.68740, d2=0.53853 g=1.07320\n",
      ">8, 23/80, d1=0.66649, d2=0.57176 g=0.95119\n",
      ">8, 25/80, d1=0.64257, d2=0.57085 g=0.97984\n",
      ">8, 27/80, d1=0.62468, d2=0.62965 g=0.96361\n",
      ">8, 29/80, d1=0.62387, d2=0.76478 g=0.99164\n",
      ">8, 31/80, d1=0.63988, d2=0.47351 g=1.29628\n",
      ">8, 33/80, d1=0.58619, d2=0.72918 g=1.21357\n",
      ">8, 35/80, d1=0.69842, d2=0.60467 g=1.25977\n",
      ">8, 37/80, d1=0.83954, d2=0.55892 g=1.48407\n",
      ">8, 39/80, d1=0.78673, d2=0.43669 g=1.47310\n",
      ">8, 41/80, d1=0.67983, d2=0.59914 g=0.99263\n",
      ">8, 43/80, d1=0.61590, d2=0.76123 g=0.93819\n",
      ">8, 45/80, d1=0.72842, d2=0.52029 g=1.14269\n",
      ">8, 47/80, d1=0.57824, d2=0.51446 g=1.13716\n",
      ">8, 49/80, d1=0.54938, d2=0.48353 g=1.09738\n",
      ">8, 51/80, d1=0.49026, d2=0.86736 g=1.01370\n",
      ">8, 53/80, d1=0.78120, d2=0.57169 g=1.16245\n",
      ">8, 55/80, d1=0.69475, d2=0.53883 g=1.17616\n",
      ">8, 57/80, d1=0.68861, d2=0.53209 g=1.10412\n",
      ">8, 59/80, d1=0.62122, d2=0.53670 g=1.03633\n",
      ">8, 61/80, d1=0.59994, d2=0.56562 g=0.99976\n",
      ">8, 63/80, d1=0.61378, d2=0.57274 g=1.01210\n",
      ">8, 65/80, d1=0.56800, d2=0.54464 g=1.05257\n",
      ">8, 67/80, d1=0.57923, d2=0.53953 g=1.02076\n",
      ">8, 69/80, d1=0.57297, d2=0.53056 g=1.03742\n",
      ">8, 71/80, d1=0.60263, d2=0.54608 g=1.00205\n",
      ">8, 73/80, d1=0.57141, d2=0.55412 g=1.08539\n",
      ">8, 75/80, d1=0.61524, d2=0.52098 g=1.17157\n",
      ">8, 77/80, d1=0.63594, d2=0.53238 g=1.11290\n",
      ">8, 79/80, d1=0.60402, d2=0.56748 g=1.11915\n",
      ">9, 1/80, d1=0.62750, d2=0.58278 g=1.13042\n",
      ">9, 3/80, d1=0.60340, d2=0.51022 g=1.15178\n",
      ">9, 5/80, d1=0.55186, d2=0.52602 g=1.12061\n",
      ">9, 7/80, d1=0.50412, d2=0.52714 g=1.40561\n",
      ">9, 9/80, d1=0.48133, d2=0.45352 g=1.46772\n",
      ">9, 11/80, d1=0.50432, d2=1.00665 g=1.51147\n",
      ">9, 13/80, d1=0.76766, d2=0.56819 g=1.21304\n",
      ">9, 15/80, d1=0.70357, d2=0.61872 g=1.26046\n",
      ">9, 17/80, d1=0.72872, d2=0.57821 g=1.24828\n",
      ">9, 19/80, d1=0.79448, d2=0.62586 g=1.12182\n",
      ">9, 21/80, d1=0.77541, d2=0.51882 g=1.16259\n",
      ">9, 23/80, d1=0.66312, d2=0.53110 g=1.09077\n",
      ">9, 25/80, d1=0.59342, d2=0.55003 g=1.03917\n",
      ">9, 27/80, d1=0.59482, d2=0.53320 g=1.08154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">9, 29/80, d1=0.59178, d2=0.52512 g=1.07994\n",
      ">9, 31/80, d1=0.61380, d2=0.52748 g=1.05297\n",
      ">9, 33/80, d1=0.60146, d2=0.53723 g=1.07683\n",
      ">9, 35/80, d1=0.56691, d2=0.52756 g=1.10895\n",
      ">9, 37/80, d1=0.57610, d2=0.56061 g=1.09297\n",
      ">9, 39/80, d1=0.67088, d2=0.60951 g=1.08345\n",
      ">9, 41/80, d1=0.62852, d2=0.59275 g=1.15005\n",
      ">9, 43/80, d1=0.68393, d2=0.52137 g=1.10786\n",
      ">9, 45/80, d1=0.64437, d2=0.57651 g=1.19450\n",
      ">9, 47/80, d1=0.66319, d2=0.58293 g=1.13141\n",
      ">9, 49/80, d1=0.69238, d2=0.52293 g=1.11529\n",
      ">9, 51/80, d1=0.65929, d2=0.52621 g=1.18219\n",
      ">9, 53/80, d1=0.66173, d2=0.59164 g=1.10044\n",
      ">9, 55/80, d1=0.68160, d2=0.51874 g=1.22773\n",
      ">9, 57/80, d1=0.62622, d2=0.67587 g=1.22710\n",
      ">9, 59/80, d1=0.65556, d2=0.60072 g=1.03850\n",
      ">9, 61/80, d1=0.67006, d2=0.53498 g=1.08084\n",
      ">9, 63/80, d1=0.59303, d2=0.56081 g=1.00967\n",
      ">9, 65/80, d1=0.60999, d2=0.53393 g=1.04618\n",
      ">9, 67/80, d1=0.62005, d2=0.53468 g=1.03580\n",
      ">9, 69/80, d1=0.61814, d2=0.52268 g=1.04088\n",
      ">9, 71/80, d1=0.63075, d2=0.55271 g=1.05624\n",
      ">9, 73/80, d1=0.64199, d2=0.54056 g=1.01948\n",
      ">9, 75/80, d1=0.60843, d2=0.61268 g=0.97327\n",
      ">9, 77/80, d1=0.68100, d2=0.53143 g=1.12089\n",
      ">9, 79/80, d1=0.66040, d2=0.56306 g=1.20583\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# size of the data\n",
    "data = 186\n",
    "# classes\n",
    "classes = 3\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "# multiples of three (three classes) (less thyan 24000)\n",
    "n_batch=300\n",
    "\n",
    "# Loss Values\n",
    "G_L = np.infty\n",
    "\n",
    "# create the discriminator\n",
    "d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "# d_model = discriminator(data_dim=data, input_classes=classes)\n",
    "\n",
    "# create the generator\n",
    "g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "# g_model = generator(noise_dim=latent_dim, input_classes=classes, out_dim=data)\n",
    "\n",
    "# create the gan\n",
    "gan_model = create_gan(d_model, g_model)\n",
    "\n",
    "folder_name = 'Final/Beat_Label_Input_New/'\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "plot_model(d_model, to_file=folder_name+'disc.pdf', show_shapes=True)\n",
    "plot_model(g_model, to_file=folder_name+'gen.pdf', show_shapes=True)\n",
    "plot_model(gan_model, to_file=folder_name+'gan.pdf', show_shapes=True)\n",
    "\n",
    "\n",
    "# load image data\n",
    "X_N, y_N, X_S, y_S, X_V, y_V = load_real_samples()\n",
    "# # train model\n",
    "# train(g_model, d_model, gan_model, dataset, latent_dim)\n",
    "\n",
    "bat_per_epo = int(y_S.shape[0] / n_batch)\n",
    "half_batch = int(n_batch / 2)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "    \n",
    "filename = folder_name + 'Plots'\n",
    "if not os.path.isdir(filename):\n",
    "    os.mkdir(filename)\n",
    "\n",
    "model_name = folder_name + 'Model/'\n",
    "if not os.path.isdir(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "f = open(folder_name + 'Loss.csv', 'w')\n",
    "f.write('d_loss1, d_loss2, g_loss \\n')\n",
    "f.close()\n",
    "\n",
    "f = open(folder_name + 'Stats.csv', 'w')\n",
    "for i in range(3):\n",
    "    for mtc in metric_to_calculate:\n",
    "        f.write(str(mtc)+'_'+str(i)+',')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# manually enumerate epochs\n",
    "for i in range(n_epochs):\n",
    "    # enumerate batches over the training set\n",
    "    for j in range(bat_per_epo):\n",
    "        \n",
    "        # get randomly selected 'real' samples\n",
    "        [X_real, labels_real], y_real = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, half_batch)\n",
    "        # print (X_real.shape, labels_real.shape, y_real.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "        \n",
    "        # generate 'fake' examples\n",
    "        [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # print (X_fake.shape, labels.shape, y_fake.shape)\n",
    "        # update discriminator model weights\n",
    "        d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "        \n",
    "        # prepare points in latent space as input for the generator\n",
    "        [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "        [X, _], _ = generate_real_samples(X_N, y_N, X_S, y_S, X_V, y_V, n_batch)\n",
    "        # print (z_input.shape)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = reshape(np.random.uniform(0.8, 1, n_batch))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "        \n",
    "#         if g_loss < G_L:\n",
    "#             G_L = g_loss\n",
    "#             g_model.save(model_name + str(i*1000 + j) + '_cgan_generator.h5')\n",
    "\n",
    "        f = open(folder_name + 'Loss.csv', 'a')\n",
    "        f.write(str(d_loss1)+','+str(d_loss2)+','+str(g_loss)+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        if (j+1)%2 == 0:\n",
    "            print('>%d, %d/%d, d1=%.5f, d2=%.5f g=%.5f' %(i, j, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "            name = filename+'/'+str(i*1000 + j)+'.jpg'\n",
    "            # generate ECGs\n",
    "            z_input  = g_model.predict([z_input, labels_input])\n",
    "            X_R = get_real_samples(X_N, y_N, X_S, y_S, X_V, y_V)\n",
    "            save_new_plot(X_R, z_input, n_batch, name)\n",
    "            g_model.save(model_name + str(i*1000 + j) + '_cgan_generator.h5')\n",
    "            \n",
    "        if (j+1)%10 == 0:\n",
    "            evaluate(X, z_input, classes, metric_to_calculate, n_batch, folder_name, samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-welsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
