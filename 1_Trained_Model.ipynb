{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pycm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from helper import *\n",
    "import keras as keras\n",
    "from pycm import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203187,) (203187, 186) (204775,) (204775, 186)\n",
      "(203187, 3) (203187, 186, 1) (204775, 3) (204775, 186, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('Data/test_data.npy')\n",
    "X_train = np.load('Data/train_data.npy')\n",
    "\n",
    "y_train = X_train[:,-1]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "y_test = X_test[:,-1]\n",
    "X_test = X_test[:,:-1]\n",
    "\n",
    "print (y_test.shape, X_test.shape, y_train.shape, X_train.shape)\n",
    "\n",
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print (y_test.shape, X_test.shape, y_train.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Gen = np.vstack((X_train, X_test))\n",
    "y_Gen = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407962, 186)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407962,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = Input(shape=(186,1), name='input')\n",
    "# x = Conv1D(filters=32, kernel_size=3, padding='same', strides=1, kernel_initializer='he_normal', activation='relu')(input1)\n",
    "# x = Flatten()(x)\n",
    "# # x = Dense(3)(x)\n",
    "# out = Dense(3, activation='softmax')(x)\n",
    "# model = Model(inputs=input1, outputs=out)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 186\n",
    "INPUT_FEAT = 1\n",
    "OUTPUT_CLASS = 3\n",
    "cb = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)]\n",
    "\n",
    "# earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "# mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "# ModelCheckpoint(filepath=str(cvset)+'/check_model.h5', monitor='val_loss', save_best_only=True),\n",
    "        \n",
    "# model.fit(Xtr_more, Ytr_more, batch_size=batch_size, epochs=50, verbose=0, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_1\n",
      "5120/5120 [==============================] - 100s 17ms/step - loss: 0.1835 - accuracy: 0.9509 - val_loss: 0.5260 - val_accuracy: 0.8831\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "6350/6350 [==============================] - 27s 4ms/step\n",
      "Saved model to disk\n",
      "ResNet_2\n",
      "5120/5120 [==============================] - 113s 22ms/step - loss: 0.1740 - accuracy: 0.9507 - val_loss: 0.6931 - val_accuracy: 0.8615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "6350/6350 [==============================] - 30s 5ms/step\n",
      "Saved model to disk\n",
      "ResNet_3\n",
      "5120/5120 [==============================] - 121s 23ms/step - loss: 0.1770 - accuracy: 0.9497 - val_loss: 0.6298 - val_accuracy: 0.8792\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "6350/6350 [==============================] - 33s 5ms/step\n",
      "Saved model to disk\n",
      "ResNet_4\n",
      "5120/5120 [==============================] - 136s 26ms/step - loss: 0.1770 - accuracy: 0.9489 - val_loss: 0.5313 - val_accuracy: 0.8520\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "6350/6350 [==============================] - 39s 6ms/step\n",
      "Saved model to disk\n",
      "ResNet_5\n",
      "5120/5120 [==============================] - 156s 30ms/step - loss: 0.2010 - accuracy: 0.9445 - val_loss: 1.8659 - val_accuracy: 0.7899\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "6350/6350 [==============================] - 44s 7ms/step\n",
      "Saved model to disk\n",
      "ResNet_6\n",
      "5120/5120 [==============================] - 174s 33ms/step - loss: 0.1673 - accuracy: 0.9506 - val_loss: 0.5053 - val_accuracy: 0.9031\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "6350/6350 [==============================] - 51s 8ms/step\n",
      "Saved model to disk\n",
      "ResNet_7\n",
      "5120/5120 [==============================] - 189s 36ms/step - loss: 0.1604 - accuracy: 0.9535 - val_loss: 0.6015 - val_accuracy: 0.8911\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "6350/6350 [==============================] - 54s 9ms/step\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "for LAYER in range(1,8):\n",
    "    filename = 'ResNet_' + str(LAYER)\n",
    "    print (filename)\n",
    "    if not os.path.exists(str(filename)):\n",
    "        os.makedirs(str(filename))\n",
    "    \n",
    "    model = ResNet_model(WINDOW_SIZE,INPUT_FEAT,OUTPUT_CLASS,LAYER)\n",
    "#     model.summary()\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size=32, epochs=1, callbacks=cb, validation_split=0.2, verbose=1)\n",
    "    prediction(model, X_test, y_test, filename)\n",
    "    save_the_model(filename, model)\n",
    "    write_history(filename, history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.callbacks.ModelCheckpoint(filepath=str(filename)+'/check_model.hdf5', monitor='val_loss', save_best_only=True)\n",
    "# for LAYER in range(1,8):\n",
    "#     filename = 'pretrained_models/CNN_' + str(LAYER)\n",
    "#     print (filename)\n",
    "#     model = CNN_model(WINDOW_SIZE,INPUT_FEAT,OUTPUT_CLASS,LAYER)\n",
    "#     model.load_weights(str(filename)+'/check_model.hdf5')\n",
    "#     model.predict(X_train)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# # enumerate the splits and summarize the distributions\n",
    "# for train_ix, test_ix in kfold.split(input_files, np.argmax(final_labels, axis=1)):\n",
    "#     X_train = input_files[train_ix]\n",
    "#     y_train = final_labels[train_ix]\n",
    "#     X_val = input_files[test_ix]\n",
    "#     y_val = final_labels[test_ix]\n",
    "#     print (cvset)\n",
    "# #     print (X_train, y_train, X_val, y_val)\n",
    "#     if not os.path.exists(str(cvset)):\n",
    "#         os.makedirs(str(cvset))\n",
    "    \n",
    "#     model = ResNet_model(2500,12,27,8)\n",
    "#     batch_size = 16\n",
    "\n",
    "#     # train_generator = generator(input_files, final_labels, batch_size)\n",
    "#     train_generator = generator(input_directory, X_train, y_train, batch_size)\n",
    "#     val_generator = generator(input_directory, X_val, y_val, batch_size)\n",
    "\n",
    "#     train_samples=np.ceil(len(X_train) / batch_size)\n",
    "#     val_samples=np.ceil(len(X_val) / batch_size)\n",
    "\n",
    "#     callbacks = [\n",
    "#         ModelCheckpoint(filepath=str(cvset)+'/check_model.h5', monitor='val_loss', save_best_only=True),\n",
    "#         EarlyStopping(monitor='val_acc', verbose=1, patience=5)]\n",
    "\n",
    "#     # ModelCheckpoint('weights-best_k{}_r{}.hdf5'.format(k,r), monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "#     history = model.fit_generator(train_generator, steps_per_epoch=train_samples, epochs=100, verbose=1, \n",
    "#                         validation_data=val_generator, validation_steps=val_samples, callbacks=callbacks)\n",
    "\n",
    "#     save_the_model(cvset, model)\n",
    "#     write_history(cvset, history.history)\n",
    "#     cvset = cvset+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
